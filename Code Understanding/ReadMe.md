# Replication Package of HelpCOM
HelpCOM is the solution we provide for generating meaningful method-level comments for dependent methods. To replicate our study, we provide folowing information to the readers.

## DataSet
The <b>Data</b> folder contains information related to our dataset.
<ol>
<li>Information of the mined JAVA projects are in "Github Projects for Method Hostory.pdf" </li>
<li>dbDump Folder
<ul>
<li>The dump of the main database used is given in "MainDB.bson" file. We used MongoDB. It can be restored using the command: <i>mongorestore --db databasename /pathTo_MainDB.bson </i></li>
<li>The Schema description of the database is given in "SchemaDetails.json" file.</li>
<ul>
</li>
</ol>

## Code Summarization Approaches
We have used several Code Summarization techniques in our study:
<ol>
<li> <b>ASAP:</b> SOTA Comment generation technique, which we replicated following the link: https://zenodo.org/records/10494170. Additional files are in <i>'/Scripts/ASAP'</i> folder. </li>
<li><b>CodeBERT:</b> For running CodeBERT for Code Summarization we followed the link: https://github.com/microsoft/CodeBERT/blob/master/CodeBERT/code2nl/README.md
</li>
<li><b>CodeT5+:</b> We utilized the HuggingFace (https://huggingface.co/Salesforce/codet5p-220m-bimodal) implementation to run CodeT5+</li> 
<li><b>Open LLM:</b>
<ul>
<li><b>CodeLama</b> ( Installation: https://ollama.com/library/codellama:7b-instruct)</li>
<li><b>Llama-3.3</b> ( Installation: https://ollama.com/library/llama3.3:70b)</li>
</ul>
</li>
</ol>

## Steps to reproduce the study
All the Scripts used in the study are placed under Scripts folder. Recommended Python version is 3.10.

<ol>
<li>Install MongoDB from https://www.mongodb.com/docs/manual/installation/. Our version is 7.0.16 </li>
<li>Create a database named 'code_understanding' in MongoDB and restore the collection from <i>'/Data/dbDump/MainDB.bson'.</i></li>
<li>Restore the dataset from <i>'/Data/dbDump/MainDB.bson'</i></li>
<li>The dataset is already ready to use. If one still wantd to make it from the scratch or see how we built it, please refer to the folder <i>'/Scripts/Data_Processing'</i>. To run the scripts, tree-sitter (https://tree-sitter.github.io/tree-sitter/) parser needs to be installed.</li>
<ul>
<li><i>gitLogExtractor.py</i> is used to fetch histories of each method from GitHub</li>
<li><i>methodExtractor.py</i> is used to extract all the methods from a java file</li>
<li><i>methodCallsExtractor.py</i> is used to extract all the method calls inside a method</li>
<li><i>matchMethods.py</i> is used to match the method bodies of the helper methods from the database</li>
</ul>
<li>To run HelpCOM and all of it's variant, please refer to <i>/Scripts/HelpCOM</i> folder</li>
<li>Al the evaluation metrics used in our study can be found in the <i>/Scripts/Metrics</i> folder.</li>
<li>Scripts for Significance Test are in the <i>/Scripts/SignificanceTest</i> folder.</li>
</ol>

## Summary Files
The <b>Summary</b> folder contains all the results in csv format generated by each of the comment generation techniques, including all the variants of HelpCOM. The ground truths can also be found there in separate csv files.

## Survey
We surveyed 156 software practitioners to take their insights of our study. The survey was approved by the board of ethics of the atuthors' university. To preserve the annonimity of the survey, we provide the survey questions in "survey_questions.pdf" file inside the <b>Survey</b> folder.