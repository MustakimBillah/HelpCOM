method,docstring,_id
"public RangeQueryBuilder timeZone(String timeZone) {
        if (timeZone == null) {
            throw new IllegalArgumentException(""timezone cannot be null"");
        }
        try {
            this.timeZone = ZoneId.of(timeZone);
        } catch (DateTimeException e) {
            throw new IllegalArgumentException(e);
        }
        return this;
    }","/**
     * In case of date field, we can adjust the from/to fields using a timezone
     */",67087d9c82a3a5339cc3dc0c
"public List<PluginRuntimeInfo> getPluginInfos() {
        return plugins.stream().sorted(Comparator.comparing(p -> p.descriptor().getName())).toList();
    }","/**
     * Returns an ordered list based on plugins name
     */",67087d9d82a3a5339cc3dc0d
"public Mesh setInstanceData (FloatBuffer instanceData, int count) {
		if (instances != null) {
			this.instances.setInstanceData(instanceData, count);
		} else {
			throw new GdxRuntimeException(""An InstanceBufferObject must be set before setting instance data!"");
		}
		return this;
	}","/** Sets the instance data of this Mesh. The attributes are assumed to be given in float format.
	 *
	 * @param instanceData the instance data.
	 * @param count the number of floats to use
	 * @return the mesh for invocation chaining. */",67087d9d82a3a5339cc3dc0e
"public static boolean convertAllMethodHandleArguments(TypeConverter converter, Object[] arguments,
			MethodHandle methodHandle, @Nullable Integer varargsPosition) throws EvaluationException {

		boolean conversionOccurred = false;
		MethodType methodHandleType = methodHandle.type();
		if (varargsPosition == null) {
			for (int i = 0; i < arguments.length; i++) {
				Class<?> argumentClass = methodHandleType.parameterType(i);
				ResolvableType resolvableType = ResolvableType.forClass(argumentClass);
				TypeDescriptor targetType = new TypeDescriptor(resolvableType, argumentClass, null);

				Object argument = arguments[i];
				TypeDescriptor sourceType = TypeDescriptor.forObject(argument);
				arguments[i] = converter.convertValue(argument, sourceType, targetType);
				conversionOccurred |= (argument != arguments[i]);
			}
		}
		else {
			// Convert everything up to the varargs position
			for (int i = 0; i < varargsPosition; i++) {
				Class<?> argumentClass = methodHandleType.parameterType(i);
				ResolvableType resolvableType = ResolvableType.forClass(argumentClass);
				TypeDescriptor targetType = new TypeDescriptor(resolvableType, argumentClass, null);

				Object argument = arguments[i];
				TypeDescriptor sourceType = TypeDescriptor.forObject(argument);
				arguments[i] = converter.convertValue(argument, sourceType, targetType);
				conversionOccurred |= (argument != arguments[i]);
			}

			Class<?> varargsArrayClass = methodHandleType.lastParameterType();
			// We use the wrapper type for a primitive varargs array, since we eventually
			// need an Object array in order to invoke the MethodHandle in
			// FunctionReference#executeFunctionViaMethodHandle().
			Class<?> varargsComponentClass = ClassUtils.resolvePrimitiveIfNecessary(varargsArrayClass.componentType());
			TypeDescriptor varargsArrayType = TypeDescriptor.array(TypeDescriptor.valueOf(varargsComponentClass));
			TypeDescriptor varargsComponentType = varargsArrayType.getElementTypeDescriptor();
			Assert.state(varargsComponentType != null, ""Component type must not be null for a varargs array"");

			// If the target is varargs and there is just one more argument, then convert it here.
			if (varargsPosition == arguments.length - 1) {
				Object argument = arguments[varargsPosition];
				TypeDescriptor sourceType = TypeDescriptor.forObject(argument);
				if (argument == null) {
					// Perform the equivalent of GenericConversionService.convertNullSource() for a single argument.
					if (varargsComponentType.getObjectType() == Optional.class) {
						arguments[varargsPosition] = Optional.empty();
						conversionOccurred = true;
					}
				}
				// If the argument type is assignable to the varargs component type, there is no need to
				// convert it. For example, using StringToArrayConverter to convert a String containing a
				// comma would result in the String being split and repackaged in an array when it should
				// be used as-is. Similarly, if the argument is an array that is assignable to the varargs
				// array type, there is no need to convert it.
				else if (!sourceType.isAssignableTo(varargsComponentType) ||
						(sourceType.isArray() && !sourceType.isAssignableTo(varargsArrayType))) {

					TypeDescriptor targetTypeToUse = (sourceType.isArray() ? varargsArrayType : varargsComponentType);
					arguments[varargsPosition] = converter.convertValue(argument, sourceType, targetTypeToUse);
				}
				// Possible outcomes of the above if-else block:
				// 1) the input argument was null, and nothing was done.
				// 2) the input argument was null; the varargs component type is Optional; and the argument was converted to Optional.empty().
				// 3) the input argument was the correct type but not wrapped in an array, and nothing was done.
				// 4) the input argument was already compatible (i.e., an Object array of valid type), and nothing was done.
				// 5) the input argument was the wrong type and got converted as explained in the comments above.
				if (argument != arguments[varargsPosition] &&
						!isFirstEntryInArray(argument, arguments[varargsPosition])) {
					conversionOccurred = true; // case 5
				}
			}
			// Otherwise, convert remaining arguments to the varargs component type.
			else {
				for (int i = varargsPosition; i < arguments.length; i++) {
					Object argument = arguments[i];
					TypeDescriptor sourceType = TypeDescriptor.forObject(argument);
					arguments[i] = converter.convertValue(argument, sourceType, varargsComponentType);
					conversionOccurred |= (argument != arguments[i]);
				}
			}
		}
		return conversionOccurred;
	}","/**
	 * Convert the supplied set of arguments into the parameter types of the supplied
	 * {@link MethodHandle}, taking the varargs position into account.
	 * <p>The arguments are converted 'in-place' in the input array.
	 * @param converter the converter to use for type conversions
	 * @param arguments the arguments to convert to the required parameter types
	 * @param methodHandle the target {@code MethodHandle}
	 * @param varargsPosition the known position of the varargs argument, if any
	 * ({@code null} if not varargs)
	 * @return {@code true} if some kind of conversion occurred on an argument
	 * @throws EvaluationException if a problem occurs during conversion
	 * @since 6.1
	 */",67087d9d82a3a5339cc3dc0f
"@Test
        void shouldProvidePopulatorThatEnforcesUniqueConstraints() throws Exception {
            // when
            Value value = Values.of(""value1"");
            int nodeId1 = 1;
            int nodeId2 = 2;

            withPopulator(
                    indexProvider.getPopulator(
                            descriptor,
                            indexSamplingConfig,
                            heapBufferFactory(1024),
                            INSTANCE,
                            tokenNameLookup,
                            Sets.immutable.empty(),
                            StorageEngineIndexingBehaviour.EMPTY),
                    p -> {
                        try {
                            p.add(
                                    Arrays.asList(add(nodeId1, descriptor, value), add(nodeId2, descriptor, value)),
                                    CursorContext.NULL_CONTEXT);
                            p.scanCompleted(
                                    PhaseTracker.nullInstance, populationWorkScheduler, CursorContext.NULL_CONTEXT);

                            fail(""expected exception"");
                        }
                        // then
                        catch (Exception e) {
                            Throwable root = getRootCause(e);
                            if (root instanceof IndexEntryConflictException conflict) {
                                assertEquals(nodeId1, conflict.getExistingEntityId());
                                assertEquals(ValueTuple.of(value), conflict.getPropertyValues());
                                assertEquals(nodeId2, conflict.getAddedEntityId());
                            } else {
                                throw e;
                            }
                        }
                    },
                    false);
        }","/**
         * This is also checked by the UniqueConstraintCompatibility test, only not on this abstraction level.
         */",67087d9d82a3a5339cc3dc10
"@Deprecated
    public boolean isAllowedByLicense(OperationMode minimumMode, boolean needActive) {
        return checkAgainstStatus(statusToCheck -> {
            if (needActive && false == statusToCheck.active()) {
                return false;
            }
            return isAllowedByOperationMode(statusToCheck.mode(), minimumMode);
        });
    }","/**
     * Test whether a feature is allowed by the status of license.
     *
     * @param minimumMode  The minimum license to meet or exceed
     * @param needActive   Whether current license needs to be active
     *
     * @return true if feature is allowed, otherwise false
     */",67087d9d82a3a5339cc3dc11
"@Nullable
	public static Integer getOrder(Class<?> type) {
		return getOrder((AnnotatedElement) type);
	}","/**
	 * Return the order on the specified {@code type}.
	 * <p>Takes care of {@link Order @Order} and {@code @jakarta.annotation.Priority}.
	 * @param type the type to handle
	 * @return the order value, or {@code null} if none can be found
	 * @see #getPriority(Class)
	 */",67087d9d82a3a5339cc3dc12
"public static ActiveShardCount parseString(final String str) {
        if (str == null) {
            return ActiveShardCount.DEFAULT;
        } else if (str.equals(""all"")) {
            return ActiveShardCount.ALL;
        } else {
            int val;
            try {
                val = Integer.parseInt(str);
            } catch (NumberFormatException e) {
                throw new IllegalArgumentException(""cannot parse ActiveShardCount["" + str + ""]"", e);
            }
            return ActiveShardCount.from(val);
        }
    }","/**
     * Parses the active shard count from the given string.  Valid values are ""all"" for
     * all shard copies, null for the default value (which defaults to one shard copy),
     * or a numeric value greater than or equal to 0. Any other input will throw an
     * IllegalArgumentException.
     */",67087d9d82a3a5339cc3dc13
"public void visitLabel(final Label label) {
    if (mv != null) {
      mv.visitLabel(label);
    }
  }","/**
   * Visits a label. A label designates the instruction that will be visited just after it.
   *
   * @param label a {@link Label} object.
   */",67087d9d82a3a5339cc3dc14
"@Override
	public Statement apply(Statement base, Description description) {
		Class<?> testClass = description.getTestClass();
		if (logger.isDebugEnabled()) {
			logger.debug(""Applying SpringClassRule to test class ["" + testClass.getName() + ""]"");
		}
		TestContextManager testContextManager = getTestContextManager(testClass);

		Statement statement = base;
		statement = withBeforeTestClassCallbacks(statement, testContextManager);
		statement = withAfterTestClassCallbacks(statement, testContextManager);
		statement = withProfileValueCheck(statement, testClass);
		statement = withTestContextManagerCacheEviction(statement, testClass);
		return statement;
	}","/**
	 * Apply <em>class-level</em> features of the <em>Spring TestContext
	 * Framework</em> to the supplied {@code base} statement.
	 * <p>Specifically, this method retrieves the {@link TestContextManager}
	 * used by this rule and its associated {@link SpringMethodRule} and
	 * invokes the {@link TestContextManager#beforeTestClass() beforeTestClass()}
	 * and {@link TestContextManager#afterTestClass() afterTestClass()} methods
	 * on the {@code TestContextManager}.
	 * <p>In addition, this method checks whether the test is enabled in
	 * the current execution environment. This prevents classes with a
	 * non-matching {@code @IfProfileValue} annotation from running altogether,
	 * even skipping the execution of {@code beforeTestClass()} methods
	 * in {@code TestExecutionListeners}.
	 * @param base the base {@code Statement} that this rule should be applied to
	 * @param description a {@code Description} of the current test execution
	 * @return a statement that wraps the supplied {@code base} with class-level
	 * features of the Spring TestContext Framework
	 * @see #getTestContextManager
	 * @see #withBeforeTestClassCallbacks
	 * @see #withAfterTestClassCallbacks
	 * @see #withProfileValueCheck
	 * @see #withTestContextManagerCacheEviction
	 */",67087d9d82a3a5339cc3dc15
"public static XContentBuilder contentBuilder() throws IOException {
        return provider.getContentBuilder();
    }","/**
     * Returns an {@link XContentBuilder} for building YAML based content.
     */",67087d9d82a3a5339cc3dc16
"public MeshPartBuilder begin (int primitiveType) {
		if (building) throw new GdxRuntimeException(""Call end() after calling begin()"");
		building = true;

		builder.begin(mesh.getVertexAttributes());
		builder.part(id, primitiveType, renderable.meshPart);
		return builder;
	}","/** Initialize ShapeCache for mesh generation
	 * @param primitiveType OpenGL primitive type */",67087d9d82a3a5339cc3dc17
"public static boolean nearlyEqual(float a, float b, float epsilon)
    {
        float absA = Math.abs(a);
        float absB = Math.abs(b);
        float diff = Math.abs(a - b);

        if (a == b) { // shortcut, handles infinities
            return true;
        }
        else if (a == 0 || b == 0 || diff < Float.MIN_NORMAL) {
            // a or b is zero or both are extremely close to it
            // relative error is less meaningful here
            return diff < (epsilon * Float.MIN_NORMAL);
        }
        else { // use relative error
            return diff / Math.min((absA + absB), Float.MAX_VALUE) < epsilon;
        }
    }","/**
     * See http://floating-point-gui.de/errors/comparison/
     */",67087d9d82a3a5339cc3dc18
"public synchronized Session getSession() {
		if (this.session == null) {
			this.session = Session.getInstance(this.javaMailProperties);
		}
		return this.session;
	}","/**
	 * Return the JavaMail {@code Session},
	 * lazily initializing it if it hasn't been specified explicitly.
	 */",67087d9d82a3a5339cc3dc19
"@Deprecated
    public B channelFactory(ChannelFactory<? extends C> channelFactory) {
        ObjectUtil.checkNotNull(channelFactory, ""channelFactory"");
        if (this.channelFactory != null) {
            throw new IllegalStateException(""channelFactory set already"");
        }

        this.channelFactory = channelFactory;
        return self();
    }","/**
     * @deprecated Use {@link #channelFactory(io.netty.channel.ChannelFactory)} instead.
     */",67087d9d82a3a5339cc3dc1a
"public String leadCoordinatorUrl()
  {
    ResolvedDruidService coord = config.requireCoordinator();
    ResolvedInstance leader = leader(coord);
    return coord.resolveUrl(leader);
  }","/**
   * Returns the URL for the lead coordinator.
   */",67087d9d82a3a5339cc3dc1b
"@Override
	public ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext context) {
		return evaluateAnnotation(EnabledIf.class, EnabledIf::expression, EnabledIf::reason,
				EnabledIf::loadContext, true, context);
	}","/**
	 * Containers and tests are enabled if {@code @EnabledIf} is present on the
	 * corresponding test class or test method and the configured expression
	 * evaluates to {@code true}.
	 */",67087d9d82a3a5339cc3dc1c
"public static int toUtf8WithLimit(final String string, final ByteBuffer byteBuffer)
  {
    final CharsetEncoder encoder = StandardCharsets.UTF_8
        .newEncoder()
        .onMalformedInput(CodingErrorAction.REPLACE)
        .onUnmappableCharacter(CodingErrorAction.REPLACE);

    final int originalPosition = byteBuffer.position();
    final int originalLimit = byteBuffer.limit();
    final int maxBytes = byteBuffer.remaining();

    try {
      final char[] chars = string.toCharArray();
      final CharBuffer charBuffer = CharBuffer.wrap(chars);

      // No reason to look at the CoderResult from the ""encode"" call; we can tell the number of transferred characters
      // by looking at the output buffer's position.
      encoder.encode(charBuffer, byteBuffer, true);

      final int bytesWritten = byteBuffer.position() - originalPosition;

      assert bytesWritten <= maxBytes;
      return bytesWritten;
    }
    finally {
      byteBuffer.position(originalPosition);
      byteBuffer.limit(originalLimit);
    }
  }","/**
   * Encodes ""string"" into the buffer ""byteBuffer"", using no more than the number of bytes remaining in the buffer.
   * Will only encode whole characters. The byteBuffer's position and limit may be changed during operation, but will
   * be reset before this method call ends.
   *
   * @return the number of bytes written, which may be shorter than the full encoded string length if there
   * is not enough room in the output buffer.
   */",67087d9d82a3a5339cc3dc1d
"public ServiceResponse<RegistrationSessionMetadataResponse> requestSmsVerificationCode(String sessionId, Locale locale, boolean androidSmsRetrieverSupported) {
    try {
      final RegistrationSessionMetadataResponse response = pushServiceSocket.requestVerificationCode(sessionId, locale, androidSmsRetrieverSupported, PushServiceSocket.VerificationCodeTransport.SMS);
      return ServiceResponse.forResult(response, 200, null);
    } catch (IOException e) {
      return ServiceResponse.forUnknownError(e);
    }
  }","/**
   * Request an SMS verification code.  On success, the server will send
   * an SMS verification code to this Signal user.
   *
   * @param androidSmsRetrieverSupported
   */",67087d9d82a3a5339cc3dc1e
"@Override
	public int hashCode() {
		return this.path.hashCode();
	}","/**
	 * This implementation returns the hash code of the underlying {@link Path} reference.
	 */",67087d9d82a3a5339cc3dc1f
"public static UriComponentsBuilder fromOriginHeader(String origin) {
		Matcher matcher = URI_PATTERN.matcher(origin);
		if (matcher.matches()) {
			UriComponentsBuilder builder = new UriComponentsBuilder();
			String scheme = matcher.group(2);
			String host = matcher.group(6);
			String port = matcher.group(8);
			if (StringUtils.hasLength(scheme)) {
				builder.scheme(scheme);
			}
			builder.host(host);
			if (StringUtils.hasLength(port)) {
				builder.port(port);
			}
			checkSchemeAndHost(origin, scheme, host);
			return builder;
		}
		else {
			throw new IllegalArgumentException(""["" + origin + ""] is not a valid \""Origin\"" header value"");
		}
	}","/**
	 * Create an instance by parsing the ""Origin"" header of an HTTP request.
	 * @see <a href=""https://tools.ietf.org/html/rfc6454"">RFC 6454</a>
	 */",67087d9d82a3a5339cc3dc20
"protected void handleResult(Object result, Message request, @Nullable Session session) {
		if (session != null) {
			if (logger.isDebugEnabled()) {
				logger.debug(""Listener method returned result ["" + result +
						""] - generating response message for it"");
			}
			try {
				Message response = buildMessage(session, result);
				postProcessResponse(request, response);
				Destination destination = getResponseDestination(request, response, session, result);
				sendResponse(session, destination, response);
			}
			catch (Exception ex) {
				throw new ReplyFailureException(""Failed to send reply with payload ["" + result + ""]"", ex);
			}
		}

		else {
			// No JMS Session available
			if (logger.isWarnEnabled()) {
				logger.warn(""Listener method returned result ["" + result +
						""]: not generating response message for it because of no JMS Session given"");
			}
		}
	}","/**
	 * Handle the given result object returned from the listener method,
	 * sending a response message back.
	 * @param result the result object to handle (never {@code null})
	 * @param request the original request message
	 * @param session the JMS Session to operate on (may be {@code null})
	 * @throws ReplyFailureException if the response message could not be sent
	 * @see #buildMessage
	 * @see #postProcessResponse
	 * @see #getResponseDestination
	 * @see #sendResponse
	 */",67087d9d82a3a5339cc3dc21
"public PackstreamBuf writeString8(String payload) {
        if (payload == null) {
            throw new NullPointerException(""payload cannot be null"");
        }

        return this.writeString8(payload.getBytes(STRING_CHARSET));
    }","/**
     * Writes an 8-bit prefixed string value of arbitrary length to this buffer.
     *
     * @param payload a string value.
     * @return a reference to this buffer.
     * @throws IllegalArgumentException when the value exceeds the bounds of this type.
     */",67087d9d82a3a5339cc3dc22
"public void testModeNonNumericField() throws IOException {
        SearchExecutionContext searchExecutionContext = createMockSearchExecutionContext();

        FieldSortBuilder sortBuilder = new FieldSortBuilder(MAPPED_STRING_FIELDNAME).sortMode(SortMode.MIN);
        SortField sortField = sortBuilder.build(searchExecutionContext).field;
        assertThat(sortField, instanceOf(SortedSetSortField.class));
        assertEquals(SortedSetSelector.Type.MIN, ((SortedSetSortField) sortField).getSelector());

        sortBuilder = new FieldSortBuilder(MAPPED_STRING_FIELDNAME).sortMode(SortMode.MAX);
        sortField = sortBuilder.build(searchExecutionContext).field;
        assertThat(sortField, instanceOf(SortedSetSortField.class));
        assertEquals(SortedSetSelector.Type.MAX, ((SortedSetSortField) sortField).getSelector());

        String expectedError = ""we only support AVG, MEDIAN and SUM on number based fields"";
        QueryShardException e = expectThrows(
            QueryShardException.class,
            () -> new FieldSortBuilder(MAPPED_STRING_FIELDNAME).sortMode(SortMode.AVG).build(searchExecutionContext)
        );
        assertEquals(expectedError, e.getMessage());

        e = expectThrows(
            QueryShardException.class,
            () -> new FieldSortBuilder(MAPPED_STRING_FIELDNAME).sortMode(SortMode.SUM).build(searchExecutionContext)
        );
        assertEquals(expectedError, e.getMessage());

        e = expectThrows(
            QueryShardException.class,
            () -> new FieldSortBuilder(MAPPED_STRING_FIELDNAME).sortMode(SortMode.MEDIAN).build(searchExecutionContext)
        );
        assertEquals(expectedError, e.getMessage());
    }","/**
     * Test that MIN, MAX mode work on non-numeric fields, but other modes throw exception
     */",67087d9d82a3a5339cc3dc23
"private void exchangeCodeForToken(AuthorizationCode code, ActionListener<Tuple<AccessToken, JWT>> tokensListener) {
        try {
            final AuthorizationCodeGrant codeGrant = new AuthorizationCodeGrant(code, rpConfig.getRedirectUri());
            final HttpPost httpPost = new HttpPost(opConfig.getTokenEndpoint());
            httpPost.setHeader(""Content-type"", ""application/x-www-form-urlencoded"");
            final List<NameValuePair> params = new ArrayList<>();
            for (Map.Entry<String, List<String>> entry : codeGrant.toParameters().entrySet()) {
                // All parameters of AuthorizationCodeGrant are singleton lists
                params.add(new BasicNameValuePair(entry.getKey(), entry.getValue().get(0)));
            }
            if (rpConfig.getClientAuthenticationMethod().equals(ClientAuthenticationMethod.CLIENT_SECRET_BASIC)) {
                UsernamePasswordCredentials creds = new UsernamePasswordCredentials(
                    URLEncoder.encode(rpConfig.getClientId().getValue(), StandardCharsets.UTF_8),
                    URLEncoder.encode(rpConfig.getClientSecret().toString(), StandardCharsets.UTF_8)
                );
                httpPost.addHeader(new BasicScheme().authenticate(creds, httpPost, null));
            } else if (rpConfig.getClientAuthenticationMethod().equals(ClientAuthenticationMethod.CLIENT_SECRET_POST)) {
                params.add(new BasicNameValuePair(""client_id"", rpConfig.getClientId().getValue()));
                params.add(new BasicNameValuePair(""client_secret"", rpConfig.getClientSecret().toString()));
            } else if (rpConfig.getClientAuthenticationMethod().equals(ClientAuthenticationMethod.CLIENT_SECRET_JWT)) {
                ClientSecretJWT clientSecretJWT = new ClientSecretJWT(
                    rpConfig.getClientId(),
                    opConfig.getTokenEndpoint(),
                    rpConfig.getClientAuthenticationJwtAlgorithm(),
                    new Secret(rpConfig.getClientSecret().toString())
                );
                for (Map.Entry<String, List<String>> entry : clientSecretJWT.toParameters().entrySet()) {
                    // Both client_assertion and client_assertion_type are singleton lists
                    params.add(new BasicNameValuePair(entry.getKey(), entry.getValue().get(0)));
                }
            } else {
                tokensListener.onFailure(
                    new ElasticsearchSecurityException(
                        ""Failed to exchange code for Id Token using Token Endpoint.""
                            + ""Expected client authentication method to be one of ""
                            + OpenIdConnectRealmSettings.CLIENT_AUTH_METHODS
                            + "" but was [""
                            + rpConfig.getClientAuthenticationMethod()
                            + ""]""
                    )
                );
            }
            httpPost.setEntity(new UrlEncodedFormEntity(params, (Charset) null));
            SpecialPermission.check();
            AccessController.doPrivileged((PrivilegedAction<Void>) () -> {

                httpClient.execute(httpPost, new FutureCallback<HttpResponse>() {
                    @Override
                    public void completed(HttpResponse result) {
                        handleTokenResponse(result, tokensListener);
                    }

                    @Override
                    public void failed(Exception ex) {
                        tokensListener.onFailure(
                            new ElasticsearchSecurityException(""Failed to exchange code for Id Token using the Token Endpoint."", ex)
                        );
                    }

                    @Override
                    public void cancelled() {
                        final String message = ""Failed to exchange code for Id Token using the Token Endpoint. Request was cancelled"";
                        tokensListener.onFailure(new ElasticsearchSecurityException(message));
                    }
                });
                return null;
            });
        } catch (AuthenticationException | JOSEException e) {
            tokensListener.onFailure(
                new ElasticsearchSecurityException(""Failed to exchange code for Id Token using the Token Endpoint."", e)
            );
        }
    }","/**
     * Attempts to make a request to the Token Endpoint of the OpenID Connect provider in order to exchange an
     * authorization code for an Id Token (and potentially an Access Token)
     */",67087d9d82a3a5339cc3dc24
"public void registerEntries(JsonMixinModuleEntries entries, ClassLoader classLoader) {
		entries.doWithEntry(classLoader, this::setMixInAnnotation);
	}","/**
	 * Register the specified {@link JsonMixinModuleEntries entries}.
	 * @param entries the entries to register to this instance
	 * @param classLoader the classloader to use
	 */",67087d9d82a3a5339cc3dc25
"protected boolean isIncludeBindingErrors(ServerRequest request, MediaType produces) {
		return switch (this.errorProperties.getIncludeBindingErrors()) {
			case ALWAYS -> true;
			case ON_PARAM -> isBindingErrorsEnabled(request);
			case NEVER -> false;
		};
	}","/**
	 * Determine if the errors attribute should be included.
	 * @param request the source request
	 * @param produces the media type produced (or {@code MediaType.ALL})
	 * @return if the errors attribute should be included
	 */",67087d9d82a3a5339cc3dc26
"public static double asin(double value) {
        boolean negateResult;
        if (value < 0.0) {
            value = -value;
            negateResult = true;
        } else {
            negateResult = false;
        }
        if (value <= ASIN_MAX_VALUE_FOR_TABS) {
            int index = (int) (value * ASIN_INDEXER + 0.5);
            double delta = value - index * ASIN_DELTA;
            double result = asinTab[index] + delta * (asinDer1DivF1Tab[index] + delta * (asinDer2DivF2Tab[index] + delta
                * (asinDer3DivF3Tab[index] + delta * asinDer4DivF4Tab[index])));
            return negateResult ? -result : result;
        } else if (value <= ASIN_MAX_VALUE_FOR_POWTABS) {
            int index = (int) (FastMath.powFast(value * ASIN_POWTABS_ONE_DIV_MAX_VALUE, ASIN_POWTABS_POWER) * ASIN_POWTABS_SIZE_MINUS_ONE
                + 0.5);
            double delta = value - asinParamPowTab[index];
            double result = asinPowTab[index] + delta * (asinDer1DivF1PowTab[index] + delta * (asinDer2DivF2PowTab[index] + delta
                * (asinDer3DivF3PowTab[index] + delta * asinDer4DivF4PowTab[index])));
            return negateResult ? -result : result;
        } else { // value > ASIN_MAX_VALUE_FOR_TABS, or value is NaN
            // This part is derived from fdlibm.
            if (value < 1.0) {
                double t = (1.0 - value) * 0.5;
                double p = t * (ASIN_PS0 + t * (ASIN_PS1 + t * (ASIN_PS2 + t * (ASIN_PS3 + t * (ASIN_PS4 + t * ASIN_PS5)))));
                double q = 1.0 + t * (ASIN_QS1 + t * (ASIN_QS2 + t * (ASIN_QS3 + t * ASIN_QS4)));
                double s = Math.sqrt(t);
                double z = s + s * (p / q);
                double result = ASIN_PIO2_HI - ((z + z) - ASIN_PIO2_LO);
                return negateResult ? -result : result;
            } else { // value >= 1.0, or value is NaN
                if (value == 1.0) {
                    return negateResult ? -Math.PI / 2 : Math.PI / 2;
                } else {
                    return Double.NaN;
                }
            }
        }
    }","/**
     * @param value Value in [-1,1].
     * @return Value arcsine, in radians, in [-PI/2,PI/2].
     */",67087d9d82a3a5339cc3dc27
"private ParseResult parse(CharSequence str, @Nullable ZoneId defaultTimezone) {
        int len = str.length();

        // YEARS
        Integer years = parseInt(str, 0, 4);
        if (years == null) return ParseResult.error(0);
        if (len == 4) {
            return isOptional(ChronoField.MONTH_OF_YEAR)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        defaults.get(ChronoField.MONTH_OF_YEAR),
                        defaults.get(ChronoField.DAY_OF_MONTH),
                        defaults.get(ChronoField.HOUR_OF_DAY),
                        defaults.get(ChronoField.MINUTE_OF_HOUR),
                        defaults.get(ChronoField.SECOND_OF_MINUTE),
                        defaults.get(ChronoField.NANO_OF_SECOND),
                        defaultTimezone
                    )
                )
                : ParseResult.error(4);
        }

        if (str.charAt(4) != '-') return ParseResult.error(4);

        // MONTHS
        Integer months = parseInt(str, 5, 7);
        if (months == null || months > 12) return ParseResult.error(5);
        if (len == 7) {
            return isOptional(ChronoField.DAY_OF_MONTH)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        defaults.get(ChronoField.DAY_OF_MONTH),
                        defaults.get(ChronoField.HOUR_OF_DAY),
                        defaults.get(ChronoField.MINUTE_OF_HOUR),
                        defaults.get(ChronoField.SECOND_OF_MINUTE),
                        defaults.get(ChronoField.NANO_OF_SECOND),
                        defaultTimezone
                    )
                )
                : ParseResult.error(7);
        }

        if (str.charAt(7) != '-') return ParseResult.error(7);

        // DAYS
        Integer days = parseInt(str, 8, 10);
        if (days == null || days > 31) return ParseResult.error(8);
        if (len == 10) {
            return optionalTime || isOptional(ChronoField.HOUR_OF_DAY)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        days,
                        defaults.get(ChronoField.HOUR_OF_DAY),
                        defaults.get(ChronoField.MINUTE_OF_HOUR),
                        defaults.get(ChronoField.SECOND_OF_MINUTE),
                        defaults.get(ChronoField.NANO_OF_SECOND),
                        defaultTimezone
                    )
                )
                : ParseResult.error(10);
        }

        if (str.charAt(10) != 'T') return ParseResult.error(10);
        if (len == 11) {
            return isOptional(ChronoField.HOUR_OF_DAY)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        days,
                        defaults.get(ChronoField.HOUR_OF_DAY),
                        defaults.get(ChronoField.MINUTE_OF_HOUR),
                        defaults.get(ChronoField.SECOND_OF_MINUTE),
                        defaults.get(ChronoField.NANO_OF_SECOND),
                        defaultTimezone
                    )
                )
                : ParseResult.error(11);
        }

        // HOURS + timezone
        Integer hours = parseInt(str, 11, 13);
        if (hours == null || hours > 23) return ParseResult.error(11);
        if (len == 13) {
            return isOptional(ChronoField.MINUTE_OF_HOUR)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        days,
                        hours,
                        defaultZero(ChronoField.MINUTE_OF_HOUR),
                        defaultZero(ChronoField.SECOND_OF_MINUTE),
                        defaultZero(ChronoField.NANO_OF_SECOND),
                        defaultTimezone
                    )
                )
                : ParseResult.error(13);
        }
        if (isZoneId(str, 13)) {
            ZoneId timezone = parseZoneId(str, 13);
            return timezone != null && isOptional(ChronoField.MINUTE_OF_HOUR)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        days,
                        hours,
                        defaultZero(ChronoField.MINUTE_OF_HOUR),
                        defaultZero(ChronoField.SECOND_OF_MINUTE),
                        defaultZero(ChronoField.NANO_OF_SECOND),
                        timezone
                    )
                )
                : ParseResult.error(13);
        }

        if (str.charAt(13) != ':') return ParseResult.error(13);

        // MINUTES + timezone
        Integer minutes = parseInt(str, 14, 16);
        if (minutes == null || minutes > 59) return ParseResult.error(14);
        if (len == 16) {
            return isOptional(ChronoField.SECOND_OF_MINUTE)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        days,
                        hours,
                        minutes,
                        defaultZero(ChronoField.SECOND_OF_MINUTE),
                        defaultZero(ChronoField.NANO_OF_SECOND),
                        defaultTimezone
                    )
                )
                : ParseResult.error(16);
        }
        if (isZoneId(str, 16)) {
            ZoneId timezone = parseZoneId(str, 16);
            return timezone != null && isOptional(ChronoField.SECOND_OF_MINUTE)
                ? new ParseResult(
                    withZoneOffset(
                        years,
                        months,
                        days,
                        hours,
                        minutes,
                        defaultZero(ChronoField.SECOND_OF_MINUTE),
                        defaultZero(ChronoField.NANO_OF_SECOND),
                        timezone
                    )
                )
                : ParseResult.error(16);
        }

        if (str.charAt(16) != ':') return ParseResult.error(16);

        // SECONDS + timezone
        Integer seconds = parseInt(str, 17, 19);
        if (seconds == null || seconds > 59) return ParseResult.error(17);
        if (len == 19) {
            return new ParseResult(
                withZoneOffset(years, months, days, hours, minutes, seconds, defaultZero(ChronoField.NANO_OF_SECOND), defaultTimezone)
            );
        }
        if (isZoneId(str, 19)) {
            ZoneId timezone = parseZoneId(str, 19);
            return timezone != null
                ? new ParseResult(
                    withZoneOffset(years, months, days, hours, minutes, seconds, defaultZero(ChronoField.NANO_OF_SECOND), timezone)
                )
                : ParseResult.error(19);
        }

        char decSeparator = str.charAt(19);
        if (decSeparator != '.' && decSeparator != ',') return ParseResult.error(19);

        // NANOS + timezone
        // nanos are always optional
        // the last number could be millis or nanos, or any combination in the middle
        // so we keep parsing numbers until we get to not a number
        int nanos = 0;
        int pos;
        for (pos = 20; pos < len && pos < 29; pos++) {
            char c = str.charAt(pos);
            if (c < ZERO || c > NINE) break;
            nanos = nanos * 10 + (c - ZERO);
        }

        if (pos == 20) return ParseResult.error(20);   // didn't find a number at all

        // multiply it by the correct multiplicand to get the nanos
        nanos *= NANO_MULTIPLICANDS[29 - pos];

        if (len == pos) {
            return new ParseResult(withZoneOffset(years, months, days, hours, minutes, seconds, nanos, defaultTimezone));
        }
        if (isZoneId(str, pos)) {
            ZoneId timezone = parseZoneId(str, pos);
            return timezone != null
                ? new ParseResult(withZoneOffset(years, months, days, hours, minutes, seconds, nanos, timezone))
                : ParseResult.error(pos);
        }

        // still chars left at the end - string is not valid
        return ParseResult.error(pos);
    }","/**
     * Parses {@code str} in ISO8601 format.
     * <p>
     * This parses the string using fixed offsets (it does not support variable-width fields) and separators,
     * sequentially parsing each field and looking for the correct separator.
     * This enables it to be very fast, as all the fields are in fixed places in the string.
     * The only variable aspect comes from the timezone, which (fortunately) is only present at the end of the string,
     * at any point after a time field.
     * It also does not use exceptions, instead returning {@code null} where a value cannot be parsed.
     */",67087d9d82a3a5339cc3dc28
"public void addCustomResolver(HandlerMethodArgumentResolver... resolvers) {
		Assert.notNull(resolvers, ""'resolvers' must not be null"");
		this.customResolvers.addAll(Arrays.asList(resolvers));
	}","/**
	 * Configure resolvers for custom handler method arguments.
	 * @param resolvers the resolvers to add
	 */",67087d9d82a3a5339cc3dc29
"public long getExpires() {
		return getFirstDate(EXPIRES, false);
	}","/**
	 * Return the date and time at which the message is no longer valid,
	 * as specified by the {@code Expires} header.
	 * <p>The date is returned as the number of milliseconds since
	 * January 1, 1970 GMT. Returns -1 when the date is unknown.
	 * @see #getFirstZonedDateTime(String)
	 */",67087d9d82a3a5339cc3dc2a
"@Override
	@Nullable
	public DataAccessException translateExceptionIfPossible(RuntimeException ex) {
		JpaDialect jpaDialect = getJpaDialect();
		return (jpaDialect != null ? jpaDialect.translateExceptionIfPossible(ex) :
				EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(ex));
	}","/**
	 * Implementation of the PersistenceExceptionTranslator interface, as
	 * autodetected by Spring's PersistenceExceptionTranslationPostProcessor.
	 * <p>Uses the dialect's conversion if possible; otherwise falls back to
	 * standard JPA exception conversion.
	 * @see org.springframework.dao.annotation.PersistenceExceptionTranslationPostProcessor
	 * @see JpaDialect#translateExceptionIfPossible
	 * @see EntityManagerFactoryUtils#convertJpaAccessExceptionIfPossible
	 */",67087d9d82a3a5339cc3dc2b
"static boolean hasAtLeastOneUnqualifiedExport(ModuleDescriptor md) {
        return md.exports().stream().anyMatch(Predicate.not(ModuleDescriptor.Exports::isQualified));
    }","/**
     * If a module has at least one unqualified export, then it has a public API
     * that can be used by other modules. If all of its exports are qualified, only
     * modules specified in its descriptor can read from it, and there's no
     * use in requiring it for a synthetic module.
     * @param md A module descriptor.
     * @return true if the module as at least one unqualified export, false otherwise
     */",67087d9d82a3a5339cc3dc2c
"public void testRemovingNodeReturnsYellowForDelayedIndex() throws Exception {
        internalCluster().startMasterOnlyNodes(1);
        internalCluster().startNodes(3, onlyRole(DiscoveryNodeRole.DATA_HOT_NODE_ROLE));
        ElasticsearchAssertions.assertAcked(
            prepareCreate(""test"").setSettings(
                Settings.builder()
                    .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)
                    .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 1)
                    .put(DataTier.TIER_PREFERENCE, DataTier.DATA_HOT)
                    .put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), TimeValue.timeValueMinutes(30))
            )
        );
        ensureGreen(""test"");
        indexRandomData(""test"");
        internalCluster().stopNode(findNodeWithPrimaryShard(""test"", 0));
        ensureYellow(""test"");
        GetHealthAction.Response healthResponse = client().execute(
            GetHealthAction.INSTANCE,
            new GetHealthAction.Request(ShardsAvailabilityHealthIndicatorService.NAME, true, 1000)
        ).get();
        HealthIndicatorResult indicatorResult = healthResponse.findIndicator(ShardsAvailabilityHealthIndicatorService.NAME);
        assertThat(indicatorResult.status(), equalTo(HealthStatus.YELLOW));
        assertThat(indicatorResult.diagnosisList().size(), equalTo(1));
        assertThat(
            indicatorResult.diagnosisList(),
            hasItem(
                new Diagnosis(
                    ShardsAvailabilityHealthIndicatorService.DIAGNOSIS_WAIT_FOR_OR_FIX_DELAYED_SHARDS,
                    List.of(new Diagnosis.Resource(Diagnosis.Resource.Type.INDEX, List.of(""test"")))
                )
            )
        );
    }","/**
     * Verify that the health API returns a ""YELLOW"" status when a node disappears and a shard is unassigned because it is delayed.
     */",67087d9d82a3a5339cc3dc2d
"@Override
	public ObjectName getObjectName(Object managedBean, @Nullable String beanKey) throws MalformedObjectNameException {
		Assert.state(this.attributeSource != null, ""No JmxAttributeSource set"");
		Class<?> managedClass = AopUtils.getTargetClass(managedBean);
		ManagedResource mr = this.attributeSource.getManagedResource(managedClass);

		// Check that an object name has been specified.
		if (mr != null && StringUtils.hasText(mr.getObjectName())) {
			return ObjectNameManager.getInstance(mr.getObjectName());
		}
		else {
			Assert.state(beanKey != null, ""No ManagedResource attribute and no bean key specified"");
			try {
				return ObjectNameManager.getInstance(beanKey);
			}
			catch (MalformedObjectNameException ex) {
				String domain = this.defaultDomain;
				if (domain == null) {
					domain = ClassUtils.getPackageName(managedClass);
				}
				Hashtable<String, String> properties = new Hashtable<>();
				properties.put(""type"", ClassUtils.getShortName(managedClass));
				properties.put(""name"", quoteIfNecessary(beanKey));
				return ObjectNameManager.getInstance(domain, properties);
			}
		}
	}","/**
	 * Reads the {@code ObjectName} from the source-level metadata associated
	 * with the managed resource's {@code Class}.
	 */",67087d9d82a3a5339cc3dc2e
"public void setJpaProperties(Properties jpaProperties) {
		CollectionUtils.mergePropertiesIntoMap(jpaProperties, this.jpaPropertyMap);
	}","/**
	 * Specify JPA properties, to be passed into
	 * {@code EntityManagerFactory.createEntityManager(Map)} (if any).
	 * <p>Can be populated with a String ""value"" (parsed via PropertiesEditor)
	 * or a ""props"" element in XML bean definitions.
	 * @see jakarta.persistence.EntityManagerFactory#createEntityManager(java.util.Map)
	 */",67087d9d82a3a5339cc3dc2f
"ActionListener<BulkResponse> wrapActionListenerIfNeeded(long ingestTookInMillis, ActionListener<BulkResponse> actionListener) {
        if (itemResponses.isEmpty()) {
            return actionListener.map(
                response -> new BulkResponse(response.getItems(), response.getTook().getMillis(), ingestTookInMillis)
            );
        } else {
            return actionListener.map(response -> {
                // these items are the responses from the subsequent bulk request, their 'slots'
                // are not correct for this response we're building
                final BulkItemResponse[] bulkResponses = response.getItems();

                final BulkItemResponse[] allResponses = new BulkItemResponse[bulkResponses.length + itemResponses.size()];

                // the item responses are from the original request, so their slots are correct.
                // these are the responses for requests that failed early and were not passed on to the subsequent bulk.
                for (BulkItemResponse item : itemResponses) {
                    allResponses[item.getItemId()] = item;
                }

                // use the original slots for the responses from the bulk
                for (int i = 0; i < bulkResponses.length; i++) {
                    allResponses[originalSlots.get(i)] = bulkResponses[i];
                }

                if (Assertions.ENABLED) {
                    assertResponsesAreCorrect(bulkResponses, allResponses);
                }

                return new BulkResponse(allResponses, response.getTook().getMillis(), ingestTookInMillis);
            });
        }
    }","/**
     * If documents were dropped or failed in ingest, this method wraps the action listener that will be notified when the
     * updated bulk operation is completed. The wrapped listener combines the dropped and failed document results from the ingest
     * service with the results returned from running the remaining write operations.
     *
     * @param ingestTookInMillis Time elapsed for ingestion to be passed to final result.
     * @param actionListener The action listener that expects the final bulk response.
     * @return An action listener that combines ingest failure results with the results from writing the remaining documents.
     */",67087d9d82a3a5339cc3dc30
"private boolean zeroHopLevel() {
        if (foundNodes.depth() > 0) {
            return false;
        }

        hooks.nextLevel(0);

        bfsExpander.discover(sourceData);
        if (sourceData.isTarget()) {
            targets.addTarget(sourceData);
        }
        // there is nothing in the frontier to expand yet, but calling this will push the discovered nodes into the
        // next frontier
        bfsExpander.expand();

        return targets.hasCurrentUnsaturatedTargets();
    }","/**
     * In some cases the start node is also a target node, so before we begin to expand any relationships we expand all
     * node juxtapositions from the source node to see if we have found targets
     *
     * @return true if the zero-hop expansion was performed and targets were found
     */",67087d9d82a3a5339cc3dc31
"public void setX (float x) {
		translateX(x - this.x);
	}","/** Sets the x position where the sprite will be drawn. If origin, rotation, or scale are changed, it is slightly more
	 * efficient to set the position after those operations. If both position and size are to be changed, it is better to use
	 * {@link #setBounds(float, float, float, float)}. */",67087d9d82a3a5339cc3dc32
"public void removeRange (int start, int end) {
		int n = size;
		if (end >= n) throw new IndexOutOfBoundsException(""end can't be >= size: "" + end + "" >= "" + size);
		if (start > end) throw new IndexOutOfBoundsException(""start can't be > end: "" + start + "" > "" + end);
		int count = end - start + 1, lastIndex = n - count;
		if (ordered)
			System.arraycopy(items, start + count, items, start, n - (start + count));
		else {
			int i = Math.max(lastIndex, end + 1);
			System.arraycopy(items, i, items, start, n - i);
		}
		size = n - count;
	}","/** Removes the items between the specified indices, inclusive. */",67087d9d82a3a5339cc3dc33
"public void testRemoteClusterProfileCannotBeUsedWhenRcs2IsEnabled() {
        List<Setting.AffixSetting<?>> transportProfileSettings = List.of(
            TransportSettings.TCP_KEEP_ALIVE_PROFILE,
            TransportSettings.TCP_KEEP_IDLE_PROFILE,
            TransportSettings.TCP_KEEP_INTERVAL_PROFILE,
            TransportSettings.TCP_KEEP_COUNT_PROFILE,
            TransportSettings.TCP_NO_DELAY_PROFILE,
            TransportSettings.TCP_REUSE_ADDRESS_PROFILE,
            TransportSettings.TCP_SEND_BUFFER_SIZE_PROFILE,
            TransportSettings.TCP_RECEIVE_BUFFER_SIZE_PROFILE,
            TransportSettings.BIND_HOST_PROFILE,
            TransportSettings.PUBLISH_HOST_PROFILE,
            TransportSettings.PORT_PROFILE,
            TransportSettings.PUBLISH_PORT_PROFILE
        );

        for (Setting.AffixSetting<?> profileSetting : transportProfileSettings) {
            Settings testSettings = Settings.builder()
                .put(REMOTE_CLUSTER_SERVER_ENABLED.getKey(), true)
                // We can just stick a random value in, even if it doesn't match the type - that validation happens at a different layer
                .put(profileSetting.getConcreteSettingForNamespace(REMOTE_CLUSTER_PROFILE).getKey(), randomAlphaOfLength(5))
                .build();
            final IllegalArgumentException e = expectThrows(
                IllegalArgumentException.class,
                () -> RemoteClusterPortSettings.buildRemoteAccessProfileSettings(testSettings)
            );
            assertThat(
                e.getMessage(),
                containsString(
                    ""Remote Access settings should not be configured using the [_remote_cluster] profile. ""
                        + ""Use the [remote_cluster.] settings instead.""
                )
            );
        }
    }","/**
     * Tests that, if Remote Cluster Security 2.0 is enabled, we reject any configuration of that profile
     * via the profile settings.
     */",67087d9d82a3a5339cc3dc34
"public Builder deleteScript(String id) {
            StoredScriptSource deleted = scripts.remove(id);

            if (deleted == null) {
                throw new ResourceNotFoundException(""stored script ["" + id + ""] does not exist and cannot be deleted"");
            }

            return this;
        }","/**
         * Delete a script from the existing stored scripts based on a user-specified id.
         * @param id The user-specified id to use for the look up.
         */",67087d9d82a3a5339cc3dc35
"public void testChangePolicyForIndex() throws Exception {
        String indexName = ""test-000001"";
        // create policy_1 and policy_2
        Map<String, Phase> phases1 = new HashMap<>();
        phases1.put(
            ""hot"",
            new Phase(
                ""hot"",
                TimeValue.ZERO,
                singletonMap(RolloverAction.NAME, new RolloverAction(null, null, null, 1L, null, null, null, null, null, null))
            )
        );
        phases1.put(
            ""warm"",
            new Phase(
                ""warm"",
                TimeValue.ZERO,
                singletonMap(AllocateAction.NAME, new AllocateAction(1, null, singletonMap(""_name"", ""foobarbaz""), null, null))
            )
        );
        LifecyclePolicy lifecyclePolicy1 = new LifecyclePolicy(""policy_1"", phases1);
        Map<String, Phase> phases2 = new HashMap<>();
        phases2.put(
            ""hot"",
            new Phase(
                ""hot"",
                TimeValue.ZERO,
                singletonMap(RolloverAction.NAME, new RolloverAction(null, null, null, 1000L, null, null, null, null, null, null))
            )
        );
        phases2.put(
            ""warm"",
            new Phase(
                ""warm"",
                TimeValue.ZERO,
                singletonMap(
                    AllocateAction.NAME,
                    new AllocateAction(
                        1,
                        null,
                        singletonMap(""_name"", ""javaRestTest-0,javaRestTest-1,javaRestTest-2,javaRestTest-3""),
                        null,
                        null
                    )
                )
            )
        );
        LifecyclePolicy lifecyclePolicy2 = new LifecyclePolicy(""policy_2"", phases2);
        // PUT policy_1 and policy_2
        XContentBuilder builder1 = jsonBuilder();
        lifecyclePolicy1.toXContent(builder1, null);
        final StringEntity entity1 = new StringEntity(""{ \""policy\"":"" + Strings.toString(builder1) + ""}"", ContentType.APPLICATION_JSON);
        Request request1 = new Request(""PUT"", ""_ilm/policy/"" + ""policy_1"");
        request1.setEntity(entity1);
        assertOK(client().performRequest(request1));
        XContentBuilder builder2 = jsonBuilder();
        lifecyclePolicy2.toXContent(builder2, null);
        final StringEntity entity2 = new StringEntity(""{ \""policy\"":"" + Strings.toString(builder2) + ""}"", ContentType.APPLICATION_JSON);
        Request request2 = new Request(""PUT"", ""_ilm/policy/"" + ""policy_2"");
        request2.setEntity(entity2);
        assertOK(client().performRequest(request2));

        // create the test-index index and set the policy to policy_1
        Settings settings = Settings.builder()
            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 4)
            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)
            .put(""index.routing.allocation.include._name"", ""javaRestTest-0"")
            .put(RolloverAction.LIFECYCLE_ROLLOVER_ALIAS, ""alias"")
            .put(LifecycleSettings.LIFECYCLE_NAME, ""policy_1"")
            .build();
        Request createIndexRequest = new Request(""PUT"", ""/"" + indexName);
        createIndexRequest.setJsonEntity(Strings.format(""""""
            {
              ""settings"": %s,
              ""aliases"": {
                ""alias"": {
                  ""is_write_index"": true
                }
              }
            }"""""", Strings.toString(settings)));
        client().performRequest(createIndexRequest);
        // wait for the shards to initialize
        ensureGreen(indexName);

        // Check the index is on the attempt rollover step
        assertBusy(() -> assertStep(indexName, new StepKey(""hot"", RolloverAction.NAME, WaitForRolloverReadyStep.NAME)));

        // Change the policy to policy_2
        Request changePolicyRequest = new Request(""PUT"", ""/"" + indexName + ""/_settings"");
        final StringEntity changePolicyEntity = new StringEntity(
            ""{ \""index.lifecycle.name\"": \""policy_2\"" }"",
            ContentType.APPLICATION_JSON
        );
        changePolicyRequest.setEntity(changePolicyEntity);
        assertOK(client().performRequest(changePolicyRequest));

        // Check the index is still on the attempt rollover step
        assertBusy(() -> assertStep(indexName, new StepKey(""hot"", RolloverAction.NAME, WaitForRolloverReadyStep.NAME)));

        // Index a single document
        XContentBuilder document = jsonBuilder().startObject();
        document.field(""foo"", ""bar"");
        document.endObject();
        final Request request = new Request(""POST"", ""/"" + indexName + ""/_doc/1?refresh"");
        request.setJsonEntity(Strings.toString(document));
        assertOK(client().performRequest(request));

        // Check the index goes to the warm phase and completes
        assertBusy(() -> assertStep(indexName, PhaseCompleteStep.finalStep(""warm"").getKey()), 30, TimeUnit.SECONDS);

        // Check index is allocated on javaRestTest-1 and javaRestTest-2 as per policy_2
        Map<String, Object> indexSettings = getIndexSettingsAsMap(indexName);
        String includesAllocation = (String) indexSettings.get(""index.routing.allocation.include._name"");
        assertEquals(""javaRestTest-0,javaRestTest-1,javaRestTest-2,javaRestTest-3"", includesAllocation);
    }","/**
     * This test aims to prove that an index will finish the current phase on an
     * existing definition when the policy is changed for that index, and that
     * after completing the current phase the new policy will be used for
     * subsequent phases.
     *
     * The test creates two policies, one with a hot phase requiring 1 document
     * to rollover and a warm phase with an impossible allocation action. The
     * second policy has a rollover action requiring 1000 document and a warm
     * phase that moves the index to known nodes that will succeed. An index is
     * created with the first policy set and the test ensures the policy is in
     * the rollover step. It then changes the policy for the index to the second
     * policy. It indexes a single document and checks that the index moves past
     * the hot phase and through the warm phase (proving the hot phase
     * definition from the first policy was used) and then checks the allocation
     * settings from the second policy are set ont he index (proving the second
     * policy was used for the warm phase)
     */",67087d9d82a3a5339cc3dc36
"public static MockHttpServletRequestBuilder put(URI uri) {
		return new MockHttpServletRequestBuilder(HttpMethod.PUT).uri(uri);
	}","/**
	 * Create a {@link MockHttpServletRequestBuilder} for a PUT request.
	 * @param uri the URI
	 * @since 4.0.3
	 */",67087d9d82a3a5339cc3dc37
"public void pulseAtPosition(int position) {
    if (position >= 0 && position < getItemCount()) {
      int correctedPosition = isHeaderPosition(position) ? position + 1 : position;

      recordToPulse = getItem(correctedPosition);
      pulseRequest = new PulseRequest(position, recordToPulse.getMessageRecord().isOutgoing());
      notifyItemChanged(correctedPosition);
    }
  }","/**
   * Momentarily highlights a mention at the requested position.
   */",67087d9d82a3a5339cc3dc38
"public List<Map<String, String>> getInteractions() throws Exception {
        final String url = ""http://localhost:"" + CONTAINER_PORT + ""/mockserver/retrieve?type=REQUEST_RESPONSES"";

        final String result = doRequest(url, null);

        final ObjectMapper objectMapper = new ObjectMapper();
        final JsonNode jsonNode = objectMapper.readTree(result);

        assertThat(""Response from mockserver is not a JSON array"", jsonNode.isArray(), is(true));

        final List<Map<String, String>> interactions = new ArrayList<>();

        for (JsonNode node : jsonNode) {
            final Map<String, String> interaction = new HashMap<>();
            addKeys("""", node, interaction);
            interactions.add(interaction);
        }

        return interactions;
    }","/**
     * Returns all interactions with the mockserver since startup, the last call to {@link #reset()} or the
     * last call to {@link #clearExpectations()}. The JSON returned by the mockserver is flattened, so that
     * the period-seperated keys in each map represent the structure of the JSON.
     *
     * @return a list of interactions
     * @throws Exception if anything goes wrong
     */",67087d9d82a3a5339cc3dc39
"public static String getErrorCodeFromMessage(String message)
  {
    if (message == null || message.isEmpty() || !message.contains(ERROR_CODE_DELIMITER)) {
      return UnknownFault.CODE;
    }
    return message.split(ERROR_CODE_DELIMITER, 2)[0];
  }","/**
   * Gets the error code from the message. If the message is empty or null, {@link UnknownFault#CODE} is returned. This method
   * does not gurantee that the error code we get out of the message is a valid error code.
   */",67087d9d82a3a5339cc3dc3a
"public static Expression unwrap(Expression e) {
        return e instanceof Alias as ? as.child() : e;
    }","/**
     * If the given expression is an alias, return its child - otherwise return as is.
     */",67087d9d82a3a5339cc3dc3b
"public PlanNode defaultRewrite(PlanNode node, C context)
        {
            List<PlanNode> children = node.getSources().stream()
                    .map(child -> rewrite(child, context))
                    .collect(Collectors.toList());

            for (int i = 0; i < node.getSources().size(); i++) {
                if (children.get(i) != node.getSources().get(i)) {
                    return node.replaceChildren(children);
                }
            }
            return node;
        }","/**
         * Invoke the rewrite logic recursively on children of the given node and swap it
         * out with an identical copy with the rewritten children
         */",67087d9d82a3a5339cc3dc3c
"private List<DruidRel<?>> flattenOutermostRel(DruidRel<?> outermostDruidRel)
  {
    List<DruidRel<?>> druidRels = new ArrayList<>();
    flattenOutermostRel(outermostDruidRel, druidRels);
    return druidRels;
  }","/**
   * Given a {@link DruidRel}, this method recursively flattens the Rels if they are of the type {@link DruidUnionRel}
   * It is implicitly assumed that the {@link DruidUnionRel} can never be the child of a non {@link DruidUnionRel}
   * node
   * E.g. a DruidRel structure of kind:<pre><code>
   * DruidUnionRel
   *  DruidUnionRel
   *    DruidRel (A)
   *    DruidRel (B)
   *  DruidRel(C)
   * </code</pre>will return {@code [DruidRel(A), DruidRel(B), DruidRel(C)]}.
   *
   * @param outermostDruidRel The outermost rel which is to be flattened
   * @return a list of DruidRel's which do not have a DruidUnionRel nested in between them
   */",67087d9d82a3a5339cc3dc3d
"protected void initJaxbUnmarshaller(Unmarshaller unmarshaller) throws JAXBException {
		if (this.unmarshallerProperties != null) {
			for (Map.Entry<String, ?> entry : this.unmarshallerProperties.entrySet()) {
				unmarshaller.setProperty(entry.getKey(), entry.getValue());
			}
		}
		if (this.unmarshallerListener != null) {
			unmarshaller.setListener(this.unmarshallerListener);
		}
		if (this.validationEventHandler != null) {
			unmarshaller.setEventHandler(this.validationEventHandler);
		}
		if (this.adapters != null) {
			for (XmlAdapter<?, ?> adapter : this.adapters) {
				unmarshaller.setAdapter(adapter);
			}
		}
		if (this.schema != null) {
			unmarshaller.setSchema(this.schema);
		}
	}","/**
	 * Template method that can be overridden by concrete JAXB marshallers
	 * for custom initialization behavior. Gets called after creation of JAXB
	 * {@code Marshaller}, and after the respective properties have been set.
	 * <p>The default implementation sets the
	 * {@link #setUnmarshallerProperties defined properties}, the
	 * {@link #setValidationEventHandler validation event handler}, the
	 * {@link #setSchemas schemas}, {@link #setUnmarshallerListener listener},
	 * and {@link #setAdapters adapters}.
	 */",67087d9d82a3a5339cc3dc3e
"@Nullable
    HttpTracer maybeLogRequest(RestRequest restRequest, @Nullable Exception e) {
        if (logger.isTraceEnabled() && TransportService.shouldTraceAction(restRequest.uri(), tracerLogInclude, tracerLogExclude)) {
            // trace.id in the response log is included from threadcontext, which isn't set at request log time
            // so include it here as part of the message
            logger.trace(
                () -> format(
                    ""[%s][%s][%s][%s] received request from [%s]%s"",
                    restRequest.getRequestId(),
                    restRequest.header(Task.X_OPAQUE_ID_HTTP_HEADER),
                    restRequest.method(),
                    restRequest.uri(),
                    restRequest.getHttpChannel(),
                    RestUtils.extractTraceId(restRequest.header(Task.TRACE_PARENT_HTTP_HEADER)).map(t -> "" trace.id: "" + t).orElse("""")
                ),
                e
            );
            if (isBodyTracerEnabled()) {
                try (var stream = HttpBodyTracer.getBodyOutputStream(restRequest.getRequestId(), HttpBodyTracer.Type.REQUEST)) {
                    restRequest.content().writeTo(stream);
                } catch (Exception e2) {
                    assert false : e2; // no real IO here
                }
            }

            return this;
        }
        return null;
    }","/**
     * Logs the given request if request tracing is enabled and the request uri matches the current include and exclude patterns defined
     * in {@link HttpTransportSettings#SETTING_HTTP_TRACE_LOG_INCLUDE} and {@link HttpTransportSettings#SETTING_HTTP_TRACE_LOG_EXCLUDE}.
     * If the request was logged returns a logger to log sending the response with or {@code null} otherwise.
     *
     * @param restRequest Rest request to trace
     * @param e           Exception when handling the request or {@code null} if none
     * @return            This instance to use for logging the response via {@link #logResponse} to this request if it was logged or
     *                    {@code null} if the request wasn't logged
     */",67087d9d82a3a5339cc3dc3f
"protected JavaType getJavaTypeForMessage(Message message) throws JMSException {
		String typeId = message.getStringProperty(this.typeIdPropertyName);
		if (typeId == null) {
			throw new MessageConversionException(
					""Could not find type id property ["" + this.typeIdPropertyName + ""] on message ["" +
					message.getJMSMessageID() + ""] from destination ["" + message.getJMSDestination() + ""]"");
		}
		Class<?> mappedClass = this.idClassMappings.get(typeId);
		if (mappedClass != null) {
			return this.objectMapper.constructType(mappedClass);
		}
		try {
			Class<?> typeClass = ClassUtils.forName(typeId, this.beanClassLoader);
			return this.objectMapper.constructType(typeClass);
		}
		catch (Throwable ex) {
			throw new MessageConversionException(""Failed to resolve type id ["" + typeId + ""]"", ex);
		}
	}","/**
	 * Determine a Jackson JavaType for the given JMS Message,
	 * typically parsing a type id message property.
	 * <p>The default implementation parses the configured type id property name
	 * and consults the configured type id mapping. This can be overridden with
	 * a different strategy, e.g. doing some heuristics based on message origin.
	 * @param message the JMS Message from which to get the type id property
	 * @throws JMSException if thrown by JMS methods
	 * @see #setTypeIdOnMessage(Object, jakarta.jms.Message)
	 * @see #setTypeIdPropertyName(String)
	 * @see #setTypeIdMappings(java.util.Map)
	 */",67087d9d82a3a5339cc3dc40
"public void drawPixmap (Pixmap pixmap, int x, int y, int srcx, int srcy, int srcWidth, int srcHeight) {
		CanvasElement image = pixmap.getCanvasElement();
		image(image, srcx, srcy, srcWidth, srcHeight, x, y, srcWidth, srcHeight);
	}","/** Draws an area from another Pixmap to this Pixmap.
	 * 
	 * @param pixmap The other Pixmap
	 * @param x The target x-coordinate (top left corner)
	 * @param y The target y-coordinate (top left corner)
	 * @param srcx The source x-coordinate (top left corner)
	 * @param srcy The source y-coordinate (top left corner)
	 * @param srcWidth The width of the area from the other Pixmap in pixels
	 * @param srcHeight The height of the area from the other Pixmap in pixels */",67087d9d82a3a5339cc3dc41
"public int size() {
            return unassigned.size();
        }","/**
         * Returns the size of the non-ignored unassigned shards
         */",67087d9d82a3a5339cc3dc42
"@After
    public void shutdownExec() {
        executorService.shutdown();
    }","/**
     * Shutdown the executor so we don't leak threads into other test runs.
     */",67087d9d82a3a5339cc3dc43
"public TokenInvalidation invalidateTokensForUser(String username) throws IOException {
        return invalidateTokens(String.format(Locale.ROOT, """"""
            {
              ""username"":""%s""
            }
            """""", username));
    }","/**
     * Uses the REST API to invalidate all tokens owned by a named user
     * @see org.elasticsearch.xpack.security.rest.action.oauth2.RestInvalidateTokenAction
     */",67087d9d82a3a5339cc3dc44
"public CompletableFuture<StompSession> connectAsync(StompSessionHandler handler) {
		return connectAsync(null, handler);
	}","/**
	 * Connect and notify the given {@link StompSessionHandler} when connected
	 * on the STOMP level.
	 * @param handler the handler for the STOMP session
	 * @return a CompletableFuture for access to the session when ready for use
	 * @since 6.0
	 */",67087d9d82a3a5339cc3dc45
"protected long now() {
        // System.nanoTime takes non-negligible time, so we only use it if we need it
        // use System.nanoTime because we want relative time, not absolute time
        return entriesExpireAfterAccess || entriesExpireAfterWrite ? System.nanoTime() : 0;
    }","/**
     * The relative time used to track time-based evictions.
     *
     * @return the current relative time
     */",67087d9d82a3a5339cc3dc46
"public void setCacheResolver(@Nullable CacheResolver cacheResolver) {
		this.cacheResolver = SingletonSupplier.ofNullable(cacheResolver);
	}","/**
	 * Set the default {@link CacheResolver} that this cache aspect should delegate
	 * to if no specific cache resolver has been set for the operation.
	 * <p>The default resolver resolves the caches against their names and the
	 * default cache manager.
	 * @see #setCacheManager
	 * @see SimpleCacheResolver
	 */",67087d9d82a3a5339cc3dc47
"public void start(ContainerReference reference) throws IOException {
			Assert.notNull(reference, ""Reference must not be null"");
			URI uri = buildUrl(""/containers/"" + reference + ""/start"");
			http().post(uri).close();
		}","/**
		 * Start a specific container.
		 * @param reference the container reference to start
		 * @throws IOException on IO error
		 */",67087d9d82a3a5339cc3dc48
"public double greatCircleMinLatitude(LatLng latLng) {
        if (isNumericallyIdentical(latLng)) {
            return latLng.lat;
        }
        return latLng.lat < this.lat ? greatCircleMinLatitude(latLng, this) : greatCircleMinLatitude(this, latLng);
    }","/**
     * Determines the minimum latitude of the great circle defined by this LatLng to the provided LatLng.
     *
     * @param latLng The LatLng.
     * @return The minimum latitude of the great circle in radians.
     */",67087d9d82a3a5339cc3dc49
"public void testNoPruningWhenDealingJustWithEvals() {
        var plan = plan(""""""
              from test
            | stats c = count(salary), max = max(salary), min = min(salary)
            | eval x = max + min + c
            | eval y = min
            | eval z = c
            """""");

        var eval = as(plan, Eval.class);
        var limit = as(eval.child(), Limit.class);
        var agg = as(limit.child(), Aggregate.class);
    }","/**
     * Expects
     * Eval[[max{r}#6 + min{r}#9 + c{r}#3 AS x, min{r}#9 AS y, c{r}#3 AS z]]
     * \_Limit[1000[INTEGER]]
     *   \_Aggregate[[],[COUNT(salary{f}#26) AS c, MAX(salary{f}#26) AS max, MIN(salary{f}#26) AS min]]
     *     \_EsRelation[test][_meta_field{f}#27, emp_no{f}#21, first_name{f}#22, ..]
     */",67087d9d82a3a5339cc3dc4a
"static void runHook() {
        for (String filename : FILES) {
            new File(filename).delete();
        }
    }","/**
     * Clean up all the files.
     */",67087d9d82a3a5339cc3dc4b
"private static void quickSort(double[] key, double[][] values, int start, int end, int limit) {
        // the while loop implements tail-recursion to avoid excessive stack calls on nasty cases
        while (end - start > limit) {

            // median of three values for the pivot
            int a = start;
            int b = (start + end) / 2;
            int c = end - 1;

            int pivotIndex;
            double pivotValue;
            double va = key[a];
            double vb = key[b];
            double vc = key[c];

            if (va > vb) {
                if (vc > va) {
                    // vc > va > vb
                    pivotIndex = a;
                    pivotValue = va;
                } else {
                    // va > vb, va >= vc
                    if (vc < vb) {
                        // va > vb > vc
                        pivotIndex = b;
                        pivotValue = vb;
                    } else {
                        // va >= vc >= vb
                        pivotIndex = c;
                        pivotValue = vc;
                    }
                }
            } else {
                // vb >= va
                if (vc > vb) {
                    // vc > vb >= va
                    pivotIndex = b;
                    pivotValue = vb;
                } else {
                    // vb >= va, vb >= vc
                    if (vc < va) {
                        // vb >= va > vc
                        pivotIndex = a;
                        pivotValue = va;
                    } else {
                        // vb >= vc >= va
                        pivotIndex = c;
                        pivotValue = vc;
                    }
                }
            }

            // move pivot to beginning of array
            swap(start, pivotIndex, key, values);

            // we use a three way partition because many duplicate values is an important case

            int low = start + 1;   // low points to first value not known to be equal to pivotValue
            int high = end;        // high points to first value > pivotValue
            int i = low;           // i scans the array
            while (i < high) {
                // invariant: values[order[k]] == pivotValue for k in [0..low)
                // invariant: values[order[k]] < pivotValue for k in [low..i)
                // invariant: values[order[k]] > pivotValue for k in [high..end)
                // in-loop: i < high
                // in-loop: low < high
                // in-loop: i >= low
                double vi = key[i];
                if (vi == pivotValue) {
                    if (low != i) {
                        swap(low, i, key, values);
                    } else {
                        i++;
                    }
                    low++;
                } else if (vi > pivotValue) {
                    high--;
                    swap(i, high, key, values);
                } else {
                    // vi < pivotValue
                    i++;
                }
            }
            // invariant: values[order[k]] == pivotValue for k in [0..low)
            // invariant: values[order[k]] < pivotValue for k in [low..i)
            // invariant: values[order[k]] > pivotValue for k in [high..end)
            // assert i == high || low == high therefore, we are done with partition

            // at this point, i==high, from [start,low) are == pivot, [low,high) are < and [high,end) are >
            // we have to move the values equal to the pivot into the middle. To do this, we swap pivot
            // values into the top end of the [low,high) range stopping when we run out of destinations
            // or when we run out of values to copy
            int from = start;
            int to = high - 1;
            for (i = 0; from < low && to >= low; i++) {
                swap(from++, to--, key, values);
            }
            if (from == low) {
                // ran out of things to copy. This means that the last destination is the boundary
                low = to + 1;
            } else {
                // ran out of places to copy to. This means that there are uncopied pivots and the
                // boundary is at the beginning of those
                low = from;
            }

            // checkPartition(order, values, pivotValue, start, low, high, end);

            // now recurse, but arrange it so we handle the longer limit by tail recursion
            if (low - start < end - high) {
                quickSort(key, values, start, low, limit);

                // this is really a way to do
                // quickSort(order, values, high, end, limit);
                start = high;
            } else {
                quickSort(key, values, high, end, limit);
                // this is really a way to do
                // quickSort(order, values, start, low, limit);
                end = low;
            }
        }
    }","/**
     * Standard quick sort except that sorting rearranges parallel arrays
     *
     * @param key    Values to sort on
     * @param values The auxiliary values to sort.
     * @param start  The beginning of the values to sort
     * @param end    The value after the last value to sort
     * @param limit  The minimum size to recurse down to.
     */",67087d9d82a3a5339cc3dc4c
"@Bean
	public RequestMappingHandlerAdapter requestMappingHandlerAdapter(
			@Qualifier(""mvcContentNegotiationManager"") ContentNegotiationManager contentNegotiationManager,
			@Qualifier(""mvcConversionService"") FormattingConversionService conversionService,
			@Qualifier(""mvcValidator"") Validator validator) {

		RequestMappingHandlerAdapter adapter = createRequestMappingHandlerAdapter();
		adapter.setContentNegotiationManager(contentNegotiationManager);
		adapter.setMessageConverters(getMessageConverters());
		adapter.setWebBindingInitializer(getConfigurableWebBindingInitializer(conversionService, validator));
		adapter.setCustomArgumentResolvers(getArgumentResolvers());
		adapter.setCustomReturnValueHandlers(getReturnValueHandlers());
		adapter.setErrorResponseInterceptors(getErrorResponseInterceptors());

		if (jackson2Present) {
			adapter.setRequestBodyAdvice(Collections.singletonList(new JsonViewRequestBodyAdvice()));
			adapter.setResponseBodyAdvice(Collections.singletonList(new JsonViewResponseBodyAdvice()));
		}

		AsyncSupportConfigurer configurer = getAsyncSupportConfigurer();
		if (configurer.getTaskExecutor() != null) {
			adapter.setTaskExecutor(configurer.getTaskExecutor());
		}
		if (configurer.getTimeout() != null) {
			adapter.setAsyncRequestTimeout(configurer.getTimeout());
		}
		adapter.setCallableInterceptors(configurer.getCallableInterceptors());
		adapter.setDeferredResultInterceptors(configurer.getDeferredResultInterceptors());

		return adapter;
	}","/**
	 * Returns a {@link RequestMappingHandlerAdapter} for processing requests
	 * through annotated controller methods. Consider overriding one of these
	 * other more fine-grained methods:
	 * <ul>
	 * <li>{@link #addArgumentResolvers} for adding custom argument resolvers.
	 * <li>{@link #addReturnValueHandlers} for adding custom return value handlers.
	 * <li>{@link #configureMessageConverters} for adding custom message converters.
	 * </ul>
	 */",67087d9d82a3a5339cc3dc4d
"public void setRequiredType(Class<T> requiredType) {
		this.requiredType = ClassUtils.resolvePrimitiveIfNecessary(requiredType);
	}","/**
	 * Set the type that each result object is expected to match.
	 * <p>If not specified, the column value will be exposed as
	 * returned by the JDBC driver.
	 */",67087d9d82a3a5339cc3dc4e
"int acquireRead() {
        long transformed = spinTransform(NO_WRITE_LOCK, ACQUIRE_READ_LOCK, false, false);
        return toIntExact(transformed & READ_LOCK_MASK);
    }","/**
     * Blocking call.
     * @return the read lock count this resulted in, > 0 if successful, otherwise 0 meaning that an acquisition on a dead lock was attempted.
     */",67087d9d82a3a5339cc3dc4f
"public boolean alterIndex (int index, K after) {
		if (index < 0 || index >= size || containsKey(after)) return false;
		super.put(after, super.remove(keys.get(index)));
		keys.set(index, after);
		return true;
	}","/** Changes the key at the given {@code index} in the order to {@code after}, without changing the ordering of other entries or
	 * any values. If {@code after} is already present, this returns false; it will also return false if {@code index} is invalid
	 * for the size of this map. Otherwise, it returns true. Unlike {@link #alter(Object, Object)}, this operates in constant time.
	 * @param index the index in the order of the key to change; must be non-negative and less than {@link #size}
	 * @param after the key that will replace the contents at {@code index}; this key must not be present for this to succeed
	 * @return true if {@code after} successfully replaced the key at {@code index}, false otherwise */",67087d9d82a3a5339cc3dc50
"private PlannerResult planWithBindableConvention()
  {
    CalcitePlanner planner = handlerContext.planner();
    BindableRel bindableRel = (BindableRel) planner.transform(
        CalciteRulesManager.BINDABLE_CONVENTION_RULES,
        planner.getEmptyTraitSet().replace(BindableConvention.INSTANCE).plus(rootQueryRel.collation),
        rootQueryRel.rel
    );

    if (!rootQueryRel.isRefTrivial()) {
      // Add a projection on top to accommodate root.fields.
      final List<RexNode> projects = new ArrayList<>();
      final RexBuilder rexBuilder = bindableRel.getCluster().getRexBuilder();
      for (int field : Pair.left(rootQueryRel.fields)) {
        projects.add(rexBuilder.makeInputRef(bindableRel, field));
      }
      bindableRel = new Bindables.BindableProject(
          bindableRel.getCluster(),
          bindableRel.getTraitSet(),
          bindableRel,
          projects,
          rootQueryRel.validatedRowType
      );
    }

    handlerContext.hook().captureBindableRel(bindableRel);
    PlannerContext plannerContext = handlerContext.plannerContext();
    if (explain != null) {
      return planExplanation(rootQueryRel, bindableRel, false);
    } else {
      final BindableRel theRel = bindableRel;
      final DataContext dataContext = plannerContext.createDataContext(
          planner.getTypeFactory(),
          plannerContext.getParameters()
      );
      final Supplier<QueryResponse<Object[]>> resultsSupplier = () -> {
        final Enumerable<?> enumerable = theRel.bind(dataContext);
        final Enumerator<?> enumerator = enumerable.enumerator();
        return QueryResponse.withEmptyContext(
            Sequences.withBaggage(new BaseSequence<>(
                new BaseSequence.IteratorMaker<Object[], QueryHandler.EnumeratorIterator<Object[]>>()
                {
                  @Override
                  public QueryHandler.EnumeratorIterator<Object[]> make()
                  {
                    return new QueryHandler.EnumeratorIterator<>(new Iterator<Object[]>()
                    {
                      @Override
                      public boolean hasNext()
                      {
                        return enumerator.moveNext();
                      }

                      @Override
                      public Object[] next()
                      {
                        return (Object[]) enumerator.current();
                      }
                    });
                  }

                  @Override
                  public void cleanup(QueryHandler.EnumeratorIterator<Object[]> iterFromMake)
                  {

                  }
                }
            ), enumerator::close)
        );
      };
      return new PlannerResult(resultsSupplier, rootQueryRel.validatedRowType);
    }
  }","/**
   * Construct a {@link PlannerResult} for a fall-back 'bindable' rel, for
   * things that are not directly translatable to native Druid queries such
   * as system tables and just a general purpose (but definitely not optimized)
   * fall-back.
   * <p>
   * See {@link #planWithDruidConvention} which will handle things which are
   * directly translatable to native Druid queries.
   * <p>
   * The bindable path handles parameter substitution of any values not
   * bound by the earlier steps.
   */",67087d9d82a3a5339cc3dc51
"protected void checkCompiled() {
		if (!isCompiled()) {
			logger.debug(""JdbcCall call not compiled before execution - invoking compile"");
			compile();
		}
	}","/**
	 * Check whether this operation has been compiled already;
	 * lazily compile it if not already compiled.
	 * <p>Automatically called by all {@code doExecute(...)} methods.
	 */",67087d9d82a3a5339cc3dc52
"public static TransformConfigVersion randomVersion(Set<TransformConfigVersion> ignore) {
        return ESTestCase.randomFrom(ALL_VERSIONS.stream().filter(v -> ignore.contains(v) == false).collect(Collectors.toList()));
    }",/** Returns a random {@link TransformConfigVersion} from all available versions without the ignore set */,67087d9d82a3a5339cc3dc53
"private static int getNetMask(String netMask) {
        StringTokenizer nm = new StringTokenizer(netMask, ""."");
        int i = 0;
        int[] netmask = new int[4];
        while (nm.hasMoreTokens()) {
            netmask[i] = Integer.parseInt(nm.nextToken());
            i++;
        }
        int mask1 = 0;
        for (i = 0; i < 4; i++) {
            mask1 += Integer.bitCount(netmask[i]);
        }
        return mask1;
    }","/**
     * Get the Subnet's Netmask in Decimal format.<BR>
     * i.e.: getNetMask(""255.255.255.0"") returns the integer CIDR mask
     *
     * @param netMask a network mask
     * @return the integer CIDR mask
     */",67087d9d82a3a5339cc3dc54
"private static String encodeToString(final byte[] outToken) {
        if (outToken != null && outToken.length > 0) {
            return Base64.getEncoder().encodeToString(outToken);
        }
        return null;
    }","/**
     * Encodes the specified byte array using base64 encoding scheme
     *
     * @param outToken byte array to be encoded
     * @return String containing base64 encoded characters. returns {@code null} if
     *         outToken is null or empty.
     */",67087d9d82a3a5339cc3dc55
"public Object newInstance () throws NoSuchMethodException {
		return getConstructor().newInstance();
	}",/** @return a new instance of this type created via the default constructor which must be public. */,67087d9d82a3a5339cc3dc56
"public PartOfSpeech getPartOfSpeech(String word) {
        if (word.length() > maxDictionaryWordLength) {
            return PartOfSpeech.NOT_IN_DICTIONARY;
        }
        // This is quite slow as it creates a new string for every lookup. However, experiments show
        // that trying to do case-insensitive comparisons instead of creating a lower case string is
        // even slower.
        return partOfSpeechDictionary.getOrDefault(word.toLowerCase(Locale.ROOT), PartOfSpeech.NOT_IN_DICTIONARY);
    }","/**
     * Find the part of speech (noun, verb, adjective, etc.) for a supplied word.
     * @return Which part of speech does the supplied word represent? {@link PartOfSpeech#NOT_IN_DICTIONARY} is returned
     *         for words that aren't in the dictionary at all.
     */",67087d9d82a3a5339cc3dc57
"static public <T> T obtain (Class<T> type) {
		return get(type).obtain();
	}",/** Obtains an object from the {@link #get(Class) pool}. */,67087d9d82a3a5339cc3dc58
"public static XContentBuilder contentBuilder() throws IOException {
        return provider.getContentBuilder();
    }","/**
     * Returns a {@link XContentBuilder} for building JSON XContent.
     */",67087d9d82a3a5339cc3dc59
"void updateClientStats(final HttpRequest httpRequest, final HttpChannel httpChannel) {
        if (clientStatsEnabled && httpChannel != null) {
            final ClientStatsBuilder clientStats = httpChannelStats.get(httpChannel);
            if (clientStats != null) {
                clientStats.update(httpRequest, httpChannel, threadPool.absoluteTimeInMillis());
            }
        }
    }","/**
     * Adjust the stats for the given channel to reflect the latest request received.
     */",67087d9d82a3a5339cc3dc5a
"public void setMisfireInstructionName(String constantName) {
		Assert.hasText(constantName, ""'constantName' must not be null or blank"");
		Integer misfireInstruction = constants.get(constantName);
		Assert.notNull(misfireInstruction, ""Only misfire instruction constants allowed"");
		this.misfireInstruction = misfireInstruction;
	}","/**
	 * Set the misfire instruction for this trigger via the name of the corresponding
	 * constant in the {@link org.quartz.Trigger} and {@link org.quartz.SimpleTrigger}
	 * classes.
	 * <p>Default is {@code MISFIRE_INSTRUCTION_SMART_POLICY}.
	 * @see org.quartz.Trigger#MISFIRE_INSTRUCTION_SMART_POLICY
	 * @see org.quartz.Trigger#MISFIRE_INSTRUCTION_IGNORE_MISFIRE_POLICY
	 * @see org.quartz.SimpleTrigger#MISFIRE_INSTRUCTION_FIRE_NOW
	 * @see org.quartz.SimpleTrigger#MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_EXISTING_COUNT
	 * @see org.quartz.SimpleTrigger#MISFIRE_INSTRUCTION_RESCHEDULE_NEXT_WITH_REMAINING_COUNT
	 * @see org.quartz.SimpleTrigger#MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_EXISTING_REPEAT_COUNT
	 * @see org.quartz.SimpleTrigger#MISFIRE_INSTRUCTION_RESCHEDULE_NOW_WITH_REMAINING_REPEAT_COUNT
	 */",67087d9d82a3a5339cc3dc5b
"static Flux<FilePartEvent> create(String partName, String filename, MediaType contentType,
			Flux<DataBuffer> contents) {

		return create(partName, filename, contentType, contents, null);
	}","/**
	 * Creates a stream of {@code FilePartEvent} objects based on the given
	 * {@linkplain PartEvent#name() name}, {@linkplain #filename()},
	 * content-type, and contents.
	 * @param partName the name of the part
	 * @param filename the filename
	 * @param contentType the content-type for the contents
	 * @param contents the contents
	 * @return a stream of events
	 */",67087d9d82a3a5339cc3dc5c
"public static void close(@Nullable Closeable closeable) throws IOException {
        if (closeable != null) {
            closeable.close();
        }
    }","/**
     * @see #close(Closeable...)
     */",67087d9d82a3a5339cc3dc5d
"public static String getConstructorDescriptor(final Constructor<?> constructor) {
    StringBuilder stringBuilder = new StringBuilder();
    stringBuilder.append('(');
    Class<?>[] parameters = constructor.getParameterTypes();
    for (Class<?> parameter : parameters) {
      appendDescriptor(parameter, stringBuilder);
    }
    return stringBuilder.append("")V"").toString();
  }","/**
   * Returns the descriptor corresponding to the given constructor.
   *
   * @param constructor a {@link Constructor} object.
   * @return the descriptor of the given constructor.
   */",67087d9d82a3a5339cc3dc5e
"private static String readString(String fieldName, ByteBuf in) {
        int length = in.bytesBefore(MAX_FIELD_LENGTH + 1, (byte) 0);
        if (length < 0) {
            throw new DecoderException(""field '"" + fieldName + ""' longer than "" + MAX_FIELD_LENGTH + "" chars"");
        }

        String value = in.readSlice(length).toString(CharsetUtil.US_ASCII);
        in.skipBytes(1); // Skip the NUL.

        return value;
    }","/**
     * Reads a variable-length NUL-terminated string as defined in SOCKS4.
     */",67087d9d82a3a5339cc3dc5f
"public void nextPage() {
		if (!isLastPage()) {
			this.page++;
		}
	}","/**
	 * Switch to next page.
	 * Will stay on last page if already on last page.
	 */",67087d9d82a3a5339cc3dc60
"private static void logCCSError(ShardSearchFailure f, String clusterAlias, boolean skipUnavailable) {
        String errorInfo;
        try {
            errorInfo = Strings.toString(f.toXContent(XContentFactory.jsonBuilder(), ToXContent.EMPTY_PARAMS));
        } catch (IOException ex) {
            // use the toString as a fallback if for some reason the XContent conversion to JSON fails
            errorInfo = f.toString();
        }
        logger.debug(
            ""CCS remote cluster failure. Cluster [{}]. skip_unavailable: [{}]. Error: {}"",
            clusterAlias,
            skipUnavailable,
            errorInfo
        );
    }","/**
     * In order to gather data on what types of CCS errors happen in the field, we will log
     * them using the ShardSearchFailure XContent (JSON), which supplies information about underlying
     * causes of shard failures.
     * @param f ShardSearchFailure to log
     * @param clusterAlias cluster on which the failure occurred
     * @param skipUnavailable the skip_unavailable setting of the cluster with the search error
     */",67087d9d82a3a5339cc3dc61
"@SuppressWarnings(""unchecked"")
    public <T> T[] selection(T[] among, int min, int max, boolean allowDuplicates) {
        assert min <= max;
        int diff = min == max ? 0 : generator.nextInt(max - min);
        int length = min + diff;
        assert allowDuplicates || length <= among.length
                : ""Unique selection of "" + length + "" items cannot possibly be created from "" + among.length + "" items"";
        T[] result = (T[]) Array.newInstance(among.getClass().getComponentType(), length);
        for (int i = 0; i < length; i++) {
            while (true) {
                T candidate = among(among);
                if (!allowDuplicates && ArrayUtils.contains(result, candidate)) { // Try again
                    continue;
                }
                result[i] = candidate;
                break;
            }
        }
        return result;
    }","/**
     * Returns a random selection of the provided array.
     *
     * @param among the array to pick elements from
     * @param min the minimum number of elements to choose
     * @param max the maximum number of elements to choose
     * @param allowDuplicates if {@code true} the same element can be chosen multiple times
     * @return a random selection of the provided array.
     */",67087d9d82a3a5339cc3dc62
"@Override
  public Block evalNullable(Block fieldVal) {
    if (fieldVal.mvSortedAscending()) {
      return evalAscendingNullable(fieldVal);
    }
    BooleanBlock v = (BooleanBlock) fieldVal;
    int positionCount = v.getPositionCount();
    try (BooleanBlock.Builder builder = driverContext.blockFactory().newBooleanBlockBuilder(positionCount)) {
      for (int p = 0; p < positionCount; p++) {
        int valueCount = v.getValueCount(p);
        if (valueCount == 0) {
          builder.appendNull();
          continue;
        }
        int first = v.getFirstValueIndex(p);
        int end = first + valueCount;
        boolean value = v.getBoolean(first);
        for (int i = first + 1; i < end; i++) {
          boolean next = v.getBoolean(i);
          value = MvMax.process(value, next);
        }
        boolean result = value;
        builder.appendBoolean(result);
      }
      return builder.build();
    }
  }","/**
   * Evaluate blocks containing at least one multivalued field.
   */",67087d9d82a3a5339cc3dc63
"@Nullable
	public Destination getDestination() {
		return (Destination) getHeader(JmsHeaders.DESTINATION);
	}","/**
	 * Return the {@link JmsHeaders#DESTINATION destination}.
	 * @see JmsHeaders#DESTINATION
	 */",67087d9d82a3a5339cc3dc64
"@WorkerThread
  public static boolean setActiveShortcuts(@NonNull Context context, @NonNull List<Recipient> rankedRecipients) {
    if (ShortcutManagerCompat.isRateLimitingActive(context)) {
      return false;
    }

    int maxShortcuts = ShortcutManagerCompat.getMaxShortcutCountPerActivity(context);

    if (rankedRecipients.size() > maxShortcuts) {
      Log.w(TAG, ""Too many recipients provided! Provided: "" + rankedRecipients.size() + "", Max: "" + maxShortcuts);
      rankedRecipients = rankedRecipients.subList(0, maxShortcuts);
    }

    List<ShortcutInfoCompat> shortcuts = new ArrayList<>(rankedRecipients.size());

    ComponentName activityName = new AppIconUtility(context).currentAppIconComponentName();

    for (int i = 0; i < rankedRecipients.size(); i++) {
      ShortcutInfoCompat info = buildShortcutInfo(context, activityName, rankedRecipients.get(i), i, Direction.NONE);
      shortcuts.add(info);
    }

    return ShortcutManagerCompat.setDynamicShortcuts(context, shortcuts);
  }","/**
   * Sets the shortcuts to match the provided recipient list. This call may fail due to getting
   * rate-limited.
   *
   * @param rankedRecipients The recipients in descending priority order. Meaning the most important
   *                         recipient should be first in the list.
   * @return True if the update was successful, false if we were rate-limited.
   */",67087d9d82a3a5339cc3dc65
"public static ResolvableType forClassWithGenerics(Class<?> clazz, Class<?>... generics) {
		Assert.notNull(clazz, ""Class must not be null"");
		Assert.notNull(generics, ""Generics array must not be null"");
		ResolvableType[] resolvableGenerics = new ResolvableType[generics.length];
		for (int i = 0; i < generics.length; i++) {
			resolvableGenerics[i] = forClass(generics[i]);
		}
		return forClassWithGenerics(clazz, resolvableGenerics);
	}","/**
	 * Return a {@code ResolvableType} for the specified {@link Class} with pre-declared generics.
	 * @param clazz the class (or interface) to introspect
	 * @param generics the generics of the class
	 * @return a {@code ResolvableType} for the specific class and generics
	 * @see #forClassWithGenerics(Class, ResolvableType...)
	 */",67087d9d82a3a5339cc3dc66
"static LayerArchiveFactory create(ImageReference reference, Path tarFile) throws IOException {
			try (TarArchiveInputStream tar = openTar(tarFile)) {
				ImageArchiveIndex index = null;
				ImageArchiveManifest manifest = null;
				TarArchiveEntry entry = tar.getNextEntry();
				while (entry != null) {
					if (""index.json"".equals(entry.getName())) {
						index = ImageArchiveIndex.of(tar);
						break;
					}
					if (""manifest.json"".equals(entry.getName())) {
						manifest = ImageArchiveManifest.of(tar);
					}
					entry = tar.getNextEntry();
				}
				Assert.state(index != null || manifest != null,
						""Exported image '%s' does not contain 'index.json' or 'manifest.json'"".formatted(reference));
				return (index != null) ? new IndexLayerArchiveFactory(tarFile, index)
						: new ManifestLayerArchiveFactory(tarFile, manifest);
			}
		}","/**
		 * Create a new {@link LayerArchiveFactory} for the given tar file using either
		 * the {@code index.json} or {@code manifest.json} to detect layers.
		 * @param reference the image that was referenced
		 * @param tarFile the source tar file
		 * @return a new {@link LayerArchiveFactory} instance
		 * @throws IOException on IO error
		 */",67087d9d82a3a5339cc3dc67
"@SuppressWarnings(""deprecation"")  // for Locale constructors on JDK 19
	@Nullable
	public static Locale parseLocaleString(String localeString) {
		if (localeString.isEmpty()) {
			return null;
		}

		String delimiter = ""_"";
		if (!localeString.contains(""_"") && localeString.contains("" "")) {
			delimiter = "" "";
		}

		String[] tokens = localeString.split(delimiter, -1);
		if (tokens.length == 1) {
			String language = tokens[0];
			validateLocalePart(language);
			return new Locale(language);
		}
		else if (tokens.length == 2) {
			String language = tokens[0];
			validateLocalePart(language);
			String country = tokens[1];
			validateLocalePart(country);
			return new Locale(language, country);
		}
		else if (tokens.length > 2) {
			String language = tokens[0];
			validateLocalePart(language);
			String country = tokens[1];
			validateLocalePart(country);
			String variant = Arrays.stream(tokens).skip(2).collect(Collectors.joining(delimiter));
			return new Locale(language, country, variant);
		}

		throw new IllegalArgumentException(""Invalid locale format: '"" + localeString + ""'"");
	}","/**
	 * Parse the given {@code String} representation into a {@link Locale}.
	 * <p>For many parsing scenarios, this is an inverse operation of
	 * {@link Locale#toString Locale's toString}, in a lenient sense.
	 * This method does not aim for strict {@code Locale} design compliance;
	 * it is rather specifically tailored for typical Spring parsing needs.
	 * <p><b>Note: This delegate does not accept the BCP 47 language tag format.
	 * Please use {@link #parseLocale} for lenient parsing of both formats.</b>
	 * @param localeString the locale {@code String}: following {@code Locale's}
	 * {@code toString()} format (""en"", ""en_UK"", etc.), also accepting spaces as
	 * separators (as an alternative to underscores)
	 * @return a corresponding {@code Locale} instance, or {@code null} if none
	 * @throws IllegalArgumentException in case of an invalid locale specification
	 */",67087d9d82a3a5339cc3dc68
"public void updateChildren () {
			if (!expanded) return;
			Tree tree = getTree();
			if (tree == null) return;
			Object[] children = this.children.items;
			int n = this.children.size;
			int actorIndex = actor.getZIndex() + 1;
			for (int i = 0; i < n; i++)
				((N)children[i]).removeFromTree(tree, actorIndex);
			for (int i = 0; i < n; i++)
				actorIndex += ((N)children[i]).addToTree(tree, actorIndex);
		}","/** Updates the order of the actors in the tree for this node and all child nodes. This is useful after changing the order
		 * of {@link #getChildren()}.
		 * @see Tree#updateRootNodes() */",67087d9d82a3a5339cc3dc69
"public void closeAll() {
		for (Session session : this.sessions) {
			try {
				session.close();
			}
			catch (Throwable ex) {
				logger.debug(""Could not close synchronized JMS Session after transaction"", ex);
			}
		}
		for (Connection con : this.connections) {
			ConnectionFactoryUtils.releaseConnection(con, this.connectionFactory, true);
		}
		this.connections.clear();
		this.sessions.clear();
		this.sessionsPerConnection.clear();
	}","/**
	 * Close all of this resource holder's Sessions and clear its state.
	 * @see Session#close()
	 */",67087d9d82a3a5339cc3dc6a
"private static boolean isTestEnabledInThisEnvironment(ProfileValueSource profileValueSource,
			@Nullable IfProfileValue ifProfileValue) {

		if (ifProfileValue == null) {
			return true;
		}

		String environmentValue = profileValueSource.get(ifProfileValue.name());
		String[] annotatedValues = ifProfileValue.values();
		if (StringUtils.hasLength(ifProfileValue.value())) {
			Assert.isTrue(annotatedValues.length == 0, ""Setting both the 'value' and 'values' attributes "" +
						""of @IfProfileValue is not allowed: choose one or the other."");
			annotatedValues = new String[] { ifProfileValue.value() };
		}

		for (String value : annotatedValues) {
			if (ObjectUtils.nullSafeEquals(value, environmentValue)) {
				return true;
			}
		}
		return false;
	}","/**
	 * Determine if the {@code value} (or one of the {@code values})
	 * in the supplied {@link IfProfileValue &#064;IfProfileValue} annotation is
	 * <em>enabled</em> in the current environment.
	 * @param profileValueSource the ProfileValueSource to use to determine if
	 * the test is enabled
	 * @param ifProfileValue the annotation to introspect; may be
	 * {@code null}
	 * @return {@code true} if the test is <em>enabled</em> in the current
	 * environment or if the supplied {@code ifProfileValue} is
	 * {@code null}
	 */",67087d9d82a3a5339cc3dc6b
"protected final void releaseSharedConnection() {
		this.sharedConnectionLock.lock();
		try {
			ConnectionFactoryUtils.releaseConnection(
					this.sharedConnection, getConnectionFactory(), this.sharedConnectionStarted);
			this.sharedConnection = null;
		}
		finally {
			this.sharedConnectionLock.unlock();
		}
	}","/**
	 * Release the shared Connection, if any.
	 * @since 6.1
	 * @see ConnectionFactoryUtils#releaseConnection
	 */",67087d9d82a3a5339cc3dc6c
"public float dst (GridPoint2 other) {
		int xd = other.x - x;
		int yd = other.y - y;

		return (float)Math.sqrt(xd * xd + yd * yd);
	}","/** @param other The other point
	 * @return the distance between this point and the other vector. */",67087d9d82a3a5339cc3dc6d
"LatLng geoAzDistanceRads(double az, double distance) {
        // algorithm from the original H3 library
        az = Vec2d.posAngleRads(az);
        final double sinDistance = FastMath.sin(distance);
        final double cosDistance = FastMath.cos(distance);
        final double sinP1Lat = FastMath.sin(getLatRad());
        final double cosP1Lat = FastMath.cos(getLatRad());
        final double sinlat = Math.max(-1.0, Math.min(1.0, sinP1Lat * cosDistance + cosP1Lat * sinDistance * FastMath.cos(az)));
        final double lat = FastMath.asin(sinlat);
        if (Math.abs(lat - M_PI_2) < Constants.EPSILON) { // north pole
            return new LatLng(M_PI_2, 0.0);
        } else if (Math.abs(lat + M_PI_2) < Constants.EPSILON) { // south pole
            return new LatLng(-M_PI_2, 0.0);
        } else {
            final double cosLat = FastMath.cos(lat);
            final double sinlng = Math.max(-1.0, Math.min(1.0, FastMath.sin(az) * sinDistance / cosLat));
            final double coslng = Math.max(-1.0, Math.min(1.0, (cosDistance - sinP1Lat * FastMath.sin(lat)) / cosP1Lat / cosLat));
            return new LatLng(lat, constrainLng(getLonRad() + FastMath.atan2(sinlng, coslng)));
        }
    }","/**
     * Computes the point on the sphere with a specified azimuth and distance from
     * this point.
     *
     * @param az       The desired azimuth.
     * @param distance The desired distance.
     * @return The LatLng point.
     */",67087d9d82a3a5339cc3dc6e
"public float[] setSize (int newSize) {
		if (newSize < 0) throw new IllegalArgumentException(""newSize must be >= 0: "" + newSize);
		if (newSize > items.length) resize(Math.max(8, newSize));
		size = newSize;
		return items;
	}","/** Sets the array size, leaving any values beyond the current size undefined.
	 * @return {@link #items} */",67087d9d82a3a5339cc3dc6f
"public void testUseClassicPullParsingSubParser() throws IOException {
        class ClassicParser {
            URI parseURI(XContentParser parser) throws IOException {
                String fieldName = null;
                String host = """";
                int port = 0;
                XContentParser.Token token;
                while ((token = parser.currentToken()) != XContentParser.Token.END_OBJECT) {
                    if (token == XContentParser.Token.FIELD_NAME) {
                        fieldName = parser.currentName();
                    } else if (token == XContentParser.Token.VALUE_STRING) {
                        if (fieldName.equals(""host"")) {
                            host = parser.text();
                        } else {
                            throw new IllegalStateException(""boom"");
                        }
                    } else if (token == XContentParser.Token.VALUE_NUMBER) {
                        if (fieldName.equals(""port"")) {
                            port = parser.intValue();
                        } else {
                            throw new IllegalStateException(""boom"");
                        }
                    }
                    parser.nextToken();
                }
                return URI.create(host + "":"" + port);
            }
        }
        class Foo {
            public String name;
            public URI uri;

            public void setName(String name) {
                this.name = name;
            }

            public void setUri(URI uri) {
                this.uri = uri;
            }
        }

        class CustomParseContext {

            public final ClassicParser parser;

            CustomParseContext(ClassicParser parser) {
                this.parser = parser;
            }

            public URI parseURI(XContentParser xContentParser) {
                try {
                    return this.parser.parseURI(xContentParser);
                } catch (IOException e) {
                    throw new UncheckedIOException(e);
                }
            }
        }
        XContentParser parser = createParser(JsonXContent.jsonXContent, """"""
            {""url"" : { ""host"": ""http://foobar"", ""port"" : 80}, ""name"" : ""foobarbaz""}"""""");
        ObjectParser<Foo, CustomParseContext> objectParser = new ObjectParser<>(""foo"");
        objectParser.declareString(Foo::setName, new ParseField(""name""));
        objectParser.declareObjectOrDefault(Foo::setUri, (p, s) -> s.parseURI(p), () -> null, new ParseField(""url""));
        Foo s = objectParser.parse(parser, new Foo(), new CustomParseContext(new ClassicParser()));
        assertEquals(s.uri.getHost(), ""foobar"");
        assertEquals(s.uri.getPort(), 80);
        assertEquals(s.name, ""foobarbaz"");
    }","/**
     * This test ensures we can use a classic pull-parsing parser
     * together with the object parser
     */",67087d9d82a3a5339cc3dc70
"public static boolean isPrimitiveWrapper(Class<?> clazz) {
		Assert.notNull(clazz, ""Class must not be null"");
		return primitiveWrapperTypeMap.containsKey(clazz);
	}","/**
	 * Check if the given class represents a primitive wrapper,
	 * i.e. Boolean, Byte, Character, Short, Integer, Long, Float, Double, or
	 * Void.
	 * @param clazz the class to check
	 * @return whether the given class is a primitive wrapper class
	 */",67087d9d82a3a5339cc3dc71
"@Override
    public DispatchQuery createDispatchQuery(
            Session session,
            AnalyzerProvider analyzerProvider,
            String query,
            PreparedQuery preparedQuery,
            String slug,
            int retryCount,
            ResourceGroupId resourceGroup,
            Optional<QueryType> queryType,
            WarningCollector warningCollector,
            Consumer<DispatchQuery> queryQueuer)
    {
        QueryStateMachine stateMachine = QueryStateMachine.begin(
                query,
                preparedQuery.getPrepareSql(),
                session,
                locationFactory.createQueryLocation(session.getQueryId()),
                resourceGroup,
                queryType,
                preparedQuery.isTransactionControlStatement(),
                transactionManager,
                accessControl,
                executor,
                metadata,
                warningCollector);

        stateMachine.addStateChangeListener(new QueryStateTracingListener(stateMachine.getSession().getTracer().orElse(NoopTracerProvider.NOOP_TRACER)));
        queryMonitor.queryCreatedEvent(stateMachine.getBasicQueryInfo(Optional.empty()));

        ListenableFuture<QueryExecution> queryExecutionFuture = executor.submit(() -> {
            QueryExecutionFactory<?> queryExecutionFactory = executionFactoriesManager.getExecutionFactory(preparedQuery);
            if (queryExecutionFactory == null) {
                throw new PrestoException(NOT_SUPPORTED, ""Unsupported statement type: "" + preparedQuery.getStatementClass().getSimpleName());
            }

            return queryExecutionFactory.createQueryExecution(analyzerProvider, preparedQuery, stateMachine, slug, retryCount, warningCollector, queryType);
        });

        return new LocalDispatchQuery(
                stateMachine,
                queryMonitor,
                queryExecutionFuture,
                clusterSizeMonitor,
                executor,
                queryQueuer,
                queryManager::createQuery,
                retryCount > 0,
                queryPrerequisitesManager);
    }","/**
     *  This method instantiates a new dispatch query object as part of preparing phase for pre-query execution.
     *
     *  The dispatch query is submitted to the {@link ResourceGroupManager} which enqueues the query.
     *  The event of creating the dispatch query is logged after registering to the query tracker which is used to keep track of the state of the query.
     *  The log is done by adding a state change listener to the query.
     *  The state transition listener is useful to understand the state when a query has moved from created to running, running to error completed.
     *  Once dispatch query object is created and it's registered with the query tracker, start sending heard beat to indicate that this query is now running
     *  to the {@link ResourceGroupManager}. This is no-op for no disaggregated coordinator setup
     *
     * @param session the session
     * @param analyzerProvider the analyzer provider
     * @param query the query
     * @param preparedQuery the prepared query
     * @param slug the unique query slug for each {@code Query} object
     * @param retryCount the query retry count
     * @param resourceGroup the resource group to be used
     * @param queryType the query type derived from the {@code PreparedQuery statement}
     * @param warningCollector the warning collector
     * @param queryQueuer the query queuer is invoked when a query is to submit to the {@link com.facebook.presto.execution.resourceGroups.ResourceGroupManager}
     * @return
     */",67087d9d82a3a5339cc3dc72
"public Color add (float r, float g, float b, float a) {
		this.r += r;
		this.g += g;
		this.b += b;
		this.a += a;
		return clamp();
	}","/** Adds the given color component values to this Color's values.
	 * 
	 * @param r Red component
	 * @param g Green component
	 * @param b Blue component
	 * @param a Alpha component
	 * 
	 * @return this Color for chaining */",67087d9d82a3a5339cc3dc73
"public static boolean isValidExpression(@Nullable String expression) {
		if (expression == null) {
			return false;
		}
		try {
			parse(expression);
			return true;
		}
		catch (IllegalArgumentException ex) {
			return false;
		}
	}","/**
	 * Determine whether the given string represents a valid cron expression.
	 * @param expression the expression to evaluate
	 * @return {@code true} if the given expression is a valid cron expression
	 * @since 5.3.8
	 */",67087d9d82a3a5339cc3dc74
"public void propagate(int lengthFromSource, int lengthToTarget) {
        int newLength = lengthFromSource + dataGraphLength();
        forwardNode.newPropagatedLengthFromSource(newLength, lengthToTarget - dataGraphLength());
        this.addSourceLength(newLength);
    }","/**
     * Propagate the length pair up to the forward node and register the new source length with the forward node
     */",67087d9d82a3a5339cc3dc75
"@Override
	public void set(String headerName, @Nullable String headerValue) {
		List<String> headerValues = new ArrayList<>(1);
		headerValues.add(headerValue);
		this.headers.put(headerName, headerValues);
	}","/**
	 * Set the given, single header value under the given name.
	 * @param headerName the header name
	 * @param headerValue the header value
	 * @throws UnsupportedOperationException if adding headers is not supported
	 * @see #put(String, List)
	 * @see #add(String, String)
	 */",67087d9d82a3a5339cc3dc76
"public List<DataSegment> getLoadingSegments()
  {
    final List<DataSegment> loadingSegments = new ArrayList<>();
    queuedSegments.forEach((segment, action) -> {
      if (action == SegmentAction.LOAD) {
        loadingSegments.add(segment);
      }
    });

    return loadingSegments;
  }","/**
   * Segments that are currently in the queue for being loaded on this server.
   * This does not include segments that are being moved to this server.
   */",67087d9d82a3a5339cc3dc77
"@Nullable
	public static String getSessionId(HttpServletRequest request) {
		Assert.notNull(request, ""Request must not be null"");
		HttpSession session = request.getSession(false);
		return (session != null ? session.getId() : null);
	}","/**
	 * Determine the session id of the given request, if any.
	 * @param request current HTTP request
	 * @return the session id, or {@code null} if none
	 */",67087d9d82a3a5339cc3dc78
"public synchronized int pendingCount() {
        List<Tuple<Translog.Location, Consumer<Boolean>>> locationListeners = locationRefreshListeners;
        List<Tuple<Long, ActionListener<Void>>> checkpointListeners = checkpointRefreshListeners;
        // A null list means we haven't accumulated any listeners. Otherwise, we need the size.
        return (locationListeners == null ? 0 : locationListeners.size()) + (checkpointListeners == null ? 0 : checkpointListeners.size());
    }","/**
     * The total number of pending listeners.
     */",67087d9d82a3a5339cc3dc79
"public CreateIndexRequestBuilder setWaitForActiveShards(ActiveShardCount waitForActiveShards) {
        request.waitForActiveShards(waitForActiveShards);
        return this;
    }","/**
     * Sets the number of shard copies that should be active for index creation to return.
     * Defaults to {@link ActiveShardCount#DEFAULT}, which will wait for one shard copy
     * (the primary) to become active. Set this value to {@link ActiveShardCount#ALL} to
     * wait for all shards (primary and all replicas) to be active before returning.
     * Otherwise, use {@link ActiveShardCount#from(int)} to set this value to any
     * non-negative integer, up to the number of copies per shard (number of replicas + 1),
     * to wait for the desired amount of shard copies to become active before returning.
     * Index creation will only wait up until the timeout value for the number of shard copies
     * to be active before returning.  Check {@link CreateIndexResponse#isShardsAcknowledged()} to
     * determine if the requisite shard copies were all started before returning or timing out.
     *
     * @param waitForActiveShards number of active shard copies to wait on
     */",67087d9d82a3a5339cc3dc7a
"@Nullable
	public T findObject(int p1, int p2, @Nullable Map<?, ?> context) throws DataAccessException {
		return findObject(new Object[] {p1, p2}, context);
	}","/**
	 * Convenient method to find a single object given two int parameters
	 * and a context.
	 */",67087d9d82a3a5339cc3dc7b
"public void add(long index, int value)
    {
        array[segment(index)][offset(index)] += value;
    }","/**
     * Adds the specified value to the specified element of this big array.
     *
     * @param index a position in this big array.
     * @param value the value
     */",67087d9d82a3a5339cc3dc7c
"@Test
  public void testAnotherAllocatePendingSegmentAfterRevertingCompaction()
  {
    String maxVersion = ""Z"";

    // 1.0) simulate one append load
    final PartialShardSpec partialShardSpec = NumberedPartialShardSpec.instance();
    final String dataSource = ""ds"";
    final Interval interval = Intervals.of(""2017-01-01/2017-02-01"");
    final SegmentIdWithShardSpec identifier = coordinator.allocatePendingSegment(
        dataSource,
        ""seq"",
        null,
        interval,
        partialShardSpec,
        ""A"",
        true,
        null
    );
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A"", identifier.toString());
    // Assume it publishes; create its corresponding segment
    DataSegment segment = new DataSegment(
        ""ds"",
        Intervals.of(""2017-01-01T00Z/2017-02-01T00Z""),
        ""A"",
        ImmutableMap.of(),
        ImmutableList.of(""dim1""),
        ImmutableList.of(""m1""),
        new LinearShardSpec(0),
        9,
        100
    );
    Assert.assertTrue(segmentSchemaTestUtils.insertUsedSegments(ImmutableSet.of(segment), Collections.emptyMap()));
    List<String> ids = retrieveUsedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A"", ids.get(0));


    // 1.1) simulate one more append load  (as if previous segment was published, note different sequence name)
    final SegmentIdWithShardSpec identifier1 = coordinator.allocatePendingSegment(
        dataSource,
        ""seq2"",
        identifier.toString(),
        interval,
        partialShardSpec,
        maxVersion,
        true,
        null
    );
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_1"", identifier1.toString());
    // Assume it publishes; create its corresponding segment
    segment = new DataSegment(
        ""ds"",
        Intervals.of(""2017-01-01T00Z/2017-02-01T00Z""),
        ""A"",
        ImmutableMap.of(),
        ImmutableList.of(""dim1""),
        ImmutableList.of(""m1""),
        new LinearShardSpec(1),
        9,
        100
    );
    Assert.assertTrue(segmentSchemaTestUtils.insertUsedSegments(ImmutableSet.of(segment), Collections.emptyMap()));
    ids = retrieveUsedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_1"", ids.get(1));


    // 1.2) simulate one more append load  (as if previous segment was published, note different sequence name)
    final SegmentIdWithShardSpec identifier2 = coordinator.allocatePendingSegment(
        dataSource,
        ""seq3"",
        identifier1.toString(),
        interval,
        partialShardSpec,
        maxVersion,
        true,
        null
    );
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_2"", identifier2.toString());
    // Assume it publishes; create its corresponding segment
    segment = new DataSegment(
        ""ds"",
        Intervals.of(""2017-01-01T00Z/2017-02-01T00Z""),
        ""A"",
        ImmutableMap.of(),
        ImmutableList.of(""dim1""),
        ImmutableList.of(""m1""),
        new LinearShardSpec(2),
        9,
        100
    );
    // state so far:
    // pendings: A: 0,1,2
    // used segments A: 0,1,2
    // unused segments:
    Assert.assertTrue(segmentSchemaTestUtils.insertUsedSegments(ImmutableSet.of(segment), Collections.emptyMap()));
    ids = retrieveUsedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_2"", ids.get(2));


    // 2)
    // now simulate that one compaction was done (batch) ingestion for same interval (like reindex of the previous three):
    DataSegment compactedSegment = new DataSegment(
        ""ds"",
        Intervals.of(""2017-01-01T00Z/2017-02-01T00Z""),
        ""B"",
        ImmutableMap.of(),
        ImmutableList.of(""dim1""),
        ImmutableList.of(""m1""),
        new LinearShardSpec(0),
        9,
        100
    );
    Assert.assertTrue(segmentSchemaTestUtils.insertUsedSegments(ImmutableSet.of(compactedSegment), Collections.emptyMap()));
    ids = retrieveUsedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_B"", ids.get(3));
    // 3) When overshadowing, segments are still marked as ""used"" in the segments table
    // state so far:
    // pendings: A: 0,1,2
    // used segments: A: 0,1,2; B: 0 <- new compacted segment, overshadows previous version A
    // unused segment:

    // 4) pending segment of version = B, id = 1 <= appending new data, aborted
    final SegmentIdWithShardSpec identifier3 = coordinator.allocatePendingSegment(
        dataSource,
        ""seq4"",
        identifier2.toString(),
        interval,
        partialShardSpec,
        maxVersion,
        true,
        null
    );
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_B_1"", identifier3.toString());
    // no corresponding segment, pending aborted
    // state so far:
    // pendings: A: 0,1,2; B:1 (note that B_1 does not make it into segments since its task aborted)
    // used segments: A: 0,1,2; B: 0 <-  compacted segment, overshadows previous version A
    // unused segment:

    // 5) reverted compaction (by marking B_0 as unused)
    // Revert compaction a manual metadata update which is basically the following two steps:
    markAllSegmentsUnused(ImmutableSet.of(compactedSegment), DateTimes.nowUtc()); // <- drop compacted segment
    //        pending: version = A, id = 0,1,2
    //                 version = B, id = 1
    //
    //        used segment: version = A, id = 0,1,2
    //        unused segment: version = B, id = 0
    List<String> pendings = retrievePendingSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(4, pendings.size());

    List<String> used = retrieveUsedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(3, used.size());

    List<String> unused = retrieveUnusedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(1, unused.size());

    // Simulate one more append load
    final SegmentIdWithShardSpec identifier4 = coordinator.allocatePendingSegment(
        dataSource,
        ""seq5"",
        identifier1.toString(),
        interval,
        partialShardSpec,
        maxVersion,
        true,
        null
    );
    // maxid = B_1 -> new partno = 2
    // versionofexistingchunk=A
    // ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_2
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_3"", identifier4.toString());
    // Assume it publishes; create its corresponding segment
    segment = new DataSegment(
        ""ds"",
        Intervals.of(""2017-01-01T00Z/2017-02-01T00Z""),
        ""A"",
        ImmutableMap.of(),
        ImmutableList.of(""dim1""),
        ImmutableList.of(""m1""),
        new LinearShardSpec(3),
        9,
        100
    );
    //        pending: version = A, id = 0,1,2,3
    //                 version = B, id = 1
    //
    //        used segment: version = A, id = 0,1,2,3
    //        unused segment: version = B, id = 0
    Assert.assertTrue(segmentSchemaTestUtils.insertUsedSegments(ImmutableSet.of(segment), Collections.emptyMap()));
    ids = retrieveUsedSegmentIds(derbyConnectorRule.metadataTablesConfigSupplier().get());
    Assert.assertEquals(""ds_2017-01-01T00:00:00.000Z_2017-02-01T00:00:00.000Z_A_3"", ids.get(3));

  }","/**
   * Slightly different from the above test that involves reverted compaction
   * 1) used segments of version = A, id = 0, 1, 2
   * 2) overwrote segments of version = B, id = 0 <= compaction
   * 3) marked segments unused for version = A, id = 0, 1, 2 <= overshadowing
   * 4) pending segment of version = B, id = 1 <= appending new data, aborted
   * 5) reverted compaction, mark segments used for version = A, id = 0, 1, 2, and mark compacted segments unused
   * 6) used segments of version = A, id = 0, 1, 2
   * 7) pending segment of version = B, id = 1
   */",67087d9d82a3a5339cc3dc7d
"@SuppressWarnings({""deprecation"", ""DataFlowIssue"", ""NullAway""})
	public static Publisher<?> invokeSuspendingFunction(
			CoroutineContext context, Method method, @Nullable Object target, @Nullable Object... args) {

		Assert.isTrue(KotlinDetector.isSuspendingFunction(method), ""Method must be a suspending function"");
		KFunction<?> function = ReflectJvmMapping.getKotlinFunction(method);
		Assert.notNull(function, () -> ""Failed to get Kotlin function for method: "" + method);
		if (!KCallablesJvm.isAccessible(function)) {
			KCallablesJvm.setAccessible(function, true);
		}
		Mono<Object> mono = MonoKt.mono(context, (scope, continuation) -> {
					Map<KParameter, Object> argMap = CollectionUtils.newHashMap(args.length + 1);
					int index = 0;
					for (KParameter parameter : function.getParameters()) {
						switch (parameter.getKind()) {
							case INSTANCE -> argMap.put(parameter, target);
							case VALUE, EXTENSION_RECEIVER -> {
								Object arg = args[index];
								if (!(parameter.isOptional() && arg == null)) {
									KType type = parameter.getType();
									if (!(type.isMarkedNullable() && arg == null) &&
											type.getClassifier() instanceof KClass<?> kClass &&
											KotlinDetector.isInlineClass(JvmClassMappingKt.getJavaClass(kClass))) {
										KFunction<?> constructor = KClasses.getPrimaryConstructor(kClass);
										if (!KCallablesJvm.isAccessible(constructor)) {
											KCallablesJvm.setAccessible(constructor, true);
										}
										arg = constructor.call(arg);
									}
									argMap.put(parameter, arg);
								}
								index++;
							}
						}
					}
					return KCallables.callSuspendBy(function, argMap, continuation);
				})
				.handle(CoroutinesUtils::handleResult)
				.onErrorMap(InvocationTargetException.class, InvocationTargetException::getTargetException);

		KType returnType = function.getReturnType();
		if (KTypes.isSubtypeOf(returnType, flowType)) {
			return mono.flatMapMany(CoroutinesUtils::asFlux);
		}
		if (KTypes.isSubtypeOf(returnType, publisherType)) {
			if (KTypes.isSubtypeOf(returnType, monoType)) {
				return mono.flatMap(o -> ((Mono<?>)o));
			}
			return mono.flatMapMany(o -> ((Publisher<?>)o));
		}
		return mono;
	}","/**
	 * Invoke a suspending function and convert it to {@link Mono} or
	 * {@link Flux}.
	 * @param context the coroutine context to use
	 * @param method the suspending function to invoke
	 * @param target the target to invoke {@code method} on
	 * @param args the function arguments. If the {@code Continuation} argument is specified as the last argument
	 * (typically {@code null}), it is ignored.
	 * @return the method invocation result as reactive stream
	 * @throws IllegalArgumentException if {@code method} is not a suspending function
	 * @since 6.0
	 */",67087d9d82a3a5339cc3dc7e
"@Nullable
	public static Integer getOrder(AnnotatedElement element) {
		return getOrderFromAnnotations(element, MergedAnnotations.from(element, SearchStrategy.TYPE_HIERARCHY));
	}","/**
	 * Return the order declared on the specified {@code element}.
	 * <p>Takes care of {@link Order @Order} and {@code @jakarta.annotation.Priority}.
	 * @param element the annotated element (e.g. type or method)
	 * @return the order value, or {@code null} if none can be found
	 * @since 5.3
	 */",67087d9d82a3a5339cc3dc7f
"default void accept(RouterFunctions.Visitor visitor) {
		visitor.unknown(this);
	}","/**
	 * Accept the given visitor. Default implementation calls
	 * {@link RouterFunctions.Visitor#unknown(RouterFunction)}; composed {@code RouterFunction}
	 * implementations are expected to call {@code accept} for all components that make up this
	 * router function.
	 * @param visitor the visitor to accept
	 */",67087d9d82a3a5339cc3dc80
"public OptionalLong allocatedSizeInBytes(Path path) {
        assert Files.isRegularFile(path) : path;
        final WString fileName = new WString(""\\\\?\\"" + path);
        final IntByReference lpFileSizeHigh = new IntByReference();

        final int lpFileSizeLow = GetCompressedFileSizeW(fileName, lpFileSizeHigh);
        if (lpFileSizeLow == INVALID_FILE_SIZE) {
            final int err = Native.getLastError();
            if (err != NO_ERROR) {
                logger.warn(""error [{}] when executing native method GetCompressedFileSizeW for file [{}]"", err, path);
                return OptionalLong.empty();
            }
        }

        // convert lpFileSizeLow to unsigned long and combine with signed/shifted lpFileSizeHigh
        final long allocatedSize = (((long) lpFileSizeHigh.getValue()) << Integer.SIZE) | Integer.toUnsignedLong(lpFileSizeLow);
        if (logger.isTraceEnabled()) {
            logger.trace(
                ""executing native method GetCompressedFileSizeW returned [high={}, low={}, allocated={}] for file [{}]"",
                lpFileSizeHigh,
                lpFileSizeLow,
                allocatedSize,
                path
            );
        }
        return OptionalLong.of(allocatedSize);
    }","/**
     * Retrieves the actual number of bytes of disk storage used to store a specified file. If the file is located on a volume that supports
     * compression and the file is compressed, the value obtained is the compressed size of the specified file. If the file is located on a
     * volume that supports sparse files and the file is a sparse file, the value obtained is the sparse size of the specified file.
     *
     * This method uses Win32 DLL native method {@link #GetCompressedFileSizeW(WString, IntByReference)}.
     *
     * @param path the path to the file
     * @return an {@link OptionalLong} that contains the number of allocated bytes on disk for the file, or empty if the size is invalid
     */",67087d9d82a3a5339cc3dc81
"private boolean isMoreToReadAfterReadingRecord(
      final SequenceOffsetType recordSequenceNumber,
      final SequenceOffsetType endSequenceNumber
  )
  {
    final int compareNextToEnd = createSequenceNumber(getNextStartOffset(recordSequenceNumber))
        .compareTo(createSequenceNumber(endSequenceNumber));

    // Unlike isMoreToReadBeforeReadingRecord, we don't care if the end is exclusive or not. If we read it, we're done.
    return compareNextToEnd < 0;
  }","/**
   * Returns true if, given that recordSequenceNumber has already been read and we want to end at endSequenceNumber,
   * there is more left to read. Used in post-read checks to determine if there is anything left to read.
   */",67087d9d82a3a5339cc3dc82
"public static RestClientBuilder builder(HttpHost... hosts) {
        if (hosts == null || hosts.length == 0) {
            throw new IllegalArgumentException(""hosts must not be null nor empty"");
        }
        List<Node> nodes = Arrays.stream(hosts).map(Node::new).collect(Collectors.toList());
        return new RestClientBuilder(nodes);
    }","/**
     * Returns a new {@link RestClientBuilder} to help with {@link RestClient} creation.
     * Creates a new builder instance and sets the nodes that the client will send requests to.
     * <p>
     * You can use this if you do not have metadata up front about the nodes. If you do, prefer
     * {@link #builder(Node...)}.
     * @see Node#Node(HttpHost)
     */",67087d9d82a3a5339cc3dc83
"private DruidCompactionConfig deleteConfigsForInactiveDatasources(
      DruidCompactionConfig current
  )
  {
    // If current compaction config is empty then there is nothing to do
    if (DruidCompactionConfig.empty().equals(current)) {
      log.info(""Nothing to do as compaction config is already empty."");
      return current;
    }

    // Get all active datasources
    // Note that we get all active datasources after getting compaction config to prevent race condition if new
    // datasource and config are added.
    Set<String> activeDatasources = sqlSegmentsMetadataManager.retrieveAllDataSourceNames();
    final Map<String, DataSourceCompactionConfig> updated = current
        .getCompactionConfigs()
        .stream()
        .filter(dataSourceCompactionConfig -> activeDatasources.contains(dataSourceCompactionConfig.getDataSource()))
        .collect(Collectors.toMap(DataSourceCompactionConfig::getDataSource, Function.identity()));

    return current.withDatasourceConfigs(ImmutableList.copyOf(updated.values()));
  }","/**
   * Creates a new compaction config by deleting entries for inactive datasources.
   */",67087d9d82a3a5339cc3dc84
"public static Mono<TransactionSynchronizationManager> forCurrentTransaction() {
		return TransactionContextManager.currentContext().map(TransactionSynchronizationManager::new);
	}","/**
	 * Get the {@link TransactionSynchronizationManager} that is associated with
	 * the current transaction context.
	 * <p>Mainly intended for code that wants to bind resources or synchronizations.
	 * @throws NoTransactionException if the transaction info cannot be found &mdash;
	 * for example, because the method was invoked outside a managed transaction
	 */",67087d9d82a3a5339cc3dc85
"@Test
	void testScenario_RegisteringJavaMethodsAsMethodHandlesAndCallingThem() throws Exception {
		// Create a parser
		SpelExpressionParser parser = new SpelExpressionParser();
		//this.context is already populated with all relevant MethodHandle examples

		Expression expr = parser.parseRaw(""#message('Message with %s words: <%s>', 2, 'Hello World', 'ignored')"");
		Object value = expr.getValue(this.context);
		assertThat(value).isEqualTo(""Message with 2 words: <Hello World>"");

		expr = parser.parseRaw(""#messageTemplate('bound', 2, 'Hello World', 'ignored')"");
		value = expr.getValue(this.context);
		assertThat(value).isEqualTo(""This is a bound message with 2 words: <Hello World>"");

		expr = parser.parseRaw(""#messageBound()"");
		value = expr.getValue(this.context);
		assertThat(value).isEqualTo(""This is a prerecorded message with 3 words: <Oh Hello World>"");

		Expression staticExpr = parser.parseRaw(""#messageStatic('Message with %s words: <%s>', 2, 'Hello World', 'ignored')"");
		Object staticValue = staticExpr.getValue(this.context);
		assertThat(staticValue).isEqualTo(""Message with 2 words: <Hello World>"");

		staticExpr = parser.parseRaw(""#messageStaticTemplate('bound', 2, 'Hello World', 'ignored')"");
		staticValue = staticExpr.getValue(this.context);
		assertThat(staticValue).isEqualTo(""This is a bound message with 2 words: <Hello World>"");

		staticExpr = parser.parseRaw(""#messageStaticBound()"");
		staticValue = staticExpr.getValue(this.context);
		assertThat(staticValue).isEqualTo(""This is a prerecorded message with 3 words: <Oh Hello World>"");
	}","/**
	 * Scenario: looking up your own MethodHandles and calling them from the expression
	 */",67087d9d82a3a5339cc3dc86
"public static void connectToNode(TransportService service, DiscoveryNode node, ConnectionProfile connectionProfile) {
        UnsafePlainActionFuture.get(fut -> service.connectToNode(node, connectionProfile, fut.map(x -> null)), ThreadPool.Names.GENERIC);
    }","/**
     * Connect to the specified node with the given connection profile
     *
     * @param service service to connect from
     * @param node the node to connect to
     * @param connectionProfile the connection profile to use when connecting to this node
     */",67087d9d82a3a5339cc3dc87
"protected static void registerClients(String... jsonBody) throws IOException {
        try (CloseableHttpClient httpClient = HttpClients.createDefault()) {
            String ci2dRegistrationUrl = c2id.getC2OPUrl() + ""/c2id/clients"";
            final BasicHttpContext context = new BasicHttpContext();
            final List<HttpPost> requests = new ArrayList<>(jsonBody.length);
            for (String body : jsonBody) {
                HttpPost httpPost = new HttpPost(ci2dRegistrationUrl);
                httpPost.setEntity(new StringEntity(body, ContentType.APPLICATION_JSON));
                httpPost.setHeader(""Accept"", ""application/json"");
                httpPost.setHeader(""Content-type"", ""application/json"");
                httpPost.setHeader(""Authorization"", ""Bearer "" + OP_API_BEARER_TOKEN);
                requests.add(httpPost);
            }

            SocketAccess.doPrivileged(() -> {
                for (HttpPost httpPost : requests) {
                    try (CloseableHttpResponse response = httpClient.execute(httpPost, context)) {
                        assertBusy(() -> assertThat(response.getStatusLine().getStatusCode(), equalTo(201)), 30, TimeUnit.SECONDS);
                    } catch (Exception e) {
                        fail(""Encountered exception while registering client: "" + e);
                    }
                }
            });
        }
    }","/**
     * Register one or more OIDC clients on the C2id server. This should be done once (per client) only.
     * C2id server only supports dynamic registration, so we can't pre-seed its config with our client data.
     */",67087d9d82a3a5339cc3dc88
"private static RubyClass setupLogstashClass(final RubyClass parent,
        final ObjectAllocator allocator, final Class<?> jclass) {
        final RubyClass clazz = RUBY.defineClassUnder(
            jclass.getAnnotation(JRubyClass.class).name()[0], parent, allocator, LOGSTASH_MODULE
        );
        clazz.defineAnnotatedMethods(jclass);
        return clazz;
    }","/**
     * Sets up a Java-defined {@link RubyClass} in the Logstash Ruby module.
     * @param parent Parent RubyClass
     * @param allocator Allocator of the class
     * @param jclass Underlying Java class that is annotated by {@link JRubyClass}
     * @return RubyClass
     */",67087d9d82a3a5339cc3dc89
"public static List<DocIdSeqNoAndSource> getDocIds(Engine engine, boolean refresh) throws IOException {
        if (refresh) {
            engine.refresh(""test_get_doc_ids"");
        }
        try (Engine.Searcher searcher = engine.acquireSearcher(""test_get_doc_ids"", Engine.SearcherScope.INTERNAL)) {
            List<DocIdSeqNoAndSource> docs = new ArrayList<>();
            for (LeafReaderContext leafContext : searcher.getIndexReader().leaves()) {
                LeafReader reader = leafContext.reader();
                NumericDocValues seqNoDocValues = reader.getNumericDocValues(SeqNoFieldMapper.NAME);
                NumericDocValues primaryTermDocValues = reader.getNumericDocValues(SeqNoFieldMapper.PRIMARY_TERM_NAME);
                NumericDocValues versionDocValues = reader.getNumericDocValues(VersionFieldMapper.NAME);
                Bits liveDocs = reader.getLiveDocs();
                StoredFields storedFields = reader.storedFields();
                for (int i = 0; i < reader.maxDoc(); i++) {
                    if (liveDocs == null || liveDocs.get(i)) {
                        if (primaryTermDocValues.advanceExact(i) == false) {
                            // We have to skip non-root docs because its _id field is not stored (indexed only).
                            continue;
                        }
                        final long primaryTerm = primaryTermDocValues.longValue();
                        Document doc = storedFields.document(i, Set.of(IdFieldMapper.NAME, SourceFieldMapper.NAME));
                        BytesRef binaryID = doc.getBinaryValue(IdFieldMapper.NAME);
                        String id = Uid.decodeId(Arrays.copyOfRange(binaryID.bytes, binaryID.offset, binaryID.offset + binaryID.length));
                        final BytesRef source = doc.getBinaryValue(SourceFieldMapper.NAME);
                        if (seqNoDocValues.advanceExact(i) == false) {
                            throw new AssertionError(""seqNoDocValues not found for doc["" + i + ""] id["" + id + ""]"");
                        }
                        final long seqNo = seqNoDocValues.longValue();
                        if (versionDocValues.advanceExact(i) == false) {
                            throw new AssertionError(""versionDocValues not found for doc["" + i + ""] id["" + id + ""]"");
                        }
                        final long version = versionDocValues.longValue();
                        docs.add(new DocIdSeqNoAndSource(id, source, seqNo, primaryTerm, version));
                    }
                }
            }
            docs.sort(
                Comparator.comparingLong(DocIdSeqNoAndSource::seqNo)
                    .thenComparingLong(DocIdSeqNoAndSource::primaryTerm)
                    .thenComparing((DocIdSeqNoAndSource::id))
            );
            return docs;
        }
    }","/**
     * Gets a collection of tuples of docId, sequence number, and primary term of all live documents in the provided engine.
     */",67087d9d82a3a5339cc3dc8a
"public RouterFunctionMockMvcBuilder addInterceptors(HandlerInterceptor... interceptors) {
		addMappedInterceptors(null, interceptors);
		return this;
	}","/**
	 * Add interceptors mapped to all incoming requests.
	 */",67087d9d82a3a5339cc3dc8b
"public void persistSchemaAndUpdateSegmentsTable(
      final String dataSource,
      final List<SegmentSchemaMetadataPlus> segmentSchemas,
      final int version
  )
  {
    connector.retryTransaction((TransactionCallback<Void>) (handle, status) -> {
      Map<String, SchemaPayload> schemaPayloadMap = new HashMap<>();

      for (SegmentSchemaMetadataPlus segmentSchema : segmentSchemas) {
        schemaPayloadMap.put(
            segmentSchema.getFingerprint(),
            segmentSchema.getSegmentSchemaMetadata().getSchemaPayload()
        );
      }
      persistSegmentSchema(handle, dataSource, version, schemaPayloadMap);
      updateSegmentWithSchemaInformation(handle, segmentSchemas);

      return null;
    }, 1, 3);
  }","/**
   * Persist segment schema and update segments in a transaction.
   */",67087d9d82a3a5339cc3dc8c
"public static int readInt(ByteBuffer buffer)
  {
    byte b;
    int v = (b = buffer.get()) & 0x7F;
    if (b < 0) {
      return v;
    }
    v = (((b = buffer.get()) & 0x7F) << 7) | v;
    if (b < 0) {
      return v;
    }
    v = (((b = buffer.get()) & 0x7F) << 14) | v;
    if (b < 0) {
      return v;
    }
    v = (((b = buffer.get()) & 0x7F) << 21) | v;
    if (b < 0) {
      return v;
    }
    v = ((buffer.get() & 0x7F) << 28) | v;
    return v;
  }","/**
   * Read a variable byte (vbyte) encoded integer from a {@link ByteBuffer} at the current position. Moves the buffer
   * ahead by 1 to 5 bytes depending on how many bytes was required to encode the integer value.
   *
   * vbyte encoding stores values in the last 7 bits of a byte and reserves the high bit for the 'contination'. If 0,
   * one or more aditional bytes must be read to complete the value, and a 1 indicates the terminal byte. Because of
   * this, it can only store positive values, and larger integers can take up to 5 bytes.
   *
   * implementation based on:
   * https://github.com/lemire/JavaFastPFOR/blob/master/src/main/java/me/lemire/integercompression/VariableByte.java
   *
   */",67087d9d82a3a5339cc3dc8d
"public JsonContentAssert isEqualToJson(byte[] expected, JSONCompareMode compareMode) {
		String expectedJson = this.loader.getJson(expected);
		return assertNotFailed(compare(expectedJson, compareMode));
	}","/**
	 * Verifies that the actual value is equal to the specified JSON bytes.
	 * @param expected the expected JSON bytes
	 * @param compareMode the compare mode used when checking
	 * @return {@code this} assertion object
	 * @throws AssertionError if the actual JSON value is not equal to the given one
	 */",67087d9d82a3a5339cc3dc8e
"public static LatLonGeometry[] toLatLonGeometry(Geometry geometry, boolean quantize, Consumer<ShapeType> checker) {
        if (geometry == null || geometry.isEmpty()) {
            return new LatLonGeometry[0];
        }
        if (GeometryNormalizer.needsNormalize(Orientation.CCW, geometry)) {
            // make geometry lucene friendly
            geometry = GeometryNormalizer.apply(Orientation.CCW, geometry);
        }
        final List<LatLonGeometry> geometries = new ArrayList<>();
        final Quantizer quantizer = quantize ? LATLON_QUANTIZER : NOOP_QUANTIZER;
        geometry.visit(new GeometryVisitor<>() {
            @Override
            public Void visit(Circle circle) {
                checker.accept(ShapeType.CIRCLE);
                if (circle.isEmpty() == false) {
                    geometries.add(toLatLonCircle(circle, quantizer));
                }
                return null;
            }

            @Override
            public Void visit(GeometryCollection<?> collection) {
                checker.accept(ShapeType.GEOMETRYCOLLECTION);
                if (collection.isEmpty() == false) {
                    for (org.elasticsearch.geometry.Geometry shape : collection) {
                        shape.visit(this);
                    }
                }
                return null;
            }

            @Override
            public Void visit(org.elasticsearch.geometry.Line line) {
                checker.accept(ShapeType.LINESTRING);
                if (line.isEmpty() == false) {
                    geometries.add(toLatLonLine(line, quantizer));
                }
                return null;
            }

            @Override
            public Void visit(LinearRing ring) {
                throw new IllegalArgumentException(""Found an unsupported shape LinearRing"");
            }

            @Override
            public Void visit(MultiLine multiLine) {
                checker.accept(ShapeType.MULTILINESTRING);
                if (multiLine.isEmpty() == false) {
                    for (Line line : multiLine) {
                        visit(line);
                    }
                }
                return null;
            }

            @Override
            public Void visit(MultiPoint multiPoint) {
                checker.accept(ShapeType.MULTIPOINT);
                if (multiPoint.isEmpty() == false) {
                    for (Point point : multiPoint) {
                        visit(point);
                    }
                }
                return null;
            }

            @Override
            public Void visit(MultiPolygon multiPolygon) {
                checker.accept(ShapeType.MULTIPOLYGON);
                if (multiPolygon.isEmpty() == false) {
                    for (Polygon polygon : multiPolygon) {
                        visit(polygon);
                    }
                }
                return null;
            }

            @Override
            public Void visit(Point point) {
                checker.accept(ShapeType.POINT);
                if (point.isEmpty() == false) {
                    geometries.add(toLatLonPoint(point, quantizer));
                }
                return null;
            }

            @Override
            public Void visit(org.elasticsearch.geometry.Polygon polygon) {
                checker.accept(ShapeType.POLYGON);
                if (polygon.isEmpty() == false) {
                    geometries.add(toLatLonPolygon(polygon, quantizer));
                }
                return null;
            }

            @Override
            public Void visit(Rectangle r) {
                checker.accept(ShapeType.ENVELOPE);
                if (r.isEmpty() == false) {
                    geometries.add(toLatLonRectangle(r, quantizer));
                }
                return null;
            }
        });
        return geometries.toArray(new LatLonGeometry[0]);
    }","/**
     * Transform an Elasticsearch {@link Geometry} into a lucene {@link LatLonGeometry}
     *
     * @param geometry the geometry to transform
     * @param quantize if true, the coordinates of the geometry will be quantized using lucene quantization.
     *                 This is useful for queries so  the latitude and longitude values to match the values on the index.
     * @param checker call for every {@link ShapeType} found in the Geometry. It allows to throw an error if a geometry is
     *                not supported.
     *
     * @return an array of {@link LatLonGeometry}
     */",67087d9d82a3a5339cc3dc8f
"private boolean isCompactibleHolder(Interval searchInterval, TimelineObjectHolder<String, DataSegment> holder)
    {
      final Iterator<PartitionChunk<DataSegment>> chunks = holder.getObject().iterator();
      if (!chunks.hasNext()) {
        return false;
      }
      PartitionChunk<DataSegment> firstChunk = chunks.next();
      if (!searchInterval.contains(firstChunk.getObject().getInterval())) {
        return false;
      }
      long partitionBytes = firstChunk.getObject().getSize();
      while (partitionBytes == 0 && chunks.hasNext()) {
        partitionBytes += chunks.next().getObject().getSize();
      }
      return partitionBytes > 0;
    }","/**
     * Checks if the {@link TimelineObjectHolder} satisfies the following:
     * <ul>
     * <li>It has atleast one segment.</li>
     * <li>The interval of the segments is contained in the searchInterval.</li>
     * <li>The total bytes across all the segments is positive.</li>
     * </ul>
     */",67087d9d82a3a5339cc3dc90
"public static Class<? extends Throwable> findClosestMatch(
			Collection<Class<? extends Throwable>> exceptionTypes, Throwable targetException) {

		Assert.notEmpty(exceptionTypes, ""Exception types must not be empty"");
		if (exceptionTypes.size() == 1) {
			return exceptionTypes.iterator().next();
		}
		List<Class<? extends Throwable>> handledExceptions = new ArrayList<>(exceptionTypes);
		handledExceptions.sort(new ExceptionDepthComparator(targetException));
		return handledExceptions.get(0);
	}","/**
	 * Obtain the closest match from the given exception types for the given target exception.
	 * @param exceptionTypes the collection of exception types
	 * @param targetException the target exception to find a match for
	 * @return the closest matching exception type from the given collection
	 */",67087d9d82a3a5339cc3dc91
"public static int toUpperCase(final int word) {
        final int mask = applyLowerCasePattern(word) >>> 2;
        return word & ~mask;
    }","/**
     * Returns a word with all bytes converted to uppercase ASCII.
     */",67087d9d82a3a5339cc3dc92
"long[] getNormalizedCoord(double[] coord) {
        long[] normalizedCoord = new long[nbrDim];

        for (int dim = 0; dim < nbrDim; dim++) {
            double value = clamp(coord[dim], range.getMin(dim), range.getMax(dim));
            // Avoiding awkward rounding errors
            if (value - range.getMin(dim) == range.getMax(dim) - range.getMin(dim)) {
                normalizedCoord[dim] = width - 1;
            } else {
                /*
                 * We are converting a world coordinate in range [min,max) to a long-int coordinate in range [0,width).
                 * The fact that the origins are not aligned means we can get numerical rounding errors of points near the world origin, but far from
                 * the normalized origin, due to very high precision in doubles near 0.0, and much lower precision of doubles of values far from 0.0.
                 * The symptom of this is points very close to tile edges end up in the adjacent tiles instead.
                 * We fix this by first converting to normalized coordinates, and then using the new tile as a new origin,
                 * and re-converting based on that origin.
                 * This should lead to a number of 0, which means we're in the origin tile (no numerical rounding errors),
                 * but when an error occurs, we could have a tile offset of +1 or -1, and we move to the adjacent tile instead.
                 */
                normalizedCoord[dim] = (long) ((value - range.getMin(dim)) * scalingFactor[dim]);
                // Calculating with an origin at the min can lead to numerical rouding errors, which can be corrected by
                // recalculating using a closer origin
                double tileCenter = ((double) normalizedCoord[dim]) / scalingFactor[dim]
                        + range.getMin(dim)
                        + getTileWidth(dim, maxLevel) / 2.0;
                // The 1E-16 is to create the behavior of the [min,max) bounds without an expensive if...else if...else
                // check
                long normalizedOffset = (long) ((value - tileCenter) * scalingFactor[dim] - 0.5 + 1E-16);
                // normalizedOffset is almost always 0, but can be +1 or -1 if there were rounding errors we need to
                // correct for
                normalizedCoord[dim] += normalizedOffset;
            }
        }
        return normalizedCoord;
    }","/**
     * Given a coordinate, find the corresponding normalized coordinate
     */",67087d9d82a3a5339cc3dc93
"@Test
    void verifyNotificationsHaveNotChanged() {
        StringBuilder notificationBuilder = new StringBuilder();
        Arrays.stream(NotificationCodeWithDescription.values()).forEach(notification -> {
            var status = notification.getStatus();
            Status.NotificationCode notificationCode = (Status.NotificationCode) status.code();

            // Covers all notification information except NotificationDetail and position, which are query dependent
            notificationBuilder.append(notificationCode.description()); // Title
            notificationBuilder.append(notification.getDescription()); // Description
            notificationBuilder.append(notification.getGqlStatus());
            notificationBuilder.append(notification.getMessage());
            notificationBuilder.append(notificationCode.serialize());
            notificationBuilder.append(notificationCode.getSeverity());
            notificationBuilder.append(notificationCode.getNotificationCategory());
        });

        byte[] notificationHash = DigestUtils.sha256(notificationBuilder.toString());

        byte[] expectedHash = new byte[] {
            -5, -109, 78, 102, -112, -122, -102, 85, 106, -83, -90, 43, -4, -120, 88, 63, 79, -110, 60, -10, -35, 25,
            61, 111, -4, -98, 96, 102, -69, -28, -84, 6
        };

        if (!Arrays.equals(notificationHash, expectedHash)) {
            fail(""Expected: "" + Arrays.toString(expectedHash) + "" \n Actual: "" + Arrays.toString(notificationHash)
                    + ""\n If you have added, changed or removed a notification, ""
                    + ""please follow the process on https://trello.com/c/9L3lbeSY/27-update-to-notification-name"");
        }
    }","/**
     * If this test fails, you have added, changed or removed a notification.
     * To get it approved, follow the instructions on
     * https://trello.com/c/9L3lbeSY/27-update-to-notification-name
     * When your changes have been approved, please change the expected byte[] below.
     */",67087d9d82a3a5339cc3dc94
"static Iterable<Iterable<Object>> valuesForRowsInPages(List<String> dataTypes, List<Page> pages) {
        BytesRef scratch = new BytesRef();
        return () -> Iterators.flatMap(pages.iterator(), page -> valuesForRowsInPage(dataTypes, page, scratch));
    }",/** Returns an iterable of iterables over the values in the given pages. There is one iterables for each row. */,67087d9d82a3a5339cc3dc95
"public SnapshotsStatusRequestBuilder setSnapshots(String... snapshots) {
        request.snapshots(snapshots);
        return this;
    }","/**
     * Sets list of snapshots to return
     *
     * @param snapshots list of snapshots
     * @return this builder
     */",67087d9d82a3a5339cc3dc96
"@Deprecated
    public static void setDate(HttpMessage message, Date value) {
        message.headers().set(HttpHeaderNames.DATE, value);
    }","/**
     * @deprecated Use {@link #set(CharSequence, Object)} instead.
     *
     * Sets the {@code ""Date""} header.
     */",67087d9d82a3a5339cc3dc97
"public RestoreSnapshotRequestBuilder setIndexSettings(Map<String, Object> source) {
        request.indexSettings(source);
        return this;
    }","/**
     * Sets index settings that should be added or replaced during restore
     *
     * @param source index settings
     * @return this builder
     */",67087d9d82a3a5339cc3dc98
"private DataSource insertSubqueryIds(
      DataSource currentDataSource,
      Map<QueryDataSource, Pair<Integer, Integer>> queryDataSourceToSubqueryIds,
      @Nullable final String parentQueryId,
      @Nullable final String parentSqlQueryId
  )
  {
    if (currentDataSource instanceof QueryDataSource
        && queryDataSourceToSubqueryIds.containsKey((QueryDataSource) currentDataSource)) {
      QueryDataSource queryDataSource = (QueryDataSource) currentDataSource;
      Pair<Integer, Integer> nestingInfo = queryDataSourceToSubqueryIds.get(queryDataSource);
      String subQueryId = nestingInfo.lhs + ""."" + nestingInfo.rhs;
      Query<?> query = queryDataSource.getQuery();

      if (StringUtils.isEmpty(query.getSubQueryId())) {
        query = query.withSubQueryId(subQueryId);
      }

      if (StringUtils.isEmpty(query.getId()) && StringUtils.isNotEmpty(parentQueryId)) {
        query = query.withId(parentQueryId);
      }

      if (StringUtils.isEmpty(query.getSqlQueryId()) && StringUtils.isNotEmpty(parentSqlQueryId)) {
        query = query.withSqlQueryId(parentSqlQueryId);
      }

      currentDataSource = new QueryDataSource(query);
    }
    return currentDataSource.withChildren(currentDataSource.getChildren()
                                                           .stream()
                                                           .map(childDataSource -> insertSubqueryIds(
                                                               childDataSource,
                                                               queryDataSourceToSubqueryIds,
                                                               parentQueryId,
                                                               parentSqlQueryId
                                                           ))
                                                           .collect(Collectors.toList()));
  }","/**
   * To be used in conjunction with {@code generateSubqueryIds()} method. This does the actual task of populating the
   * query's id, subQueryId and sqlQueryId
   *
   * @param currentDataSource            The datasource to be populated with the subqueries
   * @param queryDataSourceToSubqueryIds Map of the datasources to their level and sibling order
   * @param parentQueryId                Parent query's id
   * @param parentSqlQueryId             Parent query's sqlQueryId
   * @return Populates the subqueries from the map
   */",67087d9d82a3a5339cc3dc99
"public static <T extends Throwable> T expectScriptThrows(Class<T> expectedType, ThrowingRunnable runnable) {
        return expectScriptThrows(expectedType, true, runnable);
    }",/** Checks a specific exception class is thrown (boxed inside ScriptException) and returns it. */,67087d9d82a3a5339cc3dc9a
"public void toBytesDense(ByteBuffer buf)
  {
    buf.putInt(size);
    buf.putInt(binCount);

    buf.asFloatBuffer().put(positions);
    buf.position(buf.position() + Float.BYTES * positions.length);
    buf.asLongBuffer().put(bins);
    buf.position(buf.position() + Long.BYTES * bins.length);

    buf.putFloat(min);
    buf.putFloat(max);
  }","/**
   * Writes the dense representation of this ApproximateHistogram object to the given byte-buffer
   * 
   * Requires 16 + 12 * size bytes of storage
   *
   * @param buf ByteBuffer to write the ApproximateHistogram to
   */",67087d9d82a3a5339cc3dc9b
"protected TypedStringValue buildTypedStringValue(String value, @Nullable String targetTypeName)
			throws ClassNotFoundException {

		ClassLoader classLoader = this.readerContext.getBeanClassLoader();
		TypedStringValue typedValue;
		if (!StringUtils.hasText(targetTypeName)) {
			typedValue = new TypedStringValue(value);
		}
		else if (classLoader != null) {
			Class<?> targetType = ClassUtils.forName(targetTypeName, classLoader);
			typedValue = new TypedStringValue(value, targetType);
		}
		else {
			typedValue = new TypedStringValue(value, targetTypeName);
		}
		return typedValue;
	}","/**
	 * Build a typed String value Object for the given raw value.
	 * @see org.springframework.beans.factory.config.TypedStringValue
	 */",67087d9d82a3a5339cc3dc9c
"private static long getMaxBytesPerRowForAggregators(IncrementalIndexSchema incrementalIndexSchema)
  {
    final long rowsPerAggregator =
        incrementalIndexSchema.isRollup() ? ROLLUP_RATIO_FOR_AGGREGATOR_FOOTPRINT_ESTIMATION : 1;

    long maxAggregatorIntermediateSize = ((long) Integer.BYTES) * incrementalIndexSchema.getMetrics().length;

    for (final AggregatorFactory aggregator : incrementalIndexSchema.getMetrics()) {
      maxAggregatorIntermediateSize +=
          (long) aggregator.guessAggregatorHeapFootprint(rowsPerAggregator) + 2L * Long.BYTES;
    }

    return maxAggregatorIntermediateSize;
  }","/**
   * Old method of memory estimation. Used only when {@link #useMaxMemoryEstimates} is true.
   *
   * Gives estimated max size per aggregator. It is assumed that every aggregator will have enough overhead for its own
   * object header and for a pointer to a selector. We are adding a overhead-factor for each object as additional 16
   * bytes.
   * These 16 bytes or 128 bits is the object metadata for 64-bit JVM process and consists of:
   * <ul>
   * <li>Class pointer which describes the object type: 64 bits
   * <li>Flags which describe state of the object including hashcode: 64 bits
   * <ul/>
   * total size estimation consists of:
   * <ul>
   * <li> metrics length : Integer.BYTES * len
   * <li> maxAggregatorIntermediateSize : getMaxIntermediateSize per aggregator + overhead-factor(16 bytes)
   * </ul>
   *
   * @param incrementalIndexSchema
   *
   * @return long max aggregator size in bytes
   */",67087d9d82a3a5339cc3dc9d
"protected boolean shouldRegisterJspServlet() {
		return this.jsp != null && this.jsp.getRegistered()
				&& ClassUtils.isPresent(this.jsp.getClassName(), getClass().getClassLoader());
	}","/**
	 * Returns whether the JSP servlet should be registered with the web server.
	 * @return {@code true} if the servlet should be registered, otherwise {@code false}
	 */",67087d9d82a3a5339cc3dc9e
"public UrlBasedViewResolverRegistration viewNames(String... viewNames) {
		this.viewResolver.setViewNames(viewNames);
		return this;
	}","/**
	 * Set the view names (or name patterns) that can be handled by this view
	 * resolver. View names can contain simple wildcards such that 'my*', '*Report'
	 * and '*Repo*' will all match the view name 'myReport'.
	 * @see org.springframework.web.servlet.view.UrlBasedViewResolver#setViewNames
	 */",67087d9d82a3a5339cc3dc9f
"protected static void writeSize(int size, StreamOutput out) throws IOException {
        if (size == Integer.MAX_VALUE) {
            size = 0;
        }
        out.writeVInt(size);
    }","/**
     * Write a size under the assumption that a value of 0 means unlimited.
     */",67087d9d82a3a5339cc3dca0
"public List<StorageLocation> toStorageLocations()
  {
    return this.getLocations()
               .stream()
               .map(locationConfig -> new StorageLocation(locationConfig.getPath(),
                                                          locationConfig.getMaxSize(),
                                                          locationConfig.getFreeSpacePercent()))
               .collect(Collectors.toList());
  }","/**
   * Convert a list of {@link StorageLocationConfig} objects to {@link StorageLocation} objects.
   * <p>
   * Note: {@link #getLocations} is called instead of variable access because some testcases overrides this method
   */",67087d9d82a3a5339cc3dca1
"public void testIncludeTypeNamesWarning() throws IOException {
        Map<String, String> params = new HashMap<>();
        params.put(INCLUDE_TYPE_NAME_PARAMETER, randomFrom(""true"", ""false""));
        RestRequest request = new FakeRestRequest.Builder(xContentRegistry()).withHeaders(
            Map.of(""Content-Type"", contentTypeHeader, ""Accept"", contentTypeHeader)
        ).withMethod(RestRequest.Method.GET).withPath(""/some_index"").withParams(params).build();

        RestGetIndicesAction handler = new RestGetIndicesAction();
        handler.prepareRequest(request, mock(NodeClient.class));
        assertCriticalWarnings(RestGetIndicesAction.TYPES_DEPRECATION_MESSAGE);

        // the same request without the parameter should pass without warning
        request = new FakeRestRequest.Builder(xContentRegistry()).withHeaders(
            Map.of(""Content-Type"", contentTypeHeader, ""Accept"", contentTypeHeader)
        ).withMethod(RestRequest.Method.GET).withPath(""/some_index"").build();
        handler.prepareRequest(request, mock(NodeClient.class));
    }","/**
     * Test that setting the ""include_type_name"" parameter raises a warning for the GET request
     */",67087d9d82a3a5339cc3dca2
"public static ParameterizedType providerOf(Type providedType) {
        return newParameterizedType(Provider.class, providedType);
    }","/**
     * Returns a type modelling a {@link Provider} that provides elements of type
     * {@code elementType}.
     *
     * @return a parameterized type.
     */",67087d9d82a3a5339cc3dca3
"private boolean isStringConversionBetter(TypeDescriptor sourceType, TypeDescriptor targetType) {
		if (this.conversionService instanceof ApplicationConversionService applicationConversionService) {
			if (applicationConversionService.isConvertViaObjectSourceType(sourceType, targetType)) {
				// If an ObjectTo... converter is being used then there might be a better
				// StringTo... version
				return true;
			}
		}
		if ((targetType.isArray() || targetType.isCollection()) && !targetType.equals(BYTE_ARRAY)) {
			// StringToArrayConverter / StringToCollectionConverter are better than
			// ObjectToArrayConverter / ObjectToCollectionConverter
			return true;
		}
		return false;
	}","/**
	 * Return if String based conversion is better based on the target type. This is
	 * required when ObjectTo... conversion produces incorrect results.
	 * @param sourceType the source type to test
	 * @param targetType the target type to test
	 * @return if string conversion is better
	 */",67087d9d82a3a5339cc3dca4
"public static <T> Key<T> get(TypeLiteral<T> typeLiteral, Annotation annotation) {
        return new Key<>(typeLiteral, strategyFor(annotation));
    }","/**
     * Gets a key for an injection type and an annotation.
     */",67087d9d82a3a5339cc3dca5
"public static String style(Object value) {
		return DEFAULT_VALUE_STYLER.style(value);
	}","/**
	 * Style the specified value according to default conventions.
	 * @param value the Object value to style
	 * @return the styled String
	 * @see DefaultValueStyler
	 */",67087d9d82a3a5339cc3dca6
"public int keyValueSizeCap() {
        return rootLayer.keyValueSizeCap();
    }","/**
     * Total size limit for key and value.
     * This limit includes storage overhead that is specific to key implementation for example entity id or meta data about type.
     * @return Total size limit for key and value or {@link TreeNodeUtil#NO_KEY_VALUE_SIZE_CAP} if no such value exists.
     */",67087d9d82a3a5339cc3dca7
"@Test
    public void shouldDecodeWithoutHeader() {
        Object temp;

        write(XML4);

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlDocumentStart.class));
        assertThat(((XmlDocumentStart) temp).version(), is(nullValue()));
        assertThat(((XmlDocumentStart) temp).encoding(), is(""UTF-8""));
        assertThat(((XmlDocumentStart) temp).standalone(), is(false));
        assertThat(((XmlDocumentStart) temp).encodingScheme(), is(nullValue()));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""netty""));
        assertThat(((XmlElementStart) temp).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(0));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""netty""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""""));
        assertThat(((XmlElementEnd) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, nullValue());
    }","/**
     * This test checks for no XML header
     */",67087d9d82a3a5339cc3dca8
"public Map<String, List<DataStreamAlias>> dataStreamAliasesByDataStream() {
        Map<String, List<DataStreamAlias>> dataStreamAliases = new HashMap<>();

        for (DataStreamAlias dsAlias : dataStreamAliases().values()) {
            for (String dataStream : dsAlias.getDataStreams()) {
                if (dataStreamAliases.containsKey(dataStream) == false) {
                    dataStreamAliases.put(dataStream, new ArrayList<>());
                }
                dataStreamAliases.get(dataStream).add(dsAlias);
            }
        }

        return dataStreamAliases;
    }","/**
     * Return a map of DataStreamAlias objects by DataStream name
     * @return a map of DataStreamAlias objects by DataStream name
     */",67087d9d82a3a5339cc3dca9
"private static byte[] hexStringToByteArray(String hexString) {
        int len = hexString.length();
        if (len % 2 == 0) {
            byte[] data = new byte[len / 2];
            for (int i = 0; i < len; i += 2) {
                final int k = Character.digit(hexString.charAt(i), 16);
                final int l = Character.digit(hexString.charAt(i + 1), 16);
                if (k == -1 || l == -1) {
                    throw new IllegalStateException(""String ["" + hexString + ""] is not hexadecimal"");
                }
                data[i / 2] = (byte) ((k << 4) + l);
            }
            return data;
        } else {
            throw new IllegalStateException(
                ""Hexadecimal string ["" + hexString + ""] has odd length and cannot be converted to a byte array""
            );
        }
    }","/**
     * Converts a hexadecimal string to a byte array
     */",67087d9d82a3a5339cc3dcaa
"public boolean isCompatible(Version version) {
        boolean compatible = onOrAfter(version.minimumCompatibilityVersion()) && version.onOrAfter(minimumCompatibilityVersion());

        assert compatible == false || Math.max(major, version.major) - Math.min(major, version.major) <= 1;
        return compatible;
    }","/**
     * Returns <code>true</code> iff both version are compatible. Otherwise <code>false</code>
     */",67087d9d82a3a5339cc3dcab
"@Override
	public boolean isWritable() {
		return (this.file != null ? this.file.canWrite() && !this.file.isDirectory() :
				Files.isWritable(this.filePath) && !Files.isDirectory(this.filePath));
	}","/**
	 * This implementation checks whether the underlying file is marked as writable
	 * (and corresponds to an actual file with content, not to a directory).
	 * @see java.io.File#canWrite()
	 * @see java.io.File#isDirectory()
	 * @see java.nio.file.Files#isWritable(Path)
	 * @see java.nio.file.Files#isDirectory(Path, java.nio.file.LinkOption...)
	 */",67087d9d82a3a5339cc3dcac
"public long getFirstRel(long nodeId, GroupVisitor visitor) {
        ByteArray array = this.array.at(nodeId);
        long id = getRelationshipId(array, nodeId);
        if (id != EMPTY && isDense(array, nodeId)) { // Indirection into rel group cache
            return relGroupCache.visitGroup(nodeId, id, visitor);
        }

        return id;
    }","/**
     * Used when setting node nextRel fields. Gets the first relationship for this node,
     * or the relationship group id. As a side effect this method also creates a relationship group
     * if this node is dense, and returns that relationship group record id.
     *
     * @param nodeId id to get first relationship for.
     * @param visitor {@link GroupVisitor} which will be notified with data about group to be created.
     * This visitor is expected to create the group.
     * @return the first relationship if node is sparse, or the result of {@link GroupVisitor} if dense.
     */",67087d9d82a3a5339cc3dcad
"private static Sequence<List<Object>> unsortAndMakeRows(final List<FrameWriterTestData.Dataset<?>> datasets)
  {
    final List<List<Object>> retVal = new ArrayList<>();

    final int rowSize = datasets.size();
    final List<Iterator<?>> iterators =
        datasets.stream()
                .map(dataset -> dataset.getData(KeyOrder.NONE).iterator())
                .collect(Collectors.toList());

    while (iterators.stream().anyMatch(Iterator::hasNext)) {
      final List<Object> row = new ArrayList<>(rowSize);

      for (int i = 0; i < rowSize; i++) {
        if (iterators.get(i).hasNext()) {
          row.add(iterators.get(i).next());
        } else {
          row.add(fillerValueForType(datasets.get(i).getType().getType()));
        }
      }

      retVal.add(row);
    }

    return Sequences.simple(retVal);
  }","/**
   * Create rows out of shuffled (unsorted) datasets.
   */",67087d9d82a3a5339cc3dcae
"public CompletableFuture<StompSession> connectAsync(String url, @Nullable WebSocketHttpHeaders handshakeHeaders,
			@Nullable StompHeaders connectHeaders, StompSessionHandler handler, Object... uriVariables) {

		Assert.notNull(url, ""'url' must not be null"");
		URI uri = UriComponentsBuilder.fromUriString(url).buildAndExpand(uriVariables).encode().toUri();
		return connectAsync(uri, handshakeHeaders, connectHeaders, handler);
	}","/**
	 * An overloaded version of
	 * {@link #connect(String, StompSessionHandler, Object...)} that also accepts
	 * {@link WebSocketHttpHeaders} to use for the WebSocket handshake and
	 * {@link StompHeaders} for the STOMP CONNECT frame.
	 * @param url the url to connect to
	 * @param handshakeHeaders headers for the WebSocket handshake
	 * @param connectHeaders headers for the STOMP CONNECT frame
	 * @param handler the session handler
	 * @param uriVariables the URI variables to expand into the URL
	 * @return a CompletableFuture for access to the session when ready for use
	 * @since 6.0
	 */",67087d9d82a3a5339cc3dcaf
"public int read(int pos, char[] cbuf, int off, int len) {
        len = Math.min(content.length() - pos, len);
        content.getChars(pos, pos + len, cbuf, off);
        return len;
    }","/**
     * Reads characters into an array.
     *
     * @param pos The position of this file to start reading from
     * @param cbuf Destination buffer
     * @param off Offset at which to start storing characters
     * @param len Maximum number of characters to read (> 0)
     * @return The number of characters read (0 if no characters remain)
     * @see java.io.Reader#read(char[], int, int)
     */",67087d9d82a3a5339cc3dcb0
"@Parameterized.Parameters(name = ""{0}"")
  public static Collection<?> constructorFeeder()
  {
    List<Object[]> constructors = new ArrayList<>();
    CompressedBigDecimalGroupByQueryConfig cbdGroupByQueryConfig = new CompressedBigDecimalGroupByQueryConfig(
        ""bd_max_test_groupby_query.json"",
        ""bd_max_test_aggregators.json"",
        ""9999999999.000000000"",
        ""9999999999.000000000"",
        ""9999999999.000000000""
    );
    for (GroupByQueryConfig config : GroupByQueryRunnerTest.testConfigs()) {
      constructors.add(new Object[]{config, cbdGroupByQueryConfig});
    }
    return constructors;
  }","/**
   * Constructor feeder.
   *
   * @return constructors
   */",67087d9d82a3a5339cc3dcb1
"public void setOriginBasedPosition (float x, float y) {
		setPosition(x - this.originX, y - this.originY);
	}","/** Sets the position where the sprite will be drawn, relative to its current origin. */",67087d9d82a3a5339cc3dcb2
"public Set<Object> getAllSources() {
		Set<Object> allSources = new LinkedHashSet<>();
		if (!CollectionUtils.isEmpty(this.primarySources)) {
			allSources.addAll(this.primarySources);
		}
		if (!CollectionUtils.isEmpty(this.sources)) {
			allSources.addAll(this.sources);
		}
		return Collections.unmodifiableSet(allSources);
	}","/**
	 * Return an immutable set of all the sources that will be added to an
	 * ApplicationContext when {@link #run(String...)} is called. This method combines any
	 * primary sources specified in the constructor with any additional ones that have
	 * been {@link #setSources(Set) explicitly set}.
	 * @return an immutable set of all sources
	 */",67087d9d82a3a5339cc3dcb3
"@Override
	public int compareTo(HeadersRequestCondition other, HttpServletRequest request) {
		int result = other.expressions.size() - this.expressions.size();
		if (result != 0) {
			return result;
		}
		return (int) (getValueMatchCount(other.expressions) - getValueMatchCount(this.expressions));
	}","/**
	 * Compare to another condition based on header expressions. A condition
	 * is considered to be a more specific match, if it has:
	 * <ol>
	 * <li>A greater number of expressions.
	 * <li>A greater number of non-negated expressions with a concrete value.
	 * </ol>
	 * <p>It is assumed that both instances have been obtained via
	 * {@link #getMatchingCondition(HttpServletRequest)} and each instance
	 * contains the matching header expression only or is otherwise empty.
	 */",67087d9d82a3a5339cc3dcb4
"@Nullable
	public static String getCurrentTransactionName() {
		return currentTransactionName.get();
	}","/**
	 * Return the name of the current transaction, or {@code null} if none set.
	 * To be called by resource management code for optimizations per use case,
	 * for example to optimize fetch strategies for specific named transactions.
	 * @see org.springframework.transaction.TransactionDefinition#getName()
	 */",67087d9d82a3a5339cc3dcb5
"@Test
  public void testKillUnusedSegmentsWithUsedLoadSpec() throws Exception
  {
    final DateTime now = DateTimes.nowUtc();
    final String v1 = now.toString();
    final String v2 = now.minusHours(2).toString();
    final String v3 = now.minusHours(3).toString();

    final DataSegment segment1V1 = newSegment(Intervals.of(""2019-01-01/2019-02-01""), v1, ImmutableMap.of(""foo"", ""1""));
    final DataSegment segment2V2 = newSegment(Intervals.of(""2019-02-01/2019-03-01""), v2, ImmutableMap.of(""foo"", ""1""));
    final DataSegment segment3V3 = newSegment(Intervals.of(""2019-03-01/2019-04-01""), v3, ImmutableMap.of(""foo"", ""1""));

    final Set<DataSegment> segments = ImmutableSet.of(segment1V1, segment2V2, segment3V3);
    final Set<DataSegment> unusedSegments = ImmutableSet.of(segment1V1, segment2V2);

    Assert.assertEquals(segments, getMetadataStorageCoordinator().commitSegments(segments, null));
    Assert.assertEquals(
        unusedSegments.size(),
        getSegmentsMetadataManager().markSegmentsAsUnused(
            unusedSegments.stream().map(DataSegment::getId).collect(Collectors.toSet())
        )
    );

    final KillUnusedSegmentsTask task = new KillUnusedSegmentsTaskBuilder()
        .dataSource(DATA_SOURCE)
        .interval(Intervals.of(""2018/2020""))
        .versions(ImmutableList.of(v1, v2))
        .limit(100)
        .build();

    Assert.assertEquals(TaskState.SUCCESS, taskRunner.run(task).get().getStatusCode());
    Assert.assertEquals(
        new KillTaskReport.Stats(0, 1),
        getReportedStats()
    );

    final List<DataSegment> observedUnusedSegments =
        getMetadataStorageCoordinator().retrieveUnusedSegmentsForInterval(
          DATA_SOURCE,
          Intervals.of(""2018/2020""),
          null,
          null
      );

    Assert.assertEquals(ImmutableSet.of(), new HashSet<>(observedUnusedSegments));
  }","/**
   * {@code segment1}, {@code segment2} and {@code segment3} have different versions, but share the same load spec.
   * {@code segment1} and {@code segment2} are unused segments, while {@code segment3} is a used segment.
   * When a kill task is submitted, the unused segments {@code segment1} and {@code segment2} should be deleted from the
   * metadata store, but should be retained in deep storage as the load spec is used by {@code segment3}.
   */",67087d9d82a3a5339cc3dcb6
"static public Vector2 triangleCircumcenter (float x1, float y1, float x2, float y2, float x3, float y3, Vector2 circumcenter) {
		float dx21 = x2 - x1, dy21 = y2 - y1;
		float dx32 = x3 - x2, dy32 = y3 - y2;
		float dx13 = x1 - x3, dy13 = y1 - y3;
		float det = dx32 * dy21 - dx21 * dy32;
		if (Math.abs(det) < MathUtils.FLOAT_ROUNDING_ERROR)
			throw new IllegalArgumentException(""Triangle points must not be colinear."");
		det *= 2;
		float sqr1 = x1 * x1 + y1 * y1, sqr2 = x2 * x2 + y2 * y2, sqr3 = x3 * x3 + y3 * y3;
		circumcenter.set((sqr1 * dy32 + sqr2 * dy13 + sqr3 * dy21) / det, -(sqr1 * dx32 + sqr2 * dx13 + sqr3 * dx21) / det);
		return circumcenter;
	}",/** Returns the circumcenter of the triangle. The input points must not be colinear. */,67087d9d82a3a5339cc3dcb7
"public void setSerializersByType(Map<Class<?>, JsonSerializer<?>> serializers) {
		this.builder.serializersByType(serializers);
	}","/**
	 * Configure custom serializers for the given types.
	 * @see #setSerializers(JsonSerializer...)
	 */",67087d9d82a3a5339cc3dcb8
"@Override
	protected void configure(FilterRegistration.Dynamic registration) {
		super.configure(registration);
		EnumSet<DispatcherType> dispatcherTypes = determineDispatcherTypes();
		Set<String> servletNames = new LinkedHashSet<>();
		for (ServletRegistrationBean<?> servletRegistrationBean : this.servletRegistrationBeans) {
			servletNames.add(servletRegistrationBean.getServletName());
		}
		servletNames.addAll(this.servletNames);
		if (servletNames.isEmpty() && this.urlPatterns.isEmpty()) {
			registration.addMappingForUrlPatterns(dispatcherTypes, this.matchAfter, DEFAULT_URL_MAPPINGS);
		}
		else {
			if (!servletNames.isEmpty()) {
				registration.addMappingForServletNames(dispatcherTypes, this.matchAfter,
						StringUtils.toStringArray(servletNames));
			}
			if (!this.urlPatterns.isEmpty()) {
				registration.addMappingForUrlPatterns(dispatcherTypes, this.matchAfter,
						StringUtils.toStringArray(this.urlPatterns));
			}
		}
	}","/**
	 * Configure registration settings. Subclasses can override this method to perform
	 * additional configuration if required.
	 * @param registration the registration
	 */",67087d9d82a3a5339cc3dcb9
"private IndexDescriptor findUsableMatchingCompositeIndex(
            SchemaDescriptor schemaDescriptor,
            int[] propertyIds,
            Supplier<Iterator<IndexDescriptor>> indexesSupplier,
            IndexQuery... query) {
        // Try a direct schema match first.
        var directMatch = findUsableMatchingIndex(schemaDescriptor, query);
        if (directMatch != IndexDescriptor.NO_INDEX) {
            return directMatch;
        }

        // Attempt to find matching index with different property order
        Arrays.sort(propertyIds);
        assertNoDuplicates(propertyIds, tokenRead());

        int[] workingCopy = new int[propertyIds.length];

        Iterator<IndexDescriptor> indexes = indexesSupplier.get();
        while (indexes.hasNext()) {
            IndexDescriptor index = indexes.next();
            int[] original = index.schema().getPropertyIds();
            if (hasSamePropertyIds(original, workingCopy, propertyIds)
                    && indexIsOnline(schemaRead(), index)
                    && indexSupportQuery(index, query)) {
                // Ha! We found an index with the same properties in another order
                return index;
            }
        }

        // No dice.
        return IndexDescriptor.NO_INDEX;
    }","/**
     * Find an ONLINE index that matches the schema.
     */",67087d9d82a3a5339cc3dcba
"protected LocalExporter createLocalExporter(String localExporterName, Settings exporterSettings) {
        return createLocalExporter(localExporterName, exporterSettings, new MonitoringMigrationCoordinator());
    }","/**
     * Create a new {@link LocalExporter}. Expected usage:
     * <pre><code>
     * final Settings settings = Settings.builder().put(""xpack.monitoring.exporters._local.type"", ""local"").build();
     * try (LocalExporter exporter = createLocalExporter(""_local"", settings)) {
     *   // ...
     * }
     * </code></pre>
     *
     * @return Never {@code null}.
     */",67087d9d82a3a5339cc3dcbb
"public Query termsQuery(Collection<?> values, @Nullable SearchExecutionContext context) {
        Set<?> dedupe = new HashSet<>(values);
        BooleanQuery.Builder builder = new BooleanQuery.Builder();
        for (Object value : dedupe) {
            builder.add(termQuery(value, context), Occur.SHOULD);
        }
        return new ConstantScoreQuery(builder.build());
    }","/** Build a constant-scoring query that matches all values. The default implementation uses a
     * {@link ConstantScoreQuery} around a {@link BooleanQuery} whose {@link Occur#SHOULD} clauses
     * are generated with {@link #termQuery}. */",67087d9d82a3a5339cc3dcbc
"public TemplateAvailabilityProvider getProvider(String view, Environment environment, ClassLoader classLoader,
			ResourceLoader resourceLoader) {
		Assert.notNull(view, ""View must not be null"");
		Assert.notNull(environment, ""Environment must not be null"");
		Assert.notNull(classLoader, ""ClassLoader must not be null"");
		Assert.notNull(resourceLoader, ""ResourceLoader must not be null"");
		Boolean useCache = environment.getProperty(""spring.template.provider.cache"", Boolean.class, true);
		if (!useCache) {
			return findProvider(view, environment, classLoader, resourceLoader);
		}
		TemplateAvailabilityProvider provider = this.resolved.get(view);
		if (provider == null) {
			synchronized (this.cache) {
				provider = findProvider(view, environment, classLoader, resourceLoader);
				provider = (provider != null) ? provider : NONE;
				this.resolved.put(view, provider);
				this.cache.put(view, provider);
			}
		}
		return (provider != NONE) ? provider : null;
	}","/**
	 * Get the provider that can be used to render the given view.
	 * @param view the view to render
	 * @param environment the environment
	 * @param classLoader the class loader
	 * @param resourceLoader the resource loader
	 * @return a {@link TemplateAvailabilityProvider} or null
	 */",67087d9d82a3a5339cc3dcbd
"static JMXConnector connect(int port) throws IOException {
		String url = ""service:jmx:rmi:///jndi/rmi://127.0.0.1:"" + port + ""/jmxrmi"";
		JMXServiceURL serviceUrl = new JMXServiceURL(url);
		return JMXConnectorFactory.connect(serviceUrl, null);
	}","/**
	 * Create a connector for an {@link javax.management.MBeanServer} exposed on the
	 * current machine and the current port. Security should be disabled.
	 * @param port the port on which the mbean server is exposed
	 * @return a connection
	 * @throws IOException if the connection to that server failed
	 */",67087d9d82a3a5339cc3dcbe
"public final <V> void writeMap(final Map<String, V> map, final Writer<V> valueWriter) throws IOException {
        writeMap(map, StreamOutput::writeString, valueWriter);
    }","/**
     * Same as {@link #writeMap(Map, Writer, Writer)} but for {@code String} keys.
     */",67087d9d82a3a5339cc3dcbf
"private static boolean renameIndexFile(
      final FileSystem outputFS,
      final Path indexZipFilePath,
      final Path finalIndexZipFilePath
  )
  {
    try {
      return RetryUtils.retry(
          () -> {
            final boolean needRename;

            if (outputFS.exists(finalIndexZipFilePath)) {
              // NativeS3FileSystem.rename won't overwrite, so we might need to delete the old index first
              final FileStatus zipFile = outputFS.getFileStatus(indexZipFilePath);
              final FileStatus finalIndexZipFile = outputFS.getFileStatus(finalIndexZipFilePath);

              if (zipFile.getModificationTime() >= finalIndexZipFile.getModificationTime()
                  || zipFile.getLen() != finalIndexZipFile.getLen()) {
                log.info(
                    ""File[%s / %s / %sB] existed, but wasn't the same as [%s / %s / %sB]"",
                    finalIndexZipFile.getPath(),
                    DateTimes.utc(finalIndexZipFile.getModificationTime()),
                    finalIndexZipFile.getLen(),
                    zipFile.getPath(),
                    DateTimes.utc(zipFile.getModificationTime()),
                    zipFile.getLen()
                );
                outputFS.delete(finalIndexZipFilePath, false);
                needRename = true;
              } else {
                log.info(
                    ""File[%s / %s / %sB] existed and will be kept"",
                    finalIndexZipFile.getPath(),
                    DateTimes.utc(finalIndexZipFile.getModificationTime()),
                    finalIndexZipFile.getLen()
                );
                needRename = false;
              }
            } else {
              needRename = true;
            }

            if (needRename) {
              log.info(""Attempting rename from [%s] to [%s]"", indexZipFilePath, finalIndexZipFilePath);
              return outputFS.rename(indexZipFilePath, finalIndexZipFilePath);
            } else {
              return true;
            }
          },
          FileUtils.IS_EXCEPTION,
          NUM_RETRIES
      );
    }
    catch (Exception e) {
      throw new RuntimeException(e);
    }
  }","/**
   * Rename the file. This works around some limitations of both FileContext (no s3n support) and NativeS3FileSystem.rename
   * which will not overwrite
   *
   * @param outputFS              The output fs
   * @param indexZipFilePath      The original file path
   * @param finalIndexZipFilePath The to rename the original file to
   *
   * @return False if a rename failed, true otherwise (rename success or no rename needed)
   */",67087d9d82a3a5339cc3dcc0
"@Override
	default Locale resolveLocale(HttpServletRequest request) {
		Locale locale = resolveLocaleContext(request).getLocale();
		return (locale != null ? locale : request.getLocale());
	}","/**
	 * Default implementation of {@link LocaleResolver#resolveLocale(HttpServletRequest)}
	 * that delegates to {@link #resolveLocaleContext(HttpServletRequest)}, falling
	 * back to {@link HttpServletRequest#getLocale()} if necessary.
	 * @param request the request to resolve the locale for
	 * @return the current locale (never {@code null})
	 * @since 6.0
	 */",67087d9d82a3a5339cc3dcc1
"@Override
	public void destroy() {
		if (this.applicationContext == null) {
			stop();
		}
	}","/**
	 * Stops the resources if initialized outside an ApplicationContext.
	 * This is for backwards compatibility; the preferred way is to rely on
	 * the ApplicationContext's {@link SmartLifecycle lifecycle management}.
	 * @see #stop()
	 */",67087d9d82a3a5339cc3dcc2
"public static byte[] md5Digest(byte[] bytes) {
		return digest(MD5_ALGORITHM_NAME, bytes);
	}","/**
	 * Calculate the MD5 digest of the given bytes.
	 * @param bytes the bytes to calculate the digest over
	 * @return the digest
	 */",67087d9d82a3a5339cc3dcc3
"protected void initialize(ConfigurableEnvironment environment, ClassLoader classLoader) {
		getLoggingSystemProperties(environment).apply();
		this.logFile = LogFile.get(environment);
		if (this.logFile != null) {
			this.logFile.applyToSystemProperties();
		}
		this.loggerGroups = new LoggerGroups(DEFAULT_GROUP_LOGGERS);
		initializeEarlyLoggingLevel(environment);
		initializeSystem(environment, this.loggingSystem, this.logFile);
		initializeFinalLoggingLevels(environment, this.loggingSystem);
		registerShutdownHookIfNecessary(environment, this.loggingSystem);
	}","/**
	 * Initialize the logging system according to preferences expressed through the
	 * {@link Environment} and the classpath.
	 * @param environment the environment
	 * @param classLoader the classloader
	 */",67087d9d82a3a5339cc3dcc4
"public CorsConfiguration applyPermitDefaultValues() {
		if (this.allowedOrigins == null && this.allowedOriginPatterns == null) {
			this.allowedOrigins = DEFAULT_PERMIT_ALL;
		}
		if (this.allowedMethods == null) {
			this.allowedMethods = DEFAULT_PERMIT_METHODS;
			this.resolvedMethods = DEFAULT_PERMIT_METHODS
					.stream().map(HttpMethod::valueOf).toList();
		}
		if (this.allowedHeaders == null) {
			this.allowedHeaders = DEFAULT_PERMIT_ALL;
		}
		if (this.maxAge == null) {
			this.maxAge = 1800L;
		}
		return this;
	}","/**
	 * By default {@code CorsConfiguration} does not permit any cross-origin
	 * requests and must be configured explicitly. Use this method to switch to
	 * defaults that permit all cross-origin requests for GET, HEAD, and POST,
	 * but not overriding any values that have already been set.
	 * <p>The following defaults are applied for values that are not set:
	 * <ul>
	 * <li>Allow all origins with the special value {@code ""*""} defined in the
	 * CORS spec. This is set only if neither {@link #setAllowedOrigins origins}
	 * nor {@link #setAllowedOriginPatterns originPatterns} are already set.</li>
	 * <li>Allow ""simple"" methods {@code GET}, {@code HEAD} and {@code POST}.</li>
	 * <li>Allow all headers.</li>
	 * <li>Set max age to 1800 seconds (30 minutes).</li>
	 * </ul>
	 */",67087d9d82a3a5339cc3dcc5
"void skipBlock(IndexInput in) throws IOException {
        final int numBits = in.readByte();
        if (numBits == ALL_VALUES_EQUAL) {
            in.readVInt();
            return;
        }
        assert numBits > 0 && numBits <= 32 : numBits;
        final int encodedSize = encodedSizes[numBits];
        in.seek(in.getFilePointer() + encodedSize);
    }","/**
     * Skip the next block of data.
     *
     * @param in the input where to read data
     * @throws IOException If there is a low-level I/O error
     */",67087d9d82a3a5339cc3dcc6
"public void setHeaderName(String headerName) {
		Assert.hasText(headerName, ""'headerName' must not be empty"");
		this.headerName = headerName;
	}","/**
	 * Set the name of the session header to use for the session ID.
	 * <p>The name is used to extract the session ID from the request headers as
	 * well to set the session ID on the response headers.
	 * <p>By default set to {@code DEFAULT_HEADER_NAME}
	 * @param headerName the header name
	 */",67087d9d82a3a5339cc3dcc7
"public double nextDouble(double n) {
        checkPositive(n, ""n"");
        return nextDouble() * n;
    }","/**
     * Returns a pseudorandom, uniformly distributed {@code double} value
     * between 0 (inclusive) and the specified value (exclusive).
     *
     * @param n the bound on the random number to be returned.  Must be
     *        positive.
     * @return the next value
     * @throws IllegalArgumentException if n is not positive
     */",67087d9d82a3a5339cc3dcc8
"public static LongsColumn create(ColumnarLongs column, ImmutableBitmap nullValueBitmap)
  {
    if (nullValueBitmap.isEmpty()) {
      return new LongsColumn(column);
    } else {
      return new LongsColumnWithNulls(column, nullValueBitmap);
    }
  }","/**
   * Factory method to create LongsColumn.
   */",67087d9d82a3a5339cc3dcc9
"public static int getNumChannels() {
        return httpChannels.size();
    }","/**
     * Returns the number of channels tracked globally.
     */",67087d9d82a3a5339cc3dcca
"protected QueryBuilder rewriteQuery(
        QB queryBuilder,
        QueryRewriteContext coordinatorRewriteContext,
        SearchExecutionContext shardRewriteContext
    ) throws IOException {
        // The first rewriteAndFetch call simulates rewriting on the coordinator node
        // The second rewriteAndFetch call simulates rewriting on the shard
        QueryBuilder rewritten = rewriteAndFetch(queryBuilder, coordinatorRewriteContext);
        // extra safety to fail fast - serialize the rewritten version to ensure it's serializable.
        assertSerialization(rewritten);
        rewritten = rewriteAndFetch(rewritten, shardRewriteContext);
        // extra safety to fail fast - serialize the rewritten version to ensure it's serializable.
        assertSerialization(rewritten);
        return rewritten;
    }","/**
     * Simulate rewriting the query builder in stages across the coordinator node and data node.
     * It is rewritten on the coordinator node first, then again on the data node.
     *
     * @param queryBuilder The query builder to rewrite
     * @param coordinatorRewriteContext the coordinator node rewrite context
     * @param shardRewriteContext The data node rewrite context
     * @return The rewritten query builder
     * @throws IOException
     */",67087d9d82a3a5339cc3dccb
"private static String stripPrefixOrNull(String str, String prefix) {
        return str == null || str.startsWith(prefix) == false ? null : str.substring(prefix.length());
    }","/**
     * @return If the string starts with the prefix, this returns the string without the prefix.
     *         Otherwise, this return null.
     */",67087d9d82a3a5339cc3dccc
"private void updateStageExecutions(StreamingPlanSection section, Map<PlanFragment, PlanFragment> oldToNewFragment)
    {
        StreamingPlanSection newSection = new StreamingPlanSection(rewriteStreamingSubPlan(section.getPlan(), oldToNewFragment), section.getChildren());
        PlanFragment sectionRootFragment = newSection.getPlan().getFragment();
        Optional<int[]> bucketToPartition;
        OutputBuffers outputBuffers;
        ExchangeLocationsConsumer locationsConsumer;
        if (isRootFragment(sectionRootFragment)) {
            bucketToPartition = Optional.of(new int[1]);
            outputBuffers = createInitialEmptyOutputBuffers(sectionRootFragment.getPartitioningScheme().getPartitioning().getHandle())
                    .withBuffer(new OutputBufferId(0), BROADCAST_PARTITION_ID)
                    .withNoMoreBufferIds();
            OutputBufferId rootBufferId = getOnlyElement(outputBuffers.getBuffers().keySet());
            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) ->
                    updateQueryOutputLocations(queryStateMachine, rootBufferId, tasks, noMoreExchangeLocations);
        }
        else {
            bucketToPartition = Optional.empty();
            outputBuffers = createDiscardingOutputBuffers();
            locationsConsumer = (fragmentId, tasks, noMoreExchangeLocations) -> {};
        }
        SectionExecution sectionExecution = sectionExecutionFactory.createSectionExecutions(
                session,
                newSection,
                locationsConsumer,
                bucketToPartition,
                outputBuffers,
                summarizeTaskInfo,
                remoteTaskFactory,
                splitSourceFactory,
                0);
        addStateChangeListeners(sectionExecution);
        Map<StageId, StageExecutionAndScheduler> updatedStageExecutions = sectionExecution.getSectionStages().stream()
                .collect(toImmutableMap(execution -> execution.getStageExecution().getStageExecutionId().getStageId(), identity()));
        synchronized (this) {
            stageExecutions.putAll(updatedStageExecutions);
        }
    }","/**
     * Utility function that rebuild a StreamingPlanSection, re-create stageExecutionAndScheduler for each of its stage, and finally update the stageExecutions map.
     */",67087d9d82a3a5339cc3dccd
"public static void releaseConnection(@Nullable Connection con, @Nullable DataSource dataSource) {
		try {
			doReleaseConnection(con, dataSource);
		}
		catch (SQLException ex) {
			logger.debug(""Could not close JDBC Connection"", ex);
		}
		catch (Throwable ex) {
			logger.debug(""Unexpected exception on closing JDBC Connection"", ex);
		}
	}","/**
	 * Close the given Connection, obtained from the given DataSource,
	 * if it is not managed externally (that is, not bound to the thread).
	 * @param con the Connection to close if necessary
	 * (if this is {@code null}, the call will be ignored)
	 * @param dataSource the DataSource that the Connection was obtained from
	 * (may be {@code null})
	 * @see #getConnection
	 */",67087d9d82a3a5339cc3dcce
"public void setConnectTimeout(int connectTimeout) {
		Assert.isTrue(connectTimeout >= 0, ""Timeout must be a non-negative value"");
		this.httpClient.setConnectTimeout(connectTimeout);
	}","/**
	 * Set the underlying connect timeout in milliseconds.
	 * A value of 0 specifies an infinite timeout.
	 * <p>Default is 5 seconds.
	 */",67087d9d82a3a5339cc3dccf
"@Nullable
  private static RexNode tryDecomposeConcatEquals(
      final RexCall concatCall,
      final RexNode matchRexNode,
      final RexBuilder rexBuilder
  )
  {
    final String matchValue = getAsString(matchRexNode);
    if (matchValue == null) {
      return null;
    }

    // We can decompose if all nonliterals are separated by literals, and if each literal appears in the matchValue
    // string exactly the number of times that it appears in the call to CONCAT. (In this case, the concatenation can
    // be unambiguously reversed.)
    final StringBuilder regexBuilder = new StringBuilder();
    final List<RexNode> nonLiterals = new ArrayList<>();

    // Order is important in literalCounter, since we look for later literals only after the first occurrences of
    // earlier literals. So, use LinkedHashMultiset to preserve order.
    final Multiset<String> literalCounter = LinkedHashMultiset.create();
    boolean expectLiteral = false; // If true, next operand must be a literal.
    for (int i = 0; i < concatCall.getOperands().size(); i++) {
      final RexNode operand = concatCall.getOperands().get(i);
      if (RexUtil.isLiteral(operand, true)) {
        final String operandValue = getAsString(operand);
        if (operandValue == null || operandValue.isEmpty()) {
          return null;
        }

        regexBuilder.append(Pattern.quote(operandValue));
        literalCounter.add(operandValue);
        expectLiteral = false;
      } else {
        if (expectLiteral) {
          return null;
        }

        nonLiterals.add(operand);
        regexBuilder.append(""(.*)"");
        expectLiteral = true;
      }
    }

    // Verify, using literalCounter, that each literal appears in the matchValue the correct number of times.
    int checkPos = 0;
    for (Multiset.Entry<String> entry : literalCounter.entrySet()) {
      final int occurrences = countOccurrences(matchValue.substring(checkPos), entry.getElement());
      if (occurrences > entry.getCount()) {
        // If occurrences > entry.getCount(), the match is ambiguous; consider concat(x, 'x', y) = '2x3x4'
        return null;
      } else if (occurrences < entry.getCount()) {
        return impossibleMatch(nonLiterals, rexBuilder);
      } else {
        // Literal N + 1 can be ignored if it appears before literal N, because it can't possibly match. Consider the
        // case where [CONCAT(a, ' (', b, 'x', ')') = 'xxx (2x4)']. This is unambiguous, because 'x' only appears once
        // after the first ' ('.
        checkPos = matchValue.indexOf(entry.getElement()) + 1;
      }
    }

    // Apply the regex to the matchValue to get the expected value of each non-literal.
    final Pattern regex = Pattern.compile(regexBuilder.toString(), Pattern.DOTALL);
    final Matcher matcher = regex.matcher(matchValue);
    if (matcher.matches()) {
      final List<RexNode> conditions = new ArrayList<>(nonLiterals.size());
      for (int i = 0; i < nonLiterals.size(); i++) {
        final RexNode operand = nonLiterals.get(i);
        conditions.add(
            rexBuilder.makeCall(
                SqlStdOperatorTable.EQUALS,
                operand,
                rexBuilder.makeLiteral(matcher.group(i + 1))
            )
        );
      }

      return RexUtil.composeConjunction(rexBuilder, conditions);
    } else {
      return impossibleMatch(nonLiterals, rexBuilder);
    }
  }","/**
   * Convert [CONCAT(x, '-', y) = 'a-b'] => [x = 'a' AND y = 'b'].
   *
   * @param concatCall   the call to concat, i.e. CONCAT(x, '-', y)
   * @param matchRexNode the literal being matched, i.e. 'a-b'
   * @param rexBuilder   rex builder
   */",67087d9d82a3a5339cc3dcd0
"public synchronized <T> boolean containsAsset (T asset) {
		ObjectMap<String, RefCountedContainer> assetsByType = assets.get(asset.getClass());
		if (assetsByType == null) return false;
		for (RefCountedContainer assetRef : assetsByType.values())
			if (assetRef.object == asset || asset.equals(assetRef.object)) return true;
		return false;
	}","/** @param asset the asset
	 * @return whether the asset is contained in this manager */",67087d9d82a3a5339cc3dcd1
"private static int directCompareCompressedBigDecimal(CompressedBigDecimal lhs, CompressedBigDecimal rhs)
  {
    // this short-circuit serves two functions: 1. it speeds up comparison in +/- cases 2. it avoids the case of
    // overflow of positive - negative and negative - positive. p - p and n - n both fit in the given allotment of ints
    if (lhs.isNonNegative() && rhs.isNegative()) {
      return 1;
    } else if (lhs.isNegative() && rhs.isNonNegative()) {
      return -1;
    }

    int size = Math.max(lhs.getArraySize(), rhs.getArraySize());
    int[] result = new int[size];
    int borrow = 0;
    // for each argument, if it's negative, our extension will be -1/INT_MASK (all 1s). else, all 0s
    long lhsExtension = lhs.getArrayEntry(lhs.getArraySize() - 1) < 0 ? INT_MASK : 0;
    long rhsExtension = rhs.getArrayEntry(rhs.getArraySize() - 1) < 0 ? INT_MASK : 0;
    boolean nonZeroValues = false;

    for (int i = 0; i < size; i++) {
      // ""dynamically"" extend lhs/rhs if it's shorter than the other using extensions computed above
      long leftElement = i < lhs.getArraySize() ? (INT_MASK & lhs.getArrayEntry(i)) : lhsExtension;
      long rightElement = i < rhs.getArraySize() ? (INT_MASK & rhs.getArrayEntry(i)) : rhsExtension;
      long resultElement = leftElement - rightElement - borrow;

      borrow = 0;

      if (resultElement < 0) {
        borrow = 1;
        resultElement += 1L << 32;
      }

      result[i] = (int) resultElement;

      if (!nonZeroValues && resultElement != 0) {
        nonZeroValues = true;
      }
    }

    int signum = 0;

    if (nonZeroValues) {
      signum = result[size - 1] < 0 ? -1 : 1;
    }

    return signum;
  }","/**
   * performs a subtraction of lhs - rhs to compare elements
   *
   * @param lhs
   * @param rhs
   * @return
   */",67087d9d82a3a5339cc3dcd2
"public void add (Renderable renderable) {
		if (!building) throw new GdxRuntimeException(""Can only add items to the ModelCache in between .begin() and .end()"");
		if (renderable.bones == null)
			items.add(renderable);
		else
			renderables.add(renderable);
	}","/** Adds the specified {@link Renderable} to the cache. Must be called in between a call to {@link #begin()} and
	 * {@link #end()}. All member objects might (depending on possibilities) be used by reference and should not change while the
	 * cache is used. If the {@link Renderable#bones} member is not null then skinning is assumed and the renderable will be added
	 * as-is, by reference. Otherwise the renderable will be merged with other renderables as much as possible, depending on the
	 * {@link Mesh#getVertexAttributes()}, {@link Renderable#material} and primitiveType (in that order). The
	 * {@link Renderable#environment}, {@link Renderable#shader} and {@link Renderable#userData} values (if any) are removed.
	 * @param renderable The {@link Renderable} to add, should not change while the cache is needed. */",67087d9d82a3a5339cc3dcd3
"@Nullable
	public final ClassLoader getBeanClassLoader() {
		return this.reader.getBeanClassLoader();
	}","/**
	 * Return the bean class loader to use, if any.
	 * <p>Note that this will be null in regular scenarios,
	 * as an indication to lazily resolve bean classes.
	 * @see XmlBeanDefinitionReader#setBeanClassLoader
	 */",67087d9d82a3a5339cc3dcd4
"private void initSegmentAssignerIfRequired()
    {
      if (segmentAssigner != null || loadQueueManager == null) {
        return;
      }

      Preconditions.checkNotNull(druidCluster);
      Preconditions.checkNotNull(balancerStrategy);
      Preconditions.checkNotNull(usedSegments);
      Preconditions.checkNotNull(stats);

      if (segmentLoadingConfig == null) {
        segmentLoadingConfig = SegmentLoadingConfig.create(coordinatorDynamicConfig, usedSegments.size());
      }

      segmentAssigner = new StrategicSegmentAssigner(
          loadQueueManager,
          druidCluster,
          balancerStrategy,
          segmentLoadingConfig,
          stats
      );
    }","/**
     * Initializes {@link StrategicSegmentAssigner} used by historical management
     * duties for segment load/drop/move.
     */",67087d9d82a3a5339cc3dcd5
"public static void throwIfDoesNotExist(ConfigDataResource resource, Path pathToCheck) {
		throwIfDoesNotExist(resource, Files.exists(pathToCheck));
	}","/**
	 * Throw a {@link ConfigDataNotFoundException} if the specified {@link Path} does not
	 * exist.
	 * @param resource the config data resource
	 * @param pathToCheck the path to check
	 */",67087d9d82a3a5339cc3dcd6
"public final void setAngularVelocity (float w) {
		if (m_type == BodyType.STATIC) {
			return;
		}

		if (w * w > 0f) {
			setAwake(true);
		}

		m_angularVelocity = w;
	}","/** Set the angular velocity.
	 * 
	 * @param omega the new angular velocity in radians/second. */",67087d9d82a3a5339cc3dcd7
"public static CompatibilityVersions staticCurrent() {
        return new CompatibilityVersions(TransportVersion.current(), Map.of());
    }","/**
     * Current compatibility versions that can be determined statically
     *
     * <p>Some of our compatibility versions may be constructed at runtime, but in
     * many tests those will not be needed. This utility method returns only the ""current""
     * values for statically defined versions, like {@link TransportVersion#current()}.
     *
     * @return Compatibility versions known at compile time.
     */",67087d9d82a3a5339cc3dcd8
"@Override
        protected AzureSeedHostsProvider createSeedHostsProvider(
            final Settings settingsToUse,
            final AzureComputeService azureComputeService,
            final TransportService transportService,
            final NetworkService networkService
        ) {
            return new AzureSeedHostsProvider(settingsToUse, azureComputeService, transportService, networkService) {
                @Override
                protected String resolveInstanceAddress(final HostType hostTypeValue, final RoleInstance instance) {
                    if (hostTypeValue == HostType.PRIVATE_IP) {
                        DiscoveryNode discoveryNode = nodes.get(instance.getInstanceName());
                        if (discoveryNode != null) {
                            // Format the InetSocketAddress to a format that contains the port number
                            return NetworkAddress.format(discoveryNode.getAddress().address());
                        }
                    }
                    return super.resolveInstanceAddress(hostTypeValue, instance);
                }
            };
        }","/**
         * Defines a {@link AzureSeedHostsProvider} for testing purpose that is able to resolve
         * network addresses for Azure instances running on the same host but different ports.
         */",67087d9d82a3a5339cc3dcd9
"@Nullable
	protected String getMessageFromParent(String code, @Nullable Object[] args, Locale locale) {
		MessageSource parent = getParentMessageSource();
		if (parent != null) {
			if (parent instanceof AbstractMessageSource abstractMessageSource) {
				// Call internal method to avoid getting the default code back
				// in case of ""useCodeAsDefaultMessage"" being activated.
				return abstractMessageSource.getMessageInternal(code, args, locale);
			}
			else {
				// Check parent MessageSource, returning null if not found there.
				// Covers custom MessageSource impls and DelegatingMessageSource.
				return parent.getMessage(code, args, null, locale);
			}
		}
		// Not found in parent either.
		return null;
	}","/**
	 * Try to retrieve the given message from the parent {@code MessageSource}, if any.
	 * @param code the code to lookup up, such as 'calculator.noRateSet'
	 * @param args array of arguments that will be filled in for params
	 * within the message
	 * @param locale the locale in which to do the lookup
	 * @return the resolved message, or {@code null} if not found
	 * @see #getParentMessageSource()
	 */",67087d9d82a3a5339cc3dcda
"public void registerCustomEditor(Class<?> requiredType, PropertyEditor propertyEditor) {
		TypeConverter converter = getTypeConverter();
		if (!(converter instanceof PropertyEditorRegistry registry)) {
			throw new IllegalStateException(
					""TypeConverter does not implement PropertyEditorRegistry interface: "" + converter);
		}
		registry.registerCustomEditor(requiredType, propertyEditor);
	}","/**
	 * Register the given custom property editor for all properties of the given type.
	 * <p>Typically used in conjunction with the default
	 * {@link org.springframework.beans.SimpleTypeConverter}; will work with any
	 * TypeConverter that implements the PropertyEditorRegistry interface as well.
	 * @param requiredType type of the property
	 * @param propertyEditor editor to register
	 * @see #setTypeConverter
	 * @see org.springframework.beans.PropertyEditorRegistry#registerCustomEditor
	 */",67087d9d82a3a5339cc3dcdb
"public void createElasticUser(char[] passwordHash, ActionListener<Void> listener) {
        updateReservedUser(ElasticUser.NAME, passwordHash, DocWriteRequest.OpType.CREATE, RefreshPolicy.IMMEDIATE, listener);
    }","/**
     * Asynchronous method to create the elastic superuser with the given password hash. The cache for the user will be
     * cleared after the document has been indexed.
     */",67087d9d82a3a5339cc3dcdc
"@Override
    protected boolean canAccessAllDescribedEntities(IndexDescriptor descriptor) {
        propertyIds = descriptor.schema().getPropertyIds();
        int[] labelIds = descriptor.schema().getEntityTokenIds();
        AccessMode accessMode = read.getAccessMode();

        for (int label : labelIds) {
            /*
             * If there can be nodes in the index that that are disallowed to traverse,
             * post-filtering is needed.
             */
            if (!accessMode.allowsTraverseAllNodesWithLabel(label)) {
                return false;
            }
        }

        for (int propId : propertyIds) {
            /*
             * If reading the property is denied for some label,
             * there can be property values in the index that are disallowed,
             * so post-filtering is needed.
             */
            if (accessMode.disallowsReadPropertyForSomeLabel(propId)) {
                return false;
            }

            /*
             * If reading the property is not granted for all labels of the the index,
             * there can be property values in the index that are disallowed,
             * so post-filtering is needed.
             */
            for (int label : labelIds) {
                if (!accessMode.allowsReadNodeProperty(() -> Labels.from(label), propId)) {
                    return false;
                }
            }
        }
        return true;
    }","/**
     * Check that the user is allowed to access all nodes and properties given by the index descriptor.
     * <p>
     * If the current user is allowed to traverse all labels used in this index and read the properties
     * of all nodes in the index, we can skip checking on every node we get back.
     */",67087d9d82a3a5339cc3dcdd
"public void testBody() throws Exception {
        String body = ""{ \""field\"": \""value\"" }"";
        StringEntity entity = new StringEntity(body, ContentType.APPLICATION_JSON);
        for (String method : Arrays.asList(""DELETE"", ""GET"", ""PATCH"", ""POST"", ""PUT"")) {
            for (int okStatusCode : getOkStatusCodes()) {
                Request request = new Request(method, ""/"" + okStatusCode);
                request.setEntity(entity);
                Response response = restClient.performRequest(request);
                assertThat(response.getStatusLine().getStatusCode(), equalTo(okStatusCode));
                assertThat(EntityUtils.toString(response.getEntity()), equalTo(body));
            }
            for (int errorStatusCode : getAllErrorStatusCodes()) {
                Request request = new Request(method, ""/"" + errorStatusCode);
                request.setEntity(entity);
                try {
                    restClient.performRequest(request);
                    fail(""request should have failed"");
                } catch (ResponseException e) {
                    Response response = e.getResponse();
                    assertThat(response.getStatusLine().getStatusCode(), equalTo(errorStatusCode));
                    assertThat(EntityUtils.toString(response.getEntity()), equalTo(body));
                    assertExceptionStackContainsCallingMethod(e);
                }
            }
        }
        for (String method : Arrays.asList(""HEAD"", ""OPTIONS"", ""TRACE"")) {
            Request request = new Request(method, ""/"" + randomStatusCode(getRandom()));
            request.setEntity(entity);
            try {
                performRequestSyncOrAsync(restClient, request);
                fail(""request should have failed"");
            } catch (UnsupportedOperationException e) {
                assertThat(e.getMessage(), equalTo(method + "" with body is not supported""));
            }
        }
    }","/**
     * End to end test for request and response body. Exercises the mock http client ability to send back
     * whatever body it has received.
     */",67087d9d82a3a5339cc3dcde
"public long cpuTimeMillis() {
            long cpuTimeNanos = cpuClock.cpuTimeNanos(transactionThreadId);
            return (cpuTimeNanos < 0) ? -1 : NANOSECONDS.toMillis(cpuTimeNanos - cpuTimeNanosWhenQueryStarted);
        }","/**
         * Return CPU time used by current transaction in milliseconds
         * @return the current CPU time used by the transaction, in milliseconds.
         */",67087d9d82a3a5339cc3dcdf
"protected static List<String> generateTimesForSplits(Instant defaultUpperBound, Duration maxQueryRangeDurationRequested, Duration queryChunkSizeDurationRequested,
            PrometheusTableHandle tableHandle)
    {
        Optional<PrometheusPredicateTimeInfo> predicateRange = tableHandle.getPredicate()
                .flatMap(PrometheusSplitManager::determinePredicateTimes);

        EffectiveLimits effectiveLimits = new EffectiveLimits(defaultUpperBound, maxQueryRangeDurationRequested, predicateRange);
        Instant upperBound = effectiveLimits.getUpperBound();
        java.time.Duration maxQueryRangeDuration = effectiveLimits.getMaxQueryRangeDuration();

        java.time.Duration queryChunkSizeDuration = java.time.Duration.ofMillis(queryChunkSizeDurationRequested.toMillis());
        checkState(!maxQueryRangeDuration.isNegative(), ""prometheus.max-query-duration may not be negative"");
        checkState(!queryChunkSizeDuration.isNegative(), ""prometheus.query-chunk-duration may not be negative"");
        checkState(!queryChunkSizeDuration.isZero(), ""prometheus.query-chunk-duration may not be zero"");
        BigDecimal maxQueryRangeDecimal = BigDecimal.valueOf(maxQueryRangeDuration.getSeconds()).add(BigDecimal.valueOf(maxQueryRangeDuration.getNano(), 9));
        BigDecimal queryChunkSizeDecimal = BigDecimal.valueOf(queryChunkSizeDuration.getSeconds()).add(BigDecimal.valueOf(queryChunkSizeDuration.getNano(), 9));

        int numChunks = maxQueryRangeDecimal.divide(queryChunkSizeDecimal, 0, RoundingMode.UP).intValue();

        return Lists.reverse(IntStream.range(0, numChunks)
                .mapToObj(n -> {
                    long endTime = upperBound.toEpochMilli() -
                            n * queryChunkSizeDuration.toMillis() - n * OFFSET_MILLIS;
                    return endTime;
                })
                .map(PrometheusSplitManager::decimalSecondString)
                .collect(Collectors.toList()));
    }","/**
     * Utility method to get the end times in decimal seconds that divide up the query into chunks
     * The times will be used in queries to Prometheus like: `http://localhost:9090/api/v1/query?query=up[21d]&time=1568229904.000""`
     * ** NOTE: Prometheus instant query wants the duration and end time specified.
     * We use now() for the defaultUpperBound when none is specified, for instance, from predicate push down
     *
     * @param defaultUpperBound a LocalDateTime likely from PrometheusTimeMachine class for testability
     * @return list of end times as decimal epoch seconds, like [""1568053244.143"", ""1568926595.321""]
     */",67087d9d82a3a5339cc3dce0
"protected boolean isMainThread(Thread thread) {
		return thread.getName().equals(""main"");
	}","/**
	 * Returns whether the given {@code thread} is considered to be the main thread.
	 * @param thread the thread to check
	 * @return {@code true} if it's the main thread, otherwise {@code false}
	 * @since 2.4.0
	 */",67087d9d82a3a5339cc3dce1
"private void setDiskAllocationDeciderEnabled(boolean value) {
        Settings.Builder settings = value
            ? Settings.builder().putNull(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED_SETTING.getKey())
            : Settings.builder().put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED_SETTING.getKey(), false);
        updateClusterSettings(settings);
    }",/** Enables or disables the cluster disk allocation decider **/,67087d9d82a3a5339cc3dce2
"private static SecureString getSecureSetting(Settings settings, Setting<SecureString> secureSetting) {
                SecureString secureString = secureSetting.get(settings);
                if (secureString != null && secureString.length() > 0) {
                    return secureString;
                } else {
                    return null;
                }
            }","/**
             * Finds a setting, and then a secure setting if the setting is null, or returns null if one does not exist. This differs
             * from other getSetting calls in that it allows for null whereas the other methods throw an exception.
             * <p>
             * Note: if your setting was not previously secure, than the string reference that is in the setting object is still
             * insecure. This is only constructing a new SecureString with the char[] of the insecure setting.
             */",67087d9d82a3a5339cc3dce3
"public DateTimeFormatter createDateTimeFormatter() {
		return createDateTimeFormatter(DateTimeFormatter.ofLocalizedDateTime(FormatStyle.MEDIUM));
	}","/**
	 * Create a new {@code DateTimeFormatter} using this factory.
	 * <p>If no specific pattern or style has been defined,
	 * {@link FormatStyle#MEDIUM medium date time format} will be used.
	 * @return a new date time formatter
	 * @see #createDateTimeFormatter(DateTimeFormatter)
	 */",67087d9d82a3a5339cc3dce4
"@SuppressWarnings(""unchecked"")
        public Source extractSource(Source root) {
            // Isolate the nested json array object that matches with nested hit and wrap it back into the same json
            // structure with the nested json array object being the actual content. The latter is important, so that
            // features like source filtering and highlighting work consistent regardless of whether the field points
            // to a json object array for consistency reasons on how we refer to fields
            Map<String, Object> rootSourceAsMap = root.source();
            Map<String, Object> nestedSourceAsMap = new HashMap<>();
            Map<String, Object> current = nestedSourceAsMap;
            for (SearchHit.NestedIdentity nested = this; nested != null; nested = nested.getChild()) {
                String nestedPath = nested.getField().string();
                current.put(nestedPath, new HashMap<>());
                List<Map<?, ?>> nestedParsedSource = XContentMapValues.extractNestedSources(nestedPath, rootSourceAsMap);
                if (nestedParsedSource == null) {
                    return Source.empty(root.sourceContentType());
                }
                if (nested.getOffset() > nestedParsedSource.size() - 1) {
                    throw new IllegalStateException(""Error retrieving path "" + this.field);
                }
                rootSourceAsMap = (Map<String, Object>) nestedParsedSource.get(nested.getOffset());
                if (nested.getChild() == null) {
                    current.put(nestedPath, rootSourceAsMap);
                } else {
                    Map<String, Object> next = new HashMap<>();
                    current.put(nestedPath, next);
                    current = next;
                }
            }
            return Source.fromMap(nestedSourceAsMap, root.sourceContentType());
        }","/**
         * Extracts the part of the root source that applies to this particular NestedIdentity, while
         * preserving the enclosing path structure.
         *
         * For a root document that looks like this:
         * { ""children"" :
         *    [
         *      { ""grandchildren"" : [ { ""field"" : ""value1"" }, { ""field"" : ""value2"" } ] },
         *      { ""grandchildren"" : [ { ""field"" : ""value3"" }, { ""field"" : ""value4"" } ] }
         *   ]
         * }
         *
         * Extracting the NestedIdentity of the first child and second grandchild results in a source that looks like this:
         * { ""children"" : { ""grandchildren"" : { ""field"" : ""value2"" } } }
         *
         * If the relevant child source object does not exist in the root, then we return {@link Source#empty(XContentType)}
         */",67087d9d82a3a5339cc3dce5
"void put(
        final CacheKey cacheKey,
        final long fileLength,
        final Path cacheDir,
        final String cacheFileUuid,
        final SortedSet<ByteRange> cacheFileRanges
    ) throws Exception {

        ensureLifecycleInitializing();
        final Path path = cacheDir.resolve(cacheFileUuid);
        if (Files.exists(path) == false) {
            throw new FileNotFoundException(""Cache file ["" + path + ""] not found"");
        }
        cache.put(cacheKey, new CacheFile(cacheKey, fileLength, path, cacheFileRanges, this.cacheFilesListener));
    }","/**
     * Computes a new {@link CacheFile} instance using the specified cache file information (file length, file name, parent directory and
     * already available cache ranges) and associates it with the specified {@link CacheKey} in the cache. If the key is already
     * associated with a {@link CacheFile}, the previous instance is replaced by a new one.
     *
     * This method can only be used before the {@link CacheService} is started.
     *
     * @param cacheKey        the cache key with which the new {@link CacheFile} instance is to be associated
     * @param fileLength      the length of the cache file
     * @param cacheDir        the cache directory where the cache file on disk is located
     * @param cacheFileUuid   the name of the cache file on disk (should be a UUID)
     * @param cacheFileRanges the set of ranges that are known to be already available/completed for this cache file
     * @throws Exception if this method is used when the {@link CacheService} is not initializing
     */",67087d9d82a3a5339cc3dce6
"public void clear(NamedDatabaseId databaseId) {
        Preconditions.checkArgument(
                databaseId != null,
                ""Only queries targeting a specific database are expected in the recent query buffer, ""
                        + ""clearing non-database queries will have no effect."");

        queries.clearIf(q -> databaseId.equals(q.databaseId));
    }","/**
     * Clear all query meta data for the given database from this buffer.
     */",67087d9d82a3a5339cc3dce7
"public static int getTypeDifferenceWeight(Class<?>[] paramTypes, Object[] args) {
		int result = 0;
		for (int i = 0; i < paramTypes.length; i++) {
			if (!ClassUtils.isAssignableValue(paramTypes[i], args[i])) {
				return Integer.MAX_VALUE;
			}
			if (args[i] != null) {
				Class<?> paramType = paramTypes[i];
				Class<?> superClass = args[i].getClass().getSuperclass();
				while (superClass != null) {
					if (paramType.equals(superClass)) {
						result = result + 2;
						superClass = null;
					}
					else if (ClassUtils.isAssignable(paramType, superClass)) {
						result = result + 2;
						superClass = superClass.getSuperclass();
					}
					else {
						superClass = null;
					}
				}
				if (paramType.isInterface()) {
					result = result + 1;
				}
			}
		}
		return result;
	}","/**
	 * Algorithm that judges the match between the declared parameter types of a candidate method
	 * and a specific list of arguments that this method is supposed to be invoked with.
	 * <p>Determines a weight that represents the class hierarchy difference between types and
	 * arguments. A direct match, i.e. type Integer &rarr; arg of class Integer, does not increase
	 * the result - all direct matches means weight 0. A match between type Object and arg of
	 * class Integer would increase the weight by 2, due to the superclass 2 steps up in the
	 * hierarchy (i.e. Object) being the last one that still matches the required type Object.
	 * Type Number and class Integer would increase the weight by 1 accordingly, due to the
	 * superclass 1 step up the hierarchy (i.e. Number) still matching the required type Number.
	 * Therefore, with an arg of type Integer, a constructor (Integer) would be preferred to a
	 * constructor (Number) which would in turn be preferred to a constructor (Object).
	 * All argument weights get accumulated.
	 * <p>Note: This is the algorithm used by MethodInvoker itself and also the algorithm
	 * used for constructor and factory method selection in Spring's bean container (in case
	 * of lenient constructor resolution which is the default for regular bean definitions).
	 * @param paramTypes the parameter types to match
	 * @param args the arguments to match
	 * @return the accumulated weight for all arguments
	 */",67087d9d82a3a5339cc3dce8
"static void validateSchemaRule(SchemaRule schemaRule, KernelVersion kernelVersion)
            throws TransactionFailureException {
        if (kernelVersion.isAtLeast(LATEST_SCHEMA_CHANGE)) {
            return;
        }

        if (schemaRule instanceof final IndexDescriptor index) {
            final var schemaType = ""index"";

            if (index.getIndexType() == IndexType.VECTOR) {
                switch (index.schema().entityType()) {
                    case NODE -> {
                        if (kernelVersion.isLessThan(VERSION_NODE_VECTOR_INDEX_INTRODUCED)) {
                            throw upgradeNeededForSchemaRule(
                                    schemaType, index, kernelVersion, VERSION_NODE_VECTOR_INDEX_INTRODUCED);
                        }
                    }
                    case RELATIONSHIP -> {
                        if (kernelVersion.isLessThan(VERSION_VECTOR_2_INTRODUCED)) {
                            throw upgradeNeededForSchemaRule(
                                    schemaType, index, kernelVersion, VERSION_VECTOR_2_INTRODUCED);
                        }
                    }
                }
            }

        } else if (schemaRule instanceof final ConstraintDescriptor constraint) {
            final var schemaType = ""constraint"";

            if ((constraint.isRelationshipUniquenessConstraint() || constraint.isRelationshipKeyConstraint())
                    && kernelVersion.isLessThan(VERSION_REL_UNIQUE_CONSTRAINTS_INTRODUCED)) {
                throw upgradeNeededForSchemaRule(
                        schemaType, constraint, kernelVersion, VERSION_REL_UNIQUE_CONSTRAINTS_INTRODUCED);
            }

            if (constraint.isPropertyTypeConstraint()) {
                if (kernelVersion.isLessThan(VERSION_TYPE_CONSTRAINTS_INTRODUCED)) {
                    throw upgradeNeededForSchemaRule(
                            schemaType, constraint, kernelVersion, VERSION_TYPE_CONSTRAINTS_INTRODUCED);
                }

                final var propertyType = constraint.asPropertyTypeConstraint().propertyType();
                if ((TypeRepresentation.isUnion(propertyType) || TypeRepresentation.hasListTypes(propertyType))
                        && kernelVersion.isLessThan(VERSION_UNIONS_AND_LIST_TYPE_CONSTRAINTS_INTRODUCED)) {
                    throw upgradeNeededForSchemaRule(
                            schemaType, constraint, kernelVersion, VERSION_UNIONS_AND_LIST_TYPE_CONSTRAINTS_INTRODUCED);
                }
            }

        } else {
            throw new IllegalArgumentException(
                    ""Unknown %s. Provided: %s"".formatted(SchemaRule.class.getSimpleName(), schemaRule));
        }
    }","/**
     * Validates that the kernelVersion is now up to what it needs to be to allow new types.
     * Things should only have been let through this far if the runtime version was high enough
     * and there was hope that the upgrade transaction would run before this. If for some reason
     * the upgrade transaction has not succeeded we need to abort this commit with unsupported
     * features now.
     */",67087d9d82a3a5339cc3dce9
"public StringBuilder append (CharSequence csq) {
		if (csq == null) {
			appendNull();
		} else if (csq instanceof StringBuilder) {
			StringBuilder builder = (StringBuilder)csq;
			append0(builder.chars, 0, builder.length);
		} else {
			append0(csq.toString());
		}
		return this;
	}","/** Appends the string representation of the specified {@code CharSequence}. If the {@code CharSequence} is {@code null}, then
	 * the string {@code ""null""} is appended.
	 * 
	 * @param csq the {@code CharSequence} to append.
	 * @return this builder. */",67087d9d82a3a5339cc3dcea
"public static long estimateRamBytes(final long size) {
        return ESTIMATOR.ramBytesEstimated(size);
    }",/** Estimates the number of bytes that would be consumed by an array of the given size. */,67087d9d82a3a5339cc3dceb
"static <Request extends AbstractBulkByScrollRequest<Request>> void executeSlicedAction(
        BulkByScrollTask task,
        Request request,
        ActionType<BulkByScrollResponse> action,
        ActionListener<BulkByScrollResponse> listener,
        Client client,
        DiscoveryNode node,
        Runnable workerAction
    ) {
        if (task.isLeader()) {
            sendSubRequests(client, action, node.getId(), task, request, listener);
        } else if (task.isWorker()) {
            workerAction.run();
        } else {
            throw new AssertionError(""Task should have been initialized at this point."");
        }
    }","/**
     * Takes an action and a {@link BulkByScrollTask} and runs it with regard to whether this task is a
     * leader or worker.
     *
     * If this task is a worker, the worker action in the given {@link Runnable} will be started on the local
     * node. If the task is a leader (i.e. the number of slices is more than 1), then a subrequest will be
     * created for each slice and sent.
     *
     * This method can only be called after the task state is initialized {@link #initTaskState}.
     */",67087d9d82a3a5339cc3dcec
"public void getVertex2 (Vector2 vec) {
		jniGetVertex2(addr, vertex);
		vec.x = vertex[0];
		vec.y = vertex[1];
	}","/*
		b2EdgeShape* edge = (b2EdgeShape*)addr; 
		vertex[0] = edge->m_vertex1.x;
		vertex[1] = edge->m_vertex1.y;
	*/",67087d9d82a3a5339cc3dced
"public SessionBuilder setSystemProperty(String propertyName, String propertyValue)
        {
            systemProperties.put(propertyName, propertyValue);
            return this;
        }","/**
         * Sets a system property for the session.  The property name and value must
         * only contain characters from US-ASCII and must not be for '='.
         */",67087d9d82a3a5339cc3dcee
"public boolean hasIndexScope() {
        return properties.contains(Property.IndexScope);
    }","/**
     * Returns <code>true</code> if this setting has an index scope, otherwise <code>false</code>
     */",67087d9d82a3a5339cc3dcef
"public ResultMatcher maxAge(String name, Matcher<? super Integer> matcher) {
		return result -> {
			Cookie cookie = getCookie(result, name);
			assertThat(""Response cookie '"" + name + ""' maxAge"", cookie.getMaxAge(), matcher);
		};
	}","/**
	 * Assert a cookie's maxAge with a Hamcrest {@link Matcher}.
	 */",67087d9d82a3a5339cc3dcf0
"public synchronized int totalFileCount() {
            return fileDetails.size();
        }","/**
         * total number of files that are part of this recovery, both re-used and recovered
         */",67087d9d82a3a5339cc3dcf1
"public static BinaryDocValues toString(final SortedDocValues values) {
        return new AbstractBinaryDocValues() {

            @Override
            public BytesRef binaryValue() throws IOException {
                return values.lookupOrd(values.ordValue());
            }

            @Override
            public boolean advanceExact(int doc) throws IOException {
                return values.advanceExact(doc);
            }
        };
    }","/**
     * Return a {@link String} representation of the provided values. That is
     * typically used for scripts or for the `map` execution mode of terms aggs.
     * NOTE: this is slow!
     */",67087d9d82a3a5339cc3dcf2
"private static boolean containsValues(InternalAggregation agg) {
        // Stats & ExtendedStats
        if (agg instanceof InternalStats) {
            return hasValue((InternalStats) agg);
        }
        if (agg instanceof InternalMatrixStats) {
            return hasValue((InternalMatrixStats) agg);
        }
        if (agg instanceof Max) {
            return hasValue((Max) agg);
        }
        if (agg instanceof Min) {
            return hasValue((Min) agg);
        }
        if (agg instanceof InternalAvg) {
            return hasValue((InternalAvg) agg);
        }
        if (agg instanceof Sum) {
            return hasValue((Sum) agg);
        }
        if (agg instanceof InternalTDigestPercentileRanks) {
            return hasValue((InternalTDigestPercentileRanks) agg);
        }
        if (agg instanceof InternalTDigestPercentiles) {
            return hasValue((InternalTDigestPercentiles) agg);
        }
        return true;
    }","/**
     * Check if the given aggregate has been executed and has computed values
     * or not (the bucket is null).
     */",67087d9d82a3a5339cc3dcf3
"default Map<String, Object> getErrorAttributes(ServerRequest request, ErrorAttributeOptions options) {
		return Collections.emptyMap();
	}","/**
	 * Return a {@link Map} of the error attributes. The map can be used as the model of
	 * an error page, or returned as a {@link ServerResponse} body.
	 * @param request the source request
	 * @param options options for error attribute contents
	 * @return a map of error attributes
	 */",67087d9d82a3a5339cc3dcf4
"@Test
    public void findAndDeleteFiles_withNoPriorVersions_deletesNothing() {
        // given:
        when(gitWrapper.listVersions(anyString())).thenAnswer(args -> Stream.of());

        // when:
        findAndDeleteFiles(
            gitWrapper,
            deleteHelper,
            QualifiedVersion.of(""7.16.0""),
            Set.of(new File(""rootDir/docs/changelog/1234.yml"")),
            Path.of(""rootDir"")
        );

        // then:
        verify(gitWrapper, never()).listFiles(anyString(), anyString());
    }","/**
     * Check that if there are files in the checkout, but no prior versions in the git
     * history, the task deletes nothing.
     */",67087d9d82a3a5339cc3dcf5
"public void setDefaultTransactionIsolationName(String constantName) {
		Assert.hasText(constantName, ""'constantName' must not be null or blank"");
		Integer defaultTransactionIsolation = constants.get(constantName);
		Assert.notNull(defaultTransactionIsolation, ""Only transaction isolation constants allowed"");
		this.defaultTransactionIsolation = defaultTransactionIsolation;
	}","/**
	 * Set the default transaction isolation level by the name of the corresponding
	 * constant in {@link java.sql.Connection} &mdash; for example,
	 * {@code ""TRANSACTION_SERIALIZABLE""}.
	 * @param constantName name of the constant
	 * @see #setDefaultTransactionIsolation
	 * @see java.sql.Connection#TRANSACTION_READ_UNCOMMITTED
	 * @see java.sql.Connection#TRANSACTION_READ_COMMITTED
	 * @see java.sql.Connection#TRANSACTION_REPEATABLE_READ
	 * @see java.sql.Connection#TRANSACTION_SERIALIZABLE
	 */",67087d9d82a3a5339cc3dcf6
"public void cleanup(long repositoryDataGeneration, IndexVersion repositoryFormatIndexVersion, ActionListener<DeleteResult> listener) {
        createSnapshotsDeletion(
            List.of(),
            repositoryDataGeneration,
            repositoryFormatIndexVersion,
            listener.delegateFailureAndWrap((delegate, snapshotsDeletion) -> snapshotsDeletion.runCleanup(delegate))
        );
    }","/**
     * Runs cleanup actions on the repository. Increments the repository state id by one before executing any modifications on the
     * repository.
     * TODO: Add shard level cleanups
     * TODO: Add unreferenced index metadata cleanup
     * <ul>
     *     <li>Deleting stale indices</li>
     *     <li>Deleting unreferenced root level blobs</li>
     * </ul>
     *
     * @param repositoryDataGeneration         Generation of {@link RepositoryData} at start of process
     * @param repositoryFormatIndexVersion     Repository format version
     * @param listener                         Listener to complete when done
     */",67087d9d82a3a5339cc3dcf7
"public static EntityManager createSharedEntityManager(
			EntityManagerFactory emf, @Nullable Map<?, ?> properties, boolean synchronizedWithTransaction) {

		Class<?> emIfc = (emf instanceof EntityManagerFactoryInfo emfInfo ?
				emfInfo.getEntityManagerInterface() : EntityManager.class);
		return createSharedEntityManager(emf, properties, synchronizedWithTransaction,
				(emIfc == null ? NO_ENTITY_MANAGER_INTERFACES : new Class<?>[] {emIfc}));
	}","/**
	 * Create a transactional EntityManager proxy for the given EntityManagerFactory.
	 * @param emf the EntityManagerFactory to delegate to.
	 * @param properties the properties to be passed into the
	 * {@code createEntityManager} call (may be {@code null})
	 * @param synchronizedWithTransaction whether to automatically join ongoing
	 * transactions (according to the JPA 2.1 SynchronizationType rules)
	 * @return a shareable transaction EntityManager proxy
	 * @since 4.0
	 */",67087d9d82a3a5339cc3dcf8
"private Builder initializeAsRestore(
            IndexMetadata indexMetadata,
            SnapshotRecoverySource recoverySource,
            Set<Integer> ignoreShards,
            boolean asNew,
            UnassignedInfo unassignedInfo,
            @Nullable IndexRoutingTable previousIndexRoutingTable
        ) {
            assert indexMetadata.getIndex().equals(index);
            if (shards != null) {
                throw new IllegalStateException(""trying to initialize an index with fresh shards, but already has shards created"");
            }
            shards = new IndexShardRoutingTable.Builder[indexMetadata.getNumberOfShards()];
            for (int shardNumber = 0; shardNumber < indexMetadata.getNumberOfShards(); shardNumber++) {
                ShardId shardId = new ShardId(index, shardNumber);
                final var previousNodes = getPreviousNodes(previousIndexRoutingTable, shardNumber);
                IndexShardRoutingTable.Builder indexShardRoutingBuilder = IndexShardRoutingTable.builder(shardId);
                for (int i = 0; i <= indexMetadata.getNumberOfReplicas(); i++) {
                    boolean primary = i == 0;
                    if (asNew && ignoreShards.contains(shardNumber)) {
                        // This shards wasn't completely snapshotted - restore it as new shard
                        indexShardRoutingBuilder.addShard(
                            ShardRouting.newUnassigned(
                                shardId,
                                primary,
                                primary ? EmptyStoreRecoverySource.INSTANCE : PeerRecoverySource.INSTANCE,
                                unassignedInfo,
                                shardRoutingRoleStrategy.newRestoredRole(i)
                            )
                        );
                    } else {
                        indexShardRoutingBuilder.addShard(
                            ShardRouting.newUnassigned(
                                shardId,
                                primary,
                                primary ? recoverySource : PeerRecoverySource.INSTANCE,
                                withLastAllocatedNodeId(unassignedInfo, previousNodes, i),
                                shardRoutingRoleStrategy.newRestoredRole(i)
                            )
                        );
                    }
                }
                shards[shardNumber] = indexShardRoutingBuilder;
            }
            return this;
        }","/**
         * Initializes an index, to be restored from snapshot
         */",67087d9d82a3a5339cc3dcf9
"public void start() {
        /*
         * This is called here to cover an edge case -- when there are master-eligible nodes in the cluster but none of them has been
         * elected master. In the most common case this node will receive a ClusterChangedEvent that results in this polling being
         * cancelled almost immediately. If that does not happen, then we do in fact need to be polling. Note that
         * beginPollingRemoteMasterStabilityDiagnostic results in several internal transport actions being called, so it must run in the
         * system context.
         */
        if (clusterService.localNode().isMasterNode() == false) {
            final ThreadContext threadContext = transportService.getThreadPool().getThreadContext();
            try (ThreadContext.StoredContext ignored = threadContext.stashContext()) {
                threadContext.markAsSystemContext();
                beginPollingRemoteMasterStabilityDiagnostic();
            }
        }
        clusterService.addListener(this);
    }","/**
     * This method completes the initialization of the CoordinationDiagnosticsService. It kicks off polling for remote master stability
     * results on non-master-eligible nodes, and registers the service as a cluster service listener on all nodes.
     */",67087d9d82a3a5339cc3dcfa
"public CompletionQuery regexpQuery(Object value, int flags, int maxDeterminizedStates) {
            return new RegexCompletionQuery(new Term(name(), indexedValueForSearch(value)), flags, maxDeterminizedStates);
        }","/**
         * Completion prefix regular expression query
         */",67087d9d82a3a5339cc3dcfb
"@Override
	@Nullable
	public String getString(int columnIndex) throws InvalidResultSetAccessException {
		try {
			return this.resultSet.getString(columnIndex);
		}
		catch (SQLException se) {
			throw new InvalidResultSetAccessException(se);
		}
	}","/**
	 * @see java.sql.ResultSet#getString(int)
	 */",67087d9d82a3a5339cc3dcfc
"protected void onRstStreamRead(Http2Stream stream, FullHttpMessage msg) {
        removeMessage(stream, true);
    }","/**
     * Called if a {@code RST_STREAM} is received but we have some data for that stream.
     */",67087d9d82a3a5339cc3dcfd
"public static void copy (float[] src, int srcOffset, Buffer dst, int numElements) {
		FloatBuffer buffer = asFloatBuffer(dst);

		int oldPosition = buffer.position();
		buffer.limit(oldPosition + numElements);
		buffer.put(src, srcOffset, numElements);
		buffer.position(oldPosition);
	}","/** Copies the contents of src to dst, starting from src[srcOffset], copying numElements elements. The {@link Buffer}
	 * instance's {@link Buffer#position()} is used to define the offset into the Buffer itself. The position will stay the same,
	 * the limit will be set to position + numElements. <b>The Buffer must be a direct Buffer with native byte order. No error
	 * checking is performed</b>.
	 * 
	 * @param src the source array.
	 * @param srcOffset the offset into the source array.
	 * @param dst the destination Buffer, its position is used as an offset.
	 * @param numElements the number of elements to copy. */",67087d9d82a3a5339cc3dcfe
"@Deprecated(since = ""6.0"")
	@Nullable
	default Date nextExecutionTime(TriggerContext triggerContext) {
		Instant instant = nextExecution(triggerContext);
		return (instant != null ? Date.from(instant) : null);
	}","/**
	 * Determine the next execution time according to the given trigger context.
	 * <p>The default implementation delegates to {@link #nextExecution(TriggerContext)}.
	 * @param triggerContext context object encapsulating last execution times
	 * and last completion time
	 * @return the next execution time as defined by the trigger,
	 * or {@code null} if the trigger won't fire anymore
	 * @deprecated as of 6.0, in favor of {@link #nextExecution(TriggerContext)}
	 */",67087d9d82a3a5339cc3dcff
"static Iterator<? extends ToXContent> allColumns(List<ColumnInfo> columns, String name) {
        return ChunkedToXContentHelper.singleChunk((builder, params) -> {
            builder.startArray(name);
            for (ColumnInfo col : columns) {
                col.toXContent(builder, params);
            }
            return builder.endArray();
        });
    }","/**
     * Returns the column headings for the given columns.
     */",67087d9d82a3a5339cc3dd00
"public String getRequestUri() {
		return this.urlPathHelper.getOriginatingRequestUri(this.request);
	}","/**
	 * Return the request URI of the original request, that is, the invoked URL
	 * without parameters. This is particularly useful as HTML form action target,
	 * possibly in combination with the original query string.
	 * <p>Delegates to the UrlPathHelper for decoding.
	 * @see #getQueryString
	 * @see org.springframework.web.util.UrlPathHelper#getOriginatingRequestUri
	 * @see #getUrlPathHelper
	 */",67087d9d82a3a5339cc3dd01
"public Set<String> aliasedIndices() {
        return aliasedIndices.keySet();
    }","/**
     * @return the names of all indices aliases.
     */",67087d9d82a3a5339cc3dd02
"public <T> ResponseEntity<T> getForEntity(String url, Class<T> responseType, Object... urlVariables) {
		return this.restTemplate.getForEntity(url, responseType, urlVariables);
	}","/**
	 * Retrieve an entity by doing a GET on the specified URL. The response is converted
	 * and stored in an {@link ResponseEntity}.
	 * <p>
	 * URI Template variables are expanded using the given URI variables, if any.
	 * @param url the URL
	 * @param responseType the type of the return value
	 * @param urlVariables the variables to expand the template
	 * @param <T> the type of the return value
	 * @return the entity
	 * @see RestTemplate#getForEntity(java.lang.String, java.lang.Class,
	 * java.lang.Object[])
	 */",67087d9d82a3a5339cc3dd03
"public static boolean intersectBoundsPlaneFast (BoundingBox box, Plane plane) {
		return intersectBoundsPlaneFast(box.getCenter(tmp1), box.getDimensions(tmp2).scl(0.5f), plane.normal, plane.d);
	}","/** Quick check whether the given {@link BoundingBox} and {@link Plane} intersect.
	 * @return Whether the bounding box and the plane intersect. */",67087d9d82a3a5339cc3dd04
"private void processJoinRequest(JoinRequest joinRequest, ActionListener<Void> joinListener) {
        assert Transports.assertNotTransportThread(""blocking on coordinator mutex and maybe doing IO to increase term"");
        final Optional<Join> optionalJoin = joinRequest.getOptionalJoin();
        try {
            synchronized (mutex) {
                updateMaxTermSeen(joinRequest.getTerm());

                final CoordinationState coordState = coordinationState.get();
                final boolean prevElectionWon = coordState.electionWon()
                    && optionalJoin.stream().allMatch(j -> j.term() <= getCurrentTerm());

                optionalJoin.ifPresent(this::handleJoin);
                joinAccumulator.handleJoinRequest(
                    joinRequest.getSourceNode(),
                    joinRequest.getCompatibilityVersions(),
                    joinRequest.getFeatures(),
                    joinListener
                );

                if (prevElectionWon == false && coordState.electionWon()) {
                    becomeLeader();
                }
            }
        } catch (Exception e) {
            joinListener.onFailure(e);
        }
    }","/**
     * Processes the request to join the cluster. Received by the node running for election to master.
     */",67087d9d82a3a5339cc3dd05
"public ResultMatcher attribute(String name, @Nullable Object expectedValue) {
		return result ->
				assertEquals(""Request attribute '"" + name + ""'"", expectedValue, result.getRequest().getAttribute(name));
	}","/**
	 * Assert a request attribute value.
	 */",67087d9d82a3a5339cc3dd06
"protected boolean hasCorsConfigurationSource(Object handler) {
		if (handler instanceof HandlerExecutionChain handlerExecutionChain) {
			handler = handlerExecutionChain.getHandler();
		}
		return (handler instanceof CorsConfigurationSource || this.corsConfigurationSource != null);
	}","/**
	 * Return {@code true} if there is a {@link CorsConfigurationSource} for this handler.
	 * @since 5.2
	 */",67087d9d82a3a5339cc3dd07
"public static Map<String, String> getSecurityHeadersPreferringSecondary(
        ThreadPool threadPool,
        SecurityContext securityContext,
        ClusterState clusterState
    ) {
        SetOnce<Map<String, String>> filteredHeadersHolder = new SetOnce<>();
        useSecondaryAuthIfAvailable(securityContext, () -> {
            Map<String, String> filteredHeaders = ClientHelper.getPersistableSafeSecurityHeaders(
                threadPool.getThreadContext(),
                clusterState
            );
            filteredHeadersHolder.set(filteredHeaders);
        });
        return filteredHeadersHolder.get();
    }","/**
     * Returns security headers preferring secondary auth if it exists.
     */",67087d9d82a3a5339cc3dd08
"private static List<String> getTablesToDropInOrder(@NonNull SQLiteDatabase input) {
    List<String> tables = SqlUtil.getAllTables(input)
                                 .stream()
                                 .filter(table -> !table.startsWith(""sqlite_""))
                                 .sorted()
                                 .collect(Collectors.toList());


    Map<String, Set<String>> dependsOn = new LinkedHashMap<>();
    for (String table : tables) {
      Set<String> dependencies = SqlUtil.getForeignKeyDependencies(input, table);
      dependencies.remove(table);

      dependsOn.put(table, dependencies);
    }

    for (String table : tables) {
      Set<String> dependsOnTable = dependsOn.keySet().stream().filter(t -> dependsOn.get(t).contains(table)).collect(Collectors.toSet());
      Log.i(TAG, ""Tables that depend on "" + table + "": "" + dependsOnTable);
    }

    return computeTableDropOrder(dependsOn);
  }","/**
   * Returns the list of tables we should drop, in the order they should be dropped in.
   * The order is chosen to ensure we won't violate any foreign key constraints when we import them.
   */",67087d9d82a3a5339cc3dd09
"public static Map<StageId, SortedSet<StageId>> computeStageInflowMap(final QueryDefinition queryDefinition)
  {
    final Map<StageId, SortedSet<StageId>> retVal = new TreeMap<>();

    for (final StageDefinition stageDef : queryDefinition.getStageDefinitions()) {
      final StageId stageId = stageDef.getId();
      retVal.computeIfAbsent(stageId, ignored -> new TreeSet<>());

      for (final int inputStageNumber : queryDefinition.getStageDefinition(stageId).getInputStageNumbers()) {
        final StageId inputStageId = new StageId(queryDefinition.getQueryId(), inputStageNumber);
        retVal.computeIfAbsent(stageId, ignored -> new TreeSet<>()).add(inputStageId);
      }
    }

    return retVal;
  }","/**
   * Returns a mapping of stage -> stages that flow *into* that stage. Uses TreeMaps and TreeSets so we have a
   * consistent order for analyzing and running stages.
   */",67087d9d82a3a5339cc3dd0a
"public void setEntityManagerInterface(Class<? extends EntityManager> entityManagerInterface) {
		Assert.notNull(entityManagerInterface, ""'entityManagerInterface' must not be null"");
		this.entityManagerInterface = entityManagerInterface;
	}","/**
	 * Specify the EntityManager interface to expose.
	 * <p>Default is the EntityManager interface as defined by the
	 * EntityManagerFactoryInfo, if available. Else, the standard
	 * {@code jakarta.persistence.EntityManager} interface will be used.
	 * @see org.springframework.orm.jpa.EntityManagerFactoryInfo#getEntityManagerInterface()
	 * @see jakarta.persistence.EntityManager
	 */",67087d9d82a3a5339cc3dd0b
"@Override
  public Block evalNullable(Block fieldVal) {
    BooleanBlock v = (BooleanBlock) fieldVal;
    int positionCount = v.getPositionCount();
    try (BooleanBlock.Builder builder = driverContext.blockFactory().newBooleanBlockBuilder(positionCount)) {
      for (int p = 0; p < positionCount; p++) {
        int valueCount = v.getValueCount(p);
        if (valueCount == 0) {
          builder.appendNull();
          continue;
        }
        int first = v.getFirstValueIndex(p);
        int end = first + valueCount;
        boolean result = MvLast.process(v, first, end);
        builder.appendBoolean(result);
      }
      return builder.build();
    }
  }","/**
   * Evaluate blocks containing at least one multivalued field.
   */",67087d9d82a3a5339cc3dd0c
"@Override
    public void clusterChanged(ClusterChangedEvent event) {
        // if there is no master node configured in the current state, this node should not try to trigger anything, but consider itself
        // inactive. the same applies, if there is a cluster block that does not allow writes
        if (Strings.isNullOrEmpty(event.state().nodes().getMasterNodeId())
            || event.state().getBlocks().hasGlobalBlockWithLevel(ClusterBlockLevel.WRITE)) {
            configuration = INACTIVE;
            return;
        }

        if (event.state().nodes().getLocalNode().canContainData() && event.metadataChanged()) {
            try {
                IndexMetadata metadata = WatchStoreUtils.getConcreteIndex(Watch.INDEX, event.state().metadata());
                if (metadata == null) {
                    configuration = INACTIVE;
                } else {
                    checkWatchIndexHasChanged(metadata, event);
                }
            } catch (IllegalStateException e) {
                logger.error(""error loading watches index"", e);
                configuration = INACTIVE;
            }
        }
    }","/**
     * Listen for cluster state changes. This method will start, stop or reload the watcher
     * service based on cluster state information.
     * The method checks, if there are local watch indices up and running.
     *
     * @param event The ClusterChangedEvent class containing the current and new cluster state
     */",67087d9d82a3a5339cc3dd0d
"public static boolean isJavaLanguageInterface(Class<?> ifc) {
		return javaLanguageInterfaces.contains(ifc);
	}","/**
	 * Determine whether the given interface is a common Java language interface:
	 * {@link Serializable}, {@link Externalizable}, {@link Closeable}, {@link AutoCloseable},
	 * {@link Cloneable}, {@link Comparable} - all of which can be ignored when looking
	 * for 'primary' user-level interfaces. Common characteristics: no service-level
	 * operations, no bean property methods, no default methods.
	 * @param ifc the interface to check
	 * @since 5.0.3
	 */",67087d9d82a3a5339cc3dd0e
"public void doWithEntry(ClassLoader classLoader, BiConsumer<Class<?>, Class<?>> action) {
		this.entries.forEach((type, mixin) -> action.accept(resolveClassNameIfNecessary(type, classLoader),
				resolveClassNameIfNecessary(mixin, classLoader)));
	}","/**
	 * Perform an action on each entry defined by this instance. If a class needs to be
	 * resolved from its class name, the specified {@link ClassLoader} is used.
	 * @param classLoader the classloader to use to resolve class name if necessary
	 * @param action the action to invoke on each type to mixin class entry
	 */",67087d9d82a3a5339cc3dd0f
"public static Color valueOf (String hex, Color color) {
		hex = hex.charAt(0) == '#' ? hex.substring(1) : hex;
		color.r = Integer.parseInt(hex.substring(0, 2), 16) / 255f;
		color.g = Integer.parseInt(hex.substring(2, 4), 16) / 255f;
		color.b = Integer.parseInt(hex.substring(4, 6), 16) / 255f;
		color.a = hex.length() != 8 ? 1 : Integer.parseInt(hex.substring(6, 8), 16) / 255f;
		return color;
	}","/** Sets the specified color from a hex string with the format RRGGBBAA.
	 * @see #toString() */",67087d9d82a3a5339cc3dd10
"public boolean calculateMultiple(Node targetNode) {
        if (!calculateAllShortestPaths) {
            reset();
            calculateAllShortestPaths = true;
        }
        return calculate(targetNode);
    }","/**
     * Same as calculate(), but will set the flag to calculate all shortest
     * paths. It sets the flag and then calls calculate.
     * @return
     */",67087d9d82a3a5339cc3dd11
"void flipAfterStoreScan(CursorContext cursorContext) {
        for (IndexPopulation population : populations) {
            try {
                population.scanCompleted(cursorContext);
                population.flip(cursorContext);
            } catch (Throwable t) {
                cancel(population, t, cursorContext);
            }
        }
    }","/**
     * This concludes a successful index population.
     *
     * The last updates will be applied to every index,
     * tell {@link IndexPopulator index populators} that scan has been completed,
     * {@link IndexStatisticsStore index statistics store} will be updated with {@link IndexSample index samples},
     * {@link SchemaState schema cache} will be cleared,
     * {@link IndexPopulator index populators} will be closed and
     * {@link IndexProxy index proxy} will be {@link FlippableIndexProxy#flip(Callable, FailedIndexProxyFactory) flipped}
     * to {@link OnlineIndexProxy online}, given that nothing goes wrong.
     *
     */",67087d9d82a3a5339cc3dd12
"static void writeGlobalHeader(OutputStream outputStream) throws IOException {
        outputStream.write(GLOBAL_HEADER);
    }","/**
     * Writes the Pcap Global Header to the provided {@code OutputStream}
     *
     * @param outputStream OutputStream where Pcap data will be written.
     * @throws IOException if there is an error writing to the {@code OutputStream}
     */",67087d9d82a3a5339cc3dd13
"int addForwardUninitializedType(final String value, final Label label) {
    int labelIndex = getOrAddLabelEntry(label).index;
    int hashCode = hash(Symbol.FORWARD_UNINITIALIZED_TYPE_TAG, value, labelIndex);
    Entry entry = get(hashCode);
    while (entry != null) {
      if (entry.tag == Symbol.FORWARD_UNINITIALIZED_TYPE_TAG
          && entry.hashCode == hashCode
          && entry.data == labelIndex
          && entry.value.equals(value)) {
        return entry.index;
      }
      entry = entry.next;
    }
    return addTypeInternal(
        new Entry(typeCount, Symbol.FORWARD_UNINITIALIZED_TYPE_TAG, value, labelIndex, hashCode));
  }","/**
   * Adds a ""forward uninitialized"" type in the type table of this symbol table. Does nothing if the
   * type table already contains a similar type.
   *
   * @param value an internal class name.
   * @param label the label of the NEW instruction that created this uninitialized type value. If
   *     the label is resolved, use the {@link #addUninitializedType} method instead.
   * @return the index of a new or already existing type {@link Symbol} with the given value.
   */",67087d9d82a3a5339cc3dd14
"public AnnotationAttributes[] getAnnotationArray(String attributeName) {
		return getRequiredAttribute(attributeName, AnnotationAttributes[].class);
	}","/**
	 * Get the array of {@link AnnotationAttributes} stored under the specified
	 * {@code attributeName}.
	 * <p>If the value stored under the specified {@code attributeName} is
	 * an instance of {@code AnnotationAttributes}, it will be wrapped in
	 * a single-element array before returning it.
	 * <p>Note: if you expect an actual array of annotations, invoke
	 * {@link #getAnnotationArray(String, Class)} instead.
	 * @param attributeName the name of the attribute to get;
	 * never {@code null} or empty
	 * @return the array of {@code AnnotationAttributes}
	 * @throws IllegalArgumentException if the attribute does not exist or
	 * if it is not of the expected type
	 */",67087d9d82a3a5339cc3dd15
"public List<? extends T> getFlatNormalizedCollection() {
        return getNormalizedCollection().stream().map(PropertyListEntry::getValue).collect(Collectors.toList());
    }","/**
     * Return a ""flattened"" collection. This should be used when the collection type is itself a complex type with properties
     * annotated as Gradle inputs rather than a simple type like {@link String}.
     *
     * @return a flattened collection filtered according to normalization strategy
     */",67087d9d82a3a5339cc3dd16
"public ConnectionFactoryBuilder username(String username) {
		return configure((options) -> options.option(ConnectionFactoryOptions.USER, username));
	}","/**
	 * Configure the {@linkplain ConnectionFactoryOptions#USER username}.
	 * @param username the connection factory username
	 * @return this for method chaining
	 */",67087d9d82a3a5339cc3dd17
"private void replaceNotificationSourceIfNecessary(Notification notification) {
		if (notification.getSource() == null || notification.getSource().equals(this.managedResource)) {
			notification.setSource(this.objectName);
		}
	}","/**
	 * Replaces the notification source if necessary to do so.
	 * From the {@link Notification javadoc}:
	 * <i>""It is strongly recommended that notification senders use the object name
	 * rather than a reference to the MBean object as the source.""</i>
	 * @param notification the {@link Notification} whose
	 * {@link javax.management.Notification#getSource()} might need massaging
	 */",67087d9d82a3a5339cc3dd18
"public static Joiner getJoiner(SearchExecutionContext context) {
        return getJoiner(context.getMatchingFieldNames(""*"").stream().map(context::getFieldType));
    }","/**
     * Get the Joiner for this context, or {@code null} if none is configured
     */",67087d9d82a3a5339cc3dd19
"private static int estimateQuotient(int u2, int u1, int u0, int v1, int v0)
    {
        // estimate qhat based on the first 2 digits of divisor divided by the first digit of a dividend
        long u21 = combineInts(u2, u1);
        long qhat;
        if (u2 == v1) {
            qhat = INT_BASE - 1;
        }
        else if (u21 >= 0) {
            qhat = u21 / (v1 & LONG_MASK);
        }
        else {
            qhat = divideUnsignedLong(u21, v1 & LONG_MASK);
        }

        if (qhat == 0) {
            return 0;
        }

        // Check if qhat is greater than expected considering only first 3 digits of a dividend
        // This step help to eliminate all the cases when the estimation is greater than q by 2
        // and eliminates most of the cases when qhat is greater than q by 1
        //
        // u2 * b * b + u1 * b + u0 >= (v1 * b + v0) * qhat
        // u2 * b * b + u1 * b + u0 >= v1 * b * qhat + v0 * qhat
        // u2 * b * b + u1 * b - v1 * b * qhat >=  v0 * qhat - u0
        // (u21 - v1 * qhat) * b >=  v0 * qhat - u0
        // (u21 - v1 * qhat) * b + u0 >=  v0 * qhat
        // When ((u21 - v1 * qhat) * b + u0) is less than (v0 * qhat) decrease qhat by one

        int iterations = 0;
        long rhat = u21 - (v1 & LONG_MASK) * qhat;
        while (Long.compareUnsigned(rhat, INT_BASE) < 0 && Long.compareUnsigned((v0 & LONG_MASK) * qhat, combineInts(lowInt(rhat), u0)) > 0) {
            iterations++;
            qhat--;
            rhat += (v1 & LONG_MASK);
        }

        if (iterations > 2) {
            throw new IllegalStateException(""qhat is greater than q by more than 2: "" + iterations);
        }

        return (int) qhat;
    }","/**
     * Use the Knuth notation
     * <p>
     * u{x} - dividend
     * v{v} - divisor
     */",67087d9d82a3a5339cc3dd1a
"public static <T extends Vector<T>> T cubic_derivative (final T out, final float t, final T[] points, final boolean continuous,
		final T tmp) {
		final int n = continuous ? points.length : points.length - 3;
		float u = t * n;
		int i = (t >= 1f) ? (n - 1) : (int)u;
		u -= i;
		return cubic(out, i, u, points, continuous, tmp);
	}","/** Calculates the cubic b-spline derivative for the given position (t).
	 * @param out The Vector to set to the result.
	 * @param t The position (0<=t<=1) on the spline
	 * @param points The control points
	 * @param continuous If true the b-spline restarts at 0 when reaching 1
	 * @param tmp A temporary vector used for the calculation
	 * @return The value of out */",67087d9d82a3a5339cc3dd1b
"@Provides
  @LazySingleton
  public CuratorFramework makeCurator(
      final ZkEnablementConfig zkEnablementConfig,
      final CuratorConfig config,
      final DruidConnectionStateListener connectionStateListener,
      final ServiceEmitter emitter,
      final Lifecycle lifecycle
  )
  {
    if (!zkEnablementConfig.isEnabled()) {
      throw new RuntimeException(""Zookeeper is disabled, cannot create CuratorFramework."");
    }

    final CuratorFramework framework = createCurator(config);

    framework.getConnectionStateListenable().addListener(connectionStateListener);
    addUnhandledErrorListener(framework, emitter, lifecycle);
    addLifecycleHandler(framework, lifecycle);

    return framework;
  }","/**
   * Provide the Curator framework via Guice, integrated with the Druid lifecycle.
   */",67087d9d82a3a5339cc3dd1c
"static <CTX, S> StructRegistry<CTX, S> empty() {
        return EmptyStructRegistry.getInstance();
    }","/**
     * Retrieves an empty struct registry which will reject any struct tags or payloads given to it.
     *
     * @param <CTX> a context object.
     * @param <S> an arbitrary struct type.
     * @return a struct registry.
     */",67087d9d82a3a5339cc3dd1d
"public boolean ack(long firstSeqNum, int count, int checkpointMaxAcks) throws IOException {
        assert firstSeqNum >= this.minSeqNum :
            String.format(""seqNum=%d is smaller than minSeqnum=%d"", firstSeqNum, this.minSeqNum);
        final long maxSeqNum = firstSeqNum + count;
        assert maxSeqNum <= this.minSeqNum + this.elementCount :
            String.format(
                ""seqNum=%d is greater than minSeqnum=%d + elementCount=%d = %d"", maxSeqNum,
                this.minSeqNum, this.elementCount, this.minSeqNum + this.elementCount
            );
        final int offset = Ints.checkedCast(firstSeqNum - this.minSeqNum);
        ackedSeqNums.flip(offset, offset + count);
        // checkpoint if totally acked or we acked more than checkpointMaxAcks elements in this page since last checkpoint
        // note that fully acked pages cleanup is done at queue level in Queue.ack()
        final long firstUnackedSeqNum = firstUnackedSeqNum();

        final boolean done = isFullyAcked();
        if (done) {
            checkpoint();

            // purge fully acked tail page
            if (!this.writable) {
                purge();
                final CheckpointIO cpIO = queue.getCheckpointIO();
                cpIO.purge(cpIO.tailFileName(pageNum));
            }
            assert firstUnackedSeqNum >= this.minSeqNum + this.elementCount - 1:
                    String.format(""invalid firstUnackedSeqNum=%d for minSeqNum=%d and elementCount=%d and cardinality=%d"", firstUnackedSeqNum, this.minSeqNum, this.elementCount, this.ackedSeqNums.cardinality());

        } else if (checkpointMaxAcks > 0 && firstUnackedSeqNum >= this.lastCheckpoint.getFirstUnackedSeqNum() + checkpointMaxAcks) {
            // did we acked more than checkpointMaxAcks elements? if so checkpoint now
            checkpoint();
        }
        return done;
    }","/**
     * update the page acking bitset. trigger checkpoint on the page if it is fully acked or if we acked more than the
     * configured threshold checkpointMaxAcks.
     * note that if the fully acked tail page is the first unacked page, it is not really necessary to also checkpoint
     * the head page to update firstUnackedPageNum because it will be updated in the next upcoming head page checkpoint
     * and in a crash condition, the Queue open recovery will detect and purge fully acked pages
     *
     * @param firstSeqNum Lowest sequence number to ack
     * @param count Number of elements to ack
     * @param checkpointMaxAcks number of acks before forcing a checkpoint
     * @return true if Page and its checkpoint were purged as a result of being fully acked
     * @throws IOException if an IO error occurs
     */",67087d9d82a3a5339cc3dd1e
"public double getTime(TimeUnit timeUnit) {
			return (double) this.timeNanos / TimeUnit.NANOSECONDS.convert(1, timeUnit);
		}","/**
		 * Get the time this task took in the requested time unit
		 * (with decimal points in nanosecond precision).
		 * @param timeUnit the unit to use
		 * @since 6.1
		 * @see #getTimeNanos()
		 * @see #getTimeMillis()
		 * @see #getTimeSeconds()
		 */",67087d9d82a3a5339cc3dd1f
"public static DoublesColumn create(ColumnarDoubles column, ImmutableBitmap nullValueBitmap)
  {
    if (nullValueBitmap.isEmpty()) {
      return new DoublesColumn(column);
    } else {
      return new DoublesColumnWithNulls(column, nullValueBitmap);
    }
  }","/**
   * Factory method to create DoublesColumn.
   */",67087d9d82a3a5339cc3dd20
"private static Pair<TreeState, TreeState> loadStatePages(PagedFile pagedFile, CursorContext cursorContext)
            throws MetadataMismatchException, IOException {
        try {
            Pair<TreeState, TreeState> states = readStatePages(pagedFile, cursorContext);
            if (states.getLeft().isEmpty() && states.getRight().isEmpty()) {
                throw new MetadataMismatchException(""Index is not fully initialized since its state pages are empty"");
            }
            return states;
        } catch (IllegalStateException e) {
            throw new MetadataMismatchException(""Index is not fully initialized since it's missing state pages"", e);
        }
    }","/**
     * Basically {@link #readStatePages(PagedFile, CursorContext)} with some more checks, suitable for when first opening an index file,
     * not while running it and check pointing.
     *
     * @param pagedFile {@link PagedFile} to read the state pages from.
     * @param cursorContext underlying page cursor context
     * @return both read state pages.
     * @throws MetadataMismatchException if state pages are missing (file is smaller than that) or if they are both empty.
     * @throws IOException on {@link PageCursor} error.
     */",67087d9d82a3a5339cc3dd21
"void recoverFromRepository(final IndexShard indexShard, Repository repository, ActionListener<Boolean> listener) {
        try {
            if (canRecover(indexShard)) {
                RecoverySource.Type recoveryType = indexShard.recoveryState().getRecoverySource().getType();
                assert recoveryType == RecoverySource.Type.SNAPSHOT : ""expected snapshot recovery type: "" + recoveryType;
                SnapshotRecoverySource recoverySource = (SnapshotRecoverySource) indexShard.recoveryState().getRecoverySource();
                restore(indexShard, repository, recoverySource, recoveryListener(indexShard, listener).map(ignored -> true));
            } else {
                listener.onResponse(false);
            }
        } catch (Exception e) {
            listener.onFailure(e);
        }
    }","/**
     * Recovers an index from a given {@link Repository}. This method restores a
     * previously created index snapshot into an existing initializing shard.
     * @param indexShard the index shard instance to recovery the snapshot from
     * @param repository the repository holding the physical files the shard should be recovered from
     * @param listener resolves to <code>true</code> if the shard has been recovered successfully, <code>false</code> if the recovery
     *                 has been ignored due to a concurrent modification of if the clusters state has changed due to async updates.
     */",67087d9d82a3a5339cc3dd22
"public static ShardLimitValidator createTestShardLimitService(int maxShardsPerNode) {
        // Use a mocked clusterService - for unit tests we won't be updating the setting anyway.
        ClusterService clusterService = mock(ClusterService.class);
        Settings limitOnlySettings = Settings.builder().put(SETTING_CLUSTER_MAX_SHARDS_PER_NODE.getKey(), maxShardsPerNode).build();
        when(clusterService.getClusterSettings()).thenReturn(
            new ClusterSettings(limitOnlySettings, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS)
        );

        return new ShardLimitValidator(limitOnlySettings, clusterService);
    }","/**
     * Creates a {@link ShardLimitValidator} for testing with the given setting and a mocked cluster service.
     *
     * @param maxShardsPerNode the value to use for the max shards per node setting
     * @return a test instance
     */",67087d9d82a3a5339cc3dd23
"public void error(String message, @Nullable Object source, @Nullable ParseState parseState) {
		error(message, source, parseState, null);
	}","/**
	 * Raise a regular error.
	 */",67087d9d82a3a5339cc3dd24
"public byte[] getBytes() {
		return this.content.getBytes(StandardCharsets.UTF_8);
	}","/**
	 * Return the contents of the file as a byte array.
	 * @return the file contents as a byte array
	 */",67087d9d82a3a5339cc3dd25
"public void testStoreMalformed() throws Exception {
        String indexName = ""test_malformed"";
        createIndex(indexName, Settings.builder().put(""index.number_of_shards"", 1).build(), ""_doc"", ""version"", ""type=version"");
        ensureGreen(indexName);

        prepareIndex(indexName).setId(""1"").setSource(jsonBuilder().startObject().field(""version"", ""1.invalid.0"").endObject()).get();
        prepareIndex(indexName).setId(""2"").setSource(jsonBuilder().startObject().field(""version"", ""2.2.0"").endObject()).get();
        prepareIndex(indexName).setId(""3"").setSource(jsonBuilder().startObject().field(""version"", ""2.2.0-badchar!"").endObject()).get();
        prepareIndex(indexName).setId(""4"").setSource(jsonBuilder().startObject().field(""version"", """").endObject()).get();
        client().admin().indices().prepareRefresh(indexName).get();

        assertResponse(client().prepareSearch(indexName).addDocValueField(""version""), response -> {
            assertEquals(4, response.getHits().getTotalHits().value);
            assertEquals(""1"", response.getHits().getAt(0).getId());
            assertEquals(""1.invalid.0"", response.getHits().getAt(0).field(""version"").getValue());

            assertEquals(""2"", response.getHits().getAt(1).getId());
            assertEquals(""2.2.0"", response.getHits().getAt(1).field(""version"").getValue());

            assertEquals(""3"", response.getHits().getAt(2).getId());
            assertEquals(""2.2.0-badchar!"", response.getHits().getAt(2).field(""version"").getValue());

            assertEquals(""4"", response.getHits().getAt(3).getId());
            assertEquals("""", response.getHits().getAt(3).field(""version"").getValue());
        });

        // exact match for malformed term
        assertHitCount(client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(""version"", ""1.invalid.0"")), 1);
        assertHitCount(client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(""version"", ""2.2.0-badchar!"")), 1);
        assertHitCount(client().prepareSearch(indexName).setQuery(QueryBuilders.matchQuery(""version"", """")), 1);

        // also should appear in terms aggs
        assertResponse(
            client().prepareSearch(indexName).addAggregation(AggregationBuilders.terms(""myterms"").field(""version"")),
            response -> {
                Terms terms = response.getAggregations().get(""myterms"");
                List<? extends Bucket> buckets = terms.getBuckets();

                assertEquals(4, buckets.size());
                assertEquals(""2.2.0"", buckets.get(0).getKey());
                assertEquals("""", buckets.get(1).getKey());
                assertEquals(""1.invalid.0"", buckets.get(2).getKey());
                assertEquals(""2.2.0-badchar!"", buckets.get(3).getKey());
            }
        );

        // invalid values should sort after all valid ones
        assertResponse(
            client().prepareSearch(indexName).setQuery(QueryBuilders.matchAllQuery()).addSort(""version"", SortOrder.ASC),
            response -> {
                assertEquals(4, response.getHits().getTotalHits().value);
                SearchHit[] hits = response.getHits().getHits();
                assertEquals(""2.2.0"", hits[0].getSortValues()[0]);
                assertEquals("""", hits[1].getSortValues()[0]);
                assertEquals(""1.invalid.0"", hits[2].getSortValues()[0]);
                assertEquals(""2.2.0-badchar!"", hits[3].getSortValues()[0]);
            }
        );

        // ranges can include them, but they are sorted last
        assertHitCount(client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(""version"").to(""3.0.0"")), 1);
        assertHitCount(client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(""version"").from(""3.0.0"")), 3);

        // using the empty string as lower bound should return all ""invalid"" versions
        assertHitCount(client().prepareSearch(indexName).setQuery(QueryBuilders.rangeQuery(""version"").from("""")), 3);
    }","/**
     * test that versions that are invalid under semver are still indexed and retrieveable, though they sort differently
     */",67087d9d82a3a5339cc3dd26
"public static DisplayMode getDisplayMode (Monitor monitor) {
		Lwjgl3Application.initializeGlfw();
		GLFWVidMode videoMode = GLFW.glfwGetVideoMode(((Lwjgl3Monitor)monitor).monitorHandle);
		return new Lwjgl3Graphics.Lwjgl3DisplayMode(((Lwjgl3Monitor)monitor).monitorHandle, videoMode.width(), videoMode.height(),
			videoMode.refreshRate(), videoMode.redBits() + videoMode.greenBits() + videoMode.blueBits());
	}",/** @return the currently active {@link DisplayMode} of the given monitor */,67087d9d82a3a5339cc3dd27
"protected void initMessageSource() {
		ConfigurableListableBeanFactory beanFactory = getBeanFactory();
		if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) {
			this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class);
			// Make MessageSource aware of parent MessageSource.
			if (this.parent != null && this.messageSource instanceof HierarchicalMessageSource hms &&
					hms.getParentMessageSource() == null) {
				// Only set parent context as parent MessageSource if no parent MessageSource
				// registered already.
				hms.setParentMessageSource(getInternalParentMessageSource());
			}
			if (logger.isTraceEnabled()) {
				logger.trace(""Using MessageSource ["" + this.messageSource + ""]"");
			}
		}
		else {
			// Use empty MessageSource to be able to accept getMessage calls.
			DelegatingMessageSource dms = new DelegatingMessageSource();
			dms.setParentMessageSource(getInternalParentMessageSource());
			this.messageSource = dms;
			beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);
			if (logger.isTraceEnabled()) {
				logger.trace(""No '"" + MESSAGE_SOURCE_BEAN_NAME + ""' bean, using ["" + this.messageSource + ""]"");
			}
		}
	}","/**
	 * Initialize the {@link MessageSource}.
	 * <p>Uses parent's {@code MessageSource} if none defined in this context.
	 * @see #MESSAGE_SOURCE_BEAN_NAME
	 */",67087d9d82a3a5339cc3dd28
"public void addCookie(HttpServletResponse response, String cookieValue) {
		Assert.notNull(response, ""HttpServletResponse must not be null"");
		Cookie cookie = createCookie(cookieValue);
		Integer maxAge = getCookieMaxAge();
		if (maxAge != null) {
			cookie.setMaxAge(maxAge);
		}
		if (isCookieSecure()) {
			cookie.setSecure(true);
		}
		if (isCookieHttpOnly()) {
			cookie.setHttpOnly(true);
		}
		response.addCookie(cookie);
		if (logger.isTraceEnabled()) {
			logger.trace(""Added cookie ["" + getCookieName() + ""="" + cookieValue + ""]"");
		}
	}","/**
	 * Add a cookie with the given value to the response,
	 * using the cookie descriptor settings of this generator.
	 * <p>Delegates to {@link #createCookie} for cookie creation.
	 * @param response the HTTP response to add the cookie to
	 * @param cookieValue the value of the cookie to add
	 * @see #setCookieName
	 * @see #setCookieDomain
	 * @see #setCookiePath
	 * @see #setCookieMaxAge
	 */",67087d9d82a3a5339cc3dd29
"public void resolvePolicies(
        Collection<String> targetClusters,
        Collection<UnresolvedPolicy> unresolvedPolicies,
        ActionListener<EnrichResolution> listener
    ) {
        if (unresolvedPolicies.isEmpty() || targetClusters.isEmpty()) {
            listener.onResponse(new EnrichResolution());
            return;
        }
        final Set<String> remoteClusters = new HashSet<>(targetClusters);
        final boolean includeLocal = remoteClusters.remove(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);
        lookupPolicies(remoteClusters, includeLocal, unresolvedPolicies, listener.map(lookupResponses -> {
            final EnrichResolution enrichResolution = new EnrichResolution();
            for (UnresolvedPolicy unresolved : unresolvedPolicies) {
                Tuple<ResolvedEnrichPolicy, String> resolved = mergeLookupResults(
                    unresolved,
                    calculateTargetClusters(unresolved.mode, includeLocal, remoteClusters),
                    lookupResponses
                );
                if (resolved.v1() != null) {
                    enrichResolution.addResolvedPolicy(unresolved.name, unresolved.mode, resolved.v1());
                } else {
                    assert resolved.v2() != null;
                    enrichResolution.addError(unresolved.name, unresolved.mode, resolved.v2());
                }
            }
            return enrichResolution;
        }));
    }","/**
     * Resolves a set of enrich policies
     *
     * @param targetClusters     the target clusters
     * @param unresolvedPolicies the unresolved policies
     * @param listener           notified with the enrich resolution
     */",67087d9d82a3a5339cc3dd2a
"public void clear(long index) {
        long wordNum = wordNum(index);
        if (wordNum >= bits.size()) {
            /*
             * No need to resize the array just to clear the bit because we'll
             * initialize them to false when we grow the array anyway.
             */
            return;
        }
        bits.set(wordNum, bits.get(wordNum) & ~bitmask(index));
    }","/**
     * Clear the {@code index}th bit.
     */",67087d9d82a3a5339cc3dd2b
"protected Map<String, Object> createResultsMap() {
		if (isResultsMapCaseInsensitive()) {
			return new LinkedCaseInsensitiveMap<>();
		}
		else {
			return new LinkedHashMap<>();
		}
	}","/**
	 * Create a Map instance to be used as the results map.
	 * <p>If {@link #resultsMapCaseInsensitive} has been set to true,
	 * a {@link LinkedCaseInsensitiveMap} will be created; otherwise, a
	 * {@link LinkedHashMap} will be created.
	 * @return the results Map instance
	 * @see #setResultsMapCaseInsensitive
	 * @see #isResultsMapCaseInsensitive
	 */",67087d9d82a3a5339cc3dd2c
"@Nullable
		protected T execute(@Nullable Reference<K, V> ref, @Nullable Entry<K, V> entry, @Nullable Entries<V> entries) {
			return execute(ref, entry);
		}","/**
		 * Execute the task.
		 * @param ref the found reference (or {@code null})
		 * @param entry the found entry (or {@code null})
		 * @param entries access to the underlying entries
		 * @return the result of the task
		 * @see #execute(Reference, Entry)
		 */",67087d9d82a3a5339cc3dd2d
"public static <T> SubscribableListener<T> newForked(CheckedConsumer<ActionListener<T>, ? extends Exception> fork) {
        final var listener = new SubscribableListener<T>();
        ActionListener.run(listener, fork::accept);
        return listener;
    }","/**
     * Create a {@link SubscribableListener}, fork a computation to complete it, and return the listener. If the forking itself throws an
     * exception then the exception is caught and fed to the returned listener.
     */",67087d9d82a3a5339cc3dd2e
"@SuppressWarnings(""overloads"")  // These are ambiguous if you aren't using ctor references but we always do
    protected static <T extends Function> FunctionDefinition def(Class<T> function, TernaryBuilder<T> ctorRef, String... names) {
        FunctionBuilder builder = (source, children, cfg) -> {
            boolean hasMinimumTwo = OptionalArgument.class.isAssignableFrom(function);
            if (hasMinimumTwo && (children.size() > 3 || children.size() < 2)) {
                throw new QlIllegalArgumentException(""expects two or three arguments"");
            } else if (hasMinimumTwo == false && children.size() != 3) {
                throw new QlIllegalArgumentException(""expects exactly three arguments"");
            }
            return ctorRef.build(source, children.get(0), children.get(1), children.size() == 3 ? children.get(2) : null);
        };
        return def(function, builder, names);
    }","/**
     * Build a {@linkplain FunctionDefinition} for a ternary function.
     */",67087d9d82a3a5339cc3dd2f
"public static void addInstance (final btCollisionObject obj) {
		instances.put(getCPtr(obj), obj);
	}","/** Add the instance to the managed instances. You should avoid using this method. This method is intended for internal
	 * purposes only. */",67087d9d82a3a5339cc3dd30
"@Override
	public void onMessage(Message message) {
		try {
			onMessage(message, null);
		}
		catch (Throwable ex) {
			handleListenerException(ex);
		}
	}","/**
	 * Standard JMS {@link MessageListener} entry point.
	 * <p>Delegates the message to the target listener method, with appropriate
	 * conversion of the message argument. In case of an exception, the
	 * {@link #handleListenerException(Throwable)} method will be invoked.
	 * <p><b>Note:</b> Does not support sending response messages based on
	 * result objects returned from listener methods. Use the
	 * {@link SessionAwareMessageListener} entry point (typically through a Spring
	 * message listener container) for handling result objects as well.
	 * @param message the incoming JMS message
	 * @see #handleListenerException
	 * @see #onMessage(jakarta.jms.Message, jakarta.jms.Session)
	 */",67087d9d82a3a5339cc3dd31
"public static Map<Object, Object> getResourceMap() {
		Map<Object, Object> map = resources.get();
		return (map != null ? Collections.unmodifiableMap(map) : Collections.emptyMap());
	}","/**
	 * Return all resources that are bound to the current thread.
	 * <p>Mainly for debugging purposes. Resource managers should always invoke
	 * {@code hasResource} for a specific resource key that they are interested in.
	 * @return a Map with resource keys (usually the resource factory) and resource
	 * values (usually the active resource object), or an empty Map if there are
	 * currently no resources bound
	 * @see #hasResource
	 */",67087d9d82a3a5339cc3dd32
"public String get(String key) {
		return this.entries.getProperty(key);
	}","/**
	 * Return the value of the specified property or {@code null}.
	 * @param key the key of the property
	 * @return the property value
	 */",67087d9d82a3a5339cc3dd33
"protected AnimationDesc animate (final AnimationDesc anim, float transitionTime) {
		if (current == null || current.loopCount == 0)
			current = anim;
		else if (inAction)
			queue(anim, transitionTime);
		else if (!allowSameAnimation && anim != null && current.animation == anim.animation) {
			anim.time = current.time;
			animationPool.free(current);
			current = anim;
		} else {
			if (previous != null) {
				removeAnimation(previous.animation);
				animationPool.free(previous);
			}
			previous = current;
			current = anim;
			transitionCurrentTime = 0f;
			transitionTargetTime = transitionTime;
		}
		return anim;
	}",/** Changes the current animation by blending the new on top of the old during the transition time. */,67087d9d82a3a5339cc3dd34
"public long globalMaxOrd(IndexReader indexReader) throws IOException {
                if (indexReader.leaves().isEmpty()) {
                    return 0;
                } else {
                    LeafReaderContext atomicReaderContext = indexReader.leaves().get(0);
                    SortedSetDocValues values = globalOrdinalsValues(atomicReaderContext);
                    return values.getValueCount();
                }
            }","/**
             * Get the maximum global ordinal. Requires {@link #globalOrdinalsValues}
             * so see the note about its performance.
             */",67087d9d82a3a5339cc3dd35
"public static void copy (double[] src, int srcOffset, Buffer dst, int numElements) {
		dst.limit(dst.position() + bytesToElements(dst, numElements << 3));
		copyJni(src, srcOffset, dst, positionInBytes(dst), numElements << 3);
	}","/** Copies the contents of src to dst, starting from src[srcOffset], copying numElements elements. The {@link Buffer}
	 * instance's {@link Buffer#position()} is used to define the offset into the Buffer itself. The position will stay the same,
	 * the limit will be set to position + numElements. <b>The Buffer must be a direct Buffer with native byte order. No error
	 * checking is performed</b>.
	 * 
	 * @param src the source array.
	 * @param srcOffset the offset into the source array.
	 * @param dst the destination Buffer, its position is used as an offset.
	 * @param numElements the number of elements to copy. */",67087d9d82a3a5339cc3dd36
"private void fireCheckpointListeners(final List<Tuple<Long, ActionListener<Void>>> listenersToFire) {
        if (listenersToFire != null) {
            for (final Tuple<Long, ActionListener<Void>> listener : listenersToFire) {
                try {
                    listener.v2().onResponse(null);
                } catch (final Exception e) {
                    logger.warn(""error firing checkpoint refresh listener"", e);
                    assert false;
                }
            }
        }
    }","/**
     * Fire checkpoint listeners. Does nothing if the list of listeners is null.
     */",67087d9d82a3a5339cc3dd37
"public Fixture createFixture (Shape shape, float density) {
		long fixtureAddr = jniCreateFixture(addr, shape.addr, density);
		Fixture fixture = this.world.freeFixtures.obtain();
		fixture.reset(this, fixtureAddr);
		this.world.fixtures.put(fixture.addr, fixture);
		this.fixtures.add(fixture);
		return fixture;
	}","/** Creates a fixture from a shape and attach it to this body. This is a convenience function. Use b2FixtureDef if you need to
	 * set parameters like friction, restitution, user data, or filtering. If the density is non-zero, this function automatically
	 * updates the mass of the body.
	 * @param shape the shape to be cloned.
	 * @param density the shape density (set to zero for static bodies).
	 * @warning This function is locked during callbacks. */",67087d9d82a3a5339cc3dd38
"public static CharArraySet cleanStopWordSet(CharArraySet stopSet) {
        CharArraySet result = new CharArraySet(stopSet.size(), false);
        stopSet.stream()
                .map(cs -> new String((char[]) cs).trim())
                .filter(s -> !(s.isBlank() || s.contains(""#"") || s.contains("" "")))
                .forEach(result::add);
        return result;
    }","/**
     * Produce a new stop-word set similar to the given set, but where unclean elements have been removed.
     * Stop-word list files often contain comments, blank lines, excess white-space, etc.
     * When these files are parsed, these unclean data artifacts can end up in our stop-word sets when they should not.
     * The passed-in stop-word set is not changed.
     *
     * @param stopSet The stop-word set to clean up.
     * @return the cleaned-up stop-word set.
     */",67087d9d82a3a5339cc3dd39
"public void createSuccessFile(String taskId) throws IOException
  {
    String fileName = getSuccessFilePath();
    if (storageConnector.pathExists(fileName)) {
      LOG.warn(""Path [%s] already exists. Won't attempt to rewrite on top of it."", fileName);
      return;
    }
    OutputStreamWriter os = new OutputStreamWriter(storageConnector.write(fileName), StandardCharsets.UTF_8);
    os.write(taskId); // Add some dummy content in the file
    os.close();
  }","/**
   * Creates a file with name __success and adds the worker's id which has successfully written its outputs. While reading
   * this file can be used to find out the worker which has written its outputs completely.
   * Rename operation is not very quick in cloud storage like S3 due to which this alternative
   * route has been taken.
   * If the success file is already present in the location, then this method is a noop
   */",67087d9d82a3a5339cc3dd3a
"@Nullable
	protected List<HttpMethod> checkMethods(CorsConfiguration config, @Nullable HttpMethod requestMethod) {
		return config.checkHttpMethod(requestMethod);
	}","/**
	 * Check the HTTP method and determine the methods for the response of a
	 * pre-flight request. The default implementation simply delegates to
	 * {@link CorsConfiguration#checkHttpMethod(HttpMethod)}.
	 */",67087d9d82a3a5339cc3dd3b
"@Override
    public T decode(Object value, ObjectMapper jsonMapper)
    {
      return CatalogUtils.safeCast(value, valueClass, ""JSON object"");
    }","/**
     * Convert the value from the deserialized JSON format to the type
     * required by this field data type. Also used to decode values from
     * SQL parameters. As a side effect, verifies that the value is of
     * the correct type.
     */",67087d9d82a3a5339cc3dd3c
"protected boolean canHandle(String viewName, Locale locale) {
		String[] viewNames = getViewNames();
		return (viewNames == null || PatternMatchUtils.simpleMatch(viewNames, viewName));
	}","/**
	 * Indicates whether this {@link org.springframework.web.servlet.ViewResolver} can
	 * handle the supplied view name. If not, {@link #createView(String, java.util.Locale)} will
	 * return {@code null}. The default implementation checks against the configured
	 * {@link #setViewNames view names}.
	 * @param viewName the name of the view to retrieve
	 * @param locale the Locale to retrieve the view for
	 * @return whether this resolver applies to the specified view
	 * @see org.springframework.util.PatternMatchUtils#simpleMatch(String, String)
	 */",67087d9d82a3a5339cc3dd3d
"public void switchTo(Class<?> destination) {
		switchTo(LogFactory.getLog(destination));
	}","/**
	 * Switch from deferred logging to immediate logging to the specified destination.
	 * @param destination the new log destination
	 * @since 2.1.0
	 */",67087d9d82a3a5339cc3dd3e
"public void createChain (Vector2[] vertices) {
		Vec2[] v = new Vec2[vertices.length];
		for (int i = 0; i < vertices.length; i++) {
			v[i] = new Vec2(vertices[i].x, vertices[i].y);
		}
		shape.createChain(v, v.length);
		isLooped = false;
	}","/** Create a chain with isolated end vertices.
	 * @param vertices an array of vertices, these are copied */",67087d9d82a3a5339cc3dd3f
"@Deprecated
    public static DomainSocketAddress newSocketAddress() {
        return newDomainSocketAddress();
    }","/**
     * @deprecated Use {@link #newDomainSocketAddress()} instead.
     */",67087d9d82a3a5339cc3dd40
"private static List<String> nodeStringValues(String field, Object valueObj) {
        if (valueObj instanceof String value) {
            return List.of(value);
        } else if (valueObj instanceof Collection<?> values) {
            List<String> valuesString = new ArrayList<>();
            for (var v : values) {
                if (v instanceof String value) {
                    valuesString.add(value);
                } else {
                    throw new ElasticsearchStatusException(
                        ""Invalid format for field [{}], expected [String] got [{}]"",
                        RestStatus.BAD_REQUEST,
                        field,
                        valueObj.getClass().getSimpleName()
                    );
                }
            }
            return valuesString;
        }
        throw new ElasticsearchStatusException(
            ""Invalid format for field [{}], expected [String] got [{}]"",
            RestStatus.BAD_REQUEST,
            field,
            valueObj.getClass().getSimpleName()
        );
    }","/**
     * This method converts the given {@code valueObj} into a list of strings.
     * If {@code valueObj} is not a string or a collection of strings, it throws an ElasticsearchStatusException.
     */",67087d9d82a3a5339cc3dd41
"public static String text(ParseTree node) {
        return node == null ? null : node.getText();
    }","/**
     * Retrieves the raw text of the node (without interpreting it as a string literal).
     */",67087d9d82a3a5339cc3dd42
"public String determineVirtualHost() {
		if (CollectionUtils.isEmpty(this.parsedAddresses)) {
			return getVirtualHost();
		}
		Address address = this.parsedAddresses.get(0);
		return (address.virtualHost != null) ? address.virtualHost : getVirtualHost();
	}","/**
	 * If addresses have been set and the first address has a virtual host it is returned.
	 * Otherwise returns the result of calling {@code getVirtualHost()}.
	 * @return the virtual host or {@code null}
	 * @see #setAddresses(String)
	 * @see #getVirtualHost()
	 */",67087d9d82a3a5339cc3dd43
"protected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) {
		Class<?> contextClass = getContextClass();
		if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) {
			throw new ApplicationContextException(
					""Fatal initialization error in servlet with name '"" + getServletName() +
					""': custom WebApplicationContext class ["" + contextClass.getName() +
					""] is not of type ConfigurableWebApplicationContext"");
		}
		ConfigurableWebApplicationContext wac =
				(ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);

		wac.setEnvironment(getEnvironment());
		wac.setParent(parent);
		String configLocation = getContextConfigLocation();
		if (configLocation != null) {
			wac.setConfigLocation(configLocation);
		}
		configureAndRefreshWebApplicationContext(wac);

		return wac;
	}","/**
	 * Instantiate the WebApplicationContext for this servlet, either a default
	 * {@link org.springframework.web.context.support.XmlWebApplicationContext}
	 * or a {@link #setContextClass custom context class}, if set.
	 * <p>This implementation expects custom contexts to implement the
	 * {@link org.springframework.web.context.ConfigurableWebApplicationContext}
	 * interface. Can be overridden in subclasses.
	 * <p>Do not forget to register this servlet instance as application listener on the
	 * created context (for triggering its {@link #onRefresh callback}), and to call
	 * {@link org.springframework.context.ConfigurableApplicationContext#refresh()}
	 * before returning the context instance.
	 * @param parent the parent ApplicationContext to use, or {@code null} if none
	 * @return the WebApplicationContext for this servlet
	 * @see org.springframework.web.context.support.XmlWebApplicationContext
	 */",67087d9d82a3a5339cc3dd44
"@SuppressForbidden(reason = ""access /sys/fs/cgroup/cpu"")
    String readSysFsCgroupCpuAcctCpuAcctCfsQuota(final String controlGroup) throws IOException {
        return readSingleLine(PathUtils.get(""/sys/fs/cgroup/cpu"", controlGroup, ""cpu.cfs_quota_us""));
    }","/**
     * Returns the line from {@code cpu.cfs_quota_us} for the control group to which the Elasticsearch process belongs for the {@code cpu}
     * subsystem. This line represents the total time in microseconds that all tasks in the control group can run during one period as
     * specified by {@code cpu.cfs_period_us}.
     *
     * @param controlGroup the control group to which the Elasticsearch process belongs for the {@code cpu} subsystem
     * @return the line from {@code cpu.cfs_quota_us}
     * @throws IOException if an I/O exception occurs reading {@code cpu.cfs_quota_us} for the control group
     */",67087d9d82a3a5339cc3dd45
"void dropIndexPopulation(IndexPopulation indexPopulation) {
        indexPopulation.disconnectAndDrop();
        checkEmpty();
    }","/**
     * Stop population of given {@link IndexPopulation} and drop the index.
     * @param indexPopulation {@link IndexPopulation} to drop.
     */",67087d9d82a3a5339cc3dd46
"public void setSpringFrequencyHz (float hz) {
		joint.setSpringFrequencyHz(hz);
	}",/** Set/Get the spring frequency in hertz. Setting the frequency to zero disables the spring. */,67087d9d82a3a5339cc3dd47
"public static boolean intersectBoundsPlaneFast (Vector3 center, Vector3 halfDimensions, Vector3 normal, float distance) {
		// Compute the projection interval radius of b onto L(t) = b.c + t * p.n
		float radius = halfDimensions.x * Math.abs(normal.x) + halfDimensions.y * Math.abs(normal.y)
			+ halfDimensions.z * Math.abs(normal.z);

		// Compute distance of box center from plane
		float s = normal.dot(center) - distance;

		// Intersection occurs when plane distance falls within [-r,+r] interval
		return Math.abs(s) <= radius;
	}","/** Quick check whether the given bounding box and a plane intersect. Code adapted from Christer Ericson's Real Time Collision
	 * @param center The center of the bounding box
	 * @param halfDimensions Half of the dimensions (width, height and depth) of the bounding box
	 * @param normal The normal of the plane
	 * @param distance The distance of the plane
	 * @return Whether the bounding box and the plane intersect. */",67087d9d82a3a5339cc3dd48
"static VectorValueMatcher allFalseSingleValueDimensionMatcher(SingleValueDimensionVectorSelector selector)
  {
    final IdLookup idLookup = selector.idLookup();
    final VectorMatch match = VectorMatch.wrap(new int[selector.getMaxVectorSize()]);

    if (idLookup == null || !selector.nameLookupPossibleInAdvance()) {
      // must call selector.lookupName on every id to check for nulls
      return new BaseVectorValueMatcher(selector)
      {
        @Override
        public ReadableVectorMatch match(ReadableVectorMatch mask, boolean includeUnknown)
        {
          if (includeUnknown) {
            final int[] vector = selector.getRowVector();
            final int[] inputSelection = mask.getSelection();
            final int inputSelectionSize = mask.getSelectionSize();
            final int[] outputSelection = match.getSelection();
            int outputSelectionSize = 0;

            for (int i = 0; i < inputSelectionSize; i++) {
              final int rowNum = inputSelection[i];
              if (NullHandling.isNullOrEquivalent(selector.lookupName(vector[rowNum]))) {
                outputSelection[outputSelectionSize++] = rowNum;
              }
            }
            match.setSelectionSize(outputSelectionSize);
            return match;
          }
          return VectorMatch.allFalse();
        }
      };
    } else {
      final int nullId = idLookup.lookupId(null);
      // column doesn't have nulls, can safely return an 'all false' matcher
      if (nullId < 0) {
        return ConstantMatcherType.ALL_FALSE.asVectorMatcher(selector);
      }

      return new BaseVectorValueMatcher(selector)
      {
        @Override
        public ReadableVectorMatch match(ReadableVectorMatch mask, boolean includeUnknown)
        {
          if (includeUnknown) {
            final int[] vector = selector.getRowVector();
            final int[] inputSelection = mask.getSelection();
            final int inputSelectionSize = mask.getSelectionSize();
            final int[] outputSelection = match.getSelection();
            int outputSelectionSize = 0;

            for (int i = 0; i < inputSelectionSize; i++) {
              final int rowNum = inputSelection[i];
              if (vector[rowNum] == nullId) {
                outputSelection[outputSelectionSize++] = rowNum;
              }
            }
            match.setSelectionSize(outputSelectionSize);
            return match;
          }
          return VectorMatch.allFalse();
        }
      };
    }
  }","/**
   * Make an always false {@link VectorValueMatcher} for a {@link SingleValueDimensionVectorSelector}. When
   * {@code includeUnknown} is specified to the {@link VectorValueMatcher#match(ReadableVectorMatch, boolean)} function,
   * this matcher will add all rows of {@link SingleValueDimensionVectorSelector#getRowVector()} which are null to the
   * {@link ReadableVectorMatch} as selections, to participate in Druid 2-state logic system to SQL 3-state logic
   * system conversion.
   */",67087d9d82a3a5339cc3dd49
"public void setJmsMessageConverter(MessageConverter jmsMessageConverter) {
		Assert.notNull(jmsMessageConverter, ""MessageConverter must not be null"");
		this.jmsMessageConverter = jmsMessageConverter;
		this.converterSet = true;
	}","/**
	 * Set the {@link MessageConverter} to use to convert a {@link Message} from
	 * the messaging to and from a {@link jakarta.jms.Message}. By default, a
	 * {@link MessagingMessageConverter} is defined using a {@link SimpleMessageConverter}
	 * to convert the payload of the message.
	 * <p>Consider configuring a {@link MessagingMessageConverter} with a different
	 * {@link MessagingMessageConverter#setPayloadConverter(MessageConverter) payload converter}
	 * for more advanced scenarios.
	 * @see org.springframework.jms.support.converter.MessagingMessageConverter
	 */",67087d9d82a3a5339cc3dd4a
"void spawnNativeControllers(final Environment environment) throws IOException {
        if (spawned.compareAndSet(false, true) == false) {
            throw new IllegalStateException(""native controllers already spawned"");
        }
        if (Files.exists(environment.modulesFile()) == false) {
            throw new IllegalStateException(""modules directory ["" + environment.modulesFile() + ""] not found"");
        }
        /*
         * For each module, attempt to spawn the controller daemon. Silently ignore any module that doesn't include a controller for the
         * correct platform.
         */
        List<Path> paths = PluginsUtils.findPluginDirs(environment.modulesFile());
        for (final Path modules : paths) {
            final PluginDescriptor info = PluginDescriptor.readFromProperties(modules);
            final Path spawnPath = Platforms.nativeControllerPath(modules);
            if (Files.isRegularFile(spawnPath) == false) {
                continue;
            }
            if (info.hasNativeController() == false) {
                final String message = String.format(
                    Locale.ROOT,
                    ""module [%s] does not have permission to fork native controller"",
                    modules.getFileName()
                );
                throw new IllegalArgumentException(message);
            }
            final Process process = spawnNativeController(spawnPath, environment.tmpFile());
            // The process _shouldn't_ write any output via its stdout or stderr, but if it does then
            // it will block if nothing is reading that output. To avoid this we can pipe the
            // outputs and create pump threads to write any messages there to the ES log.
            startPumpThread(info.getName(), ""stdout"", process.getInputStream());
            startPumpThread(info.getName(), ""stderr"", process.getErrorStream());
            processes.add(process);
        }
    }","/**
     * Spawns the native controllers for each module.
     *
     * @param environment The node environment
     * @throws IOException if an I/O error occurs reading the module or spawning a native process
     */",67087d9d82a3a5339cc3dd4b
"final ByteVector put122(final int byteValue, final int shortValue1, final int shortValue2) {
    int currentLength = length;
    if (currentLength + 5 > data.length) {
      enlarge(5);
    }
    byte[] currentData = data;
    currentData[currentLength++] = (byte) byteValue;
    currentData[currentLength++] = (byte) (shortValue1 >>> 8);
    currentData[currentLength++] = (byte) shortValue1;
    currentData[currentLength++] = (byte) (shortValue2 >>> 8);
    currentData[currentLength++] = (byte) shortValue2;
    length = currentLength;
    return this;
  }","/**
   * Puts one byte and two shorts into this byte vector. The byte vector is automatically enlarged
   * if necessary.
   *
   * @param byteValue a byte.
   * @param shortValue1 a short.
   * @param shortValue2 another short.
   * @return this byte vector.
   */",67087d9d82a3a5339cc3dd4c
"@Override
	public Document loadDocument(InputSource inputSource, EntityResolver entityResolver,
			ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception {

		DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware);
		if (logger.isTraceEnabled()) {
			logger.trace(""Using JAXP provider ["" + factory.getClass().getName() + ""]"");
		}
		DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler);
		return builder.parse(inputSource);
	}","/**
	 * Load the {@link Document} at the supplied {@link InputSource} using the standard JAXP-configured
	 * XML parser.
	 */",67087d9d82a3a5339cc3dd4d
"public String getDetailedLogMessage(@Nullable Object payload) {
		return ""headers="" + this.headers.toString() + getDetailedPayloadLogMessage(payload);
	}","/**
	 * Return a more detailed message for logging purposes.
	 * @param payload the payload that corresponds to the headers.
	 * @return the message
	 */",67087d9d82a3a5339cc3dd4e
"private void sortWithIndices (float[] values, int count, boolean yDown) {
		int pointCount = count / 2;
		originalIndices.clear();
		originalIndices.ensureCapacity(pointCount);
		short[] originalIndicesArray = originalIndices.items;
		for (short i = 0; i < pointCount; i++)
			originalIndicesArray[i] = i;

		int lower = 0;
		int upper = count - 1;
		IntArray stack = quicksortStack;
		stack.add(lower);
		stack.add(upper - 1);
		while (stack.size > 0) {
			upper = stack.pop();
			lower = stack.pop();
			if (upper <= lower) continue;
			int i = quicksortPartitionWithIndices(values, lower, upper, yDown, originalIndicesArray);
			if (i - lower > upper - i) {
				stack.add(lower);
				stack.add(i - 2);
			}
			stack.add(i + 2);
			stack.add(upper);
			if (upper - i >= i - lower) {
				stack.add(lower);
				stack.add(i - 2);
			}
		}
	}","/** Sorts x,y pairs of values by the x value, then the y value and stores unsorted original indices.
	 * @param count Number of indices, must be even. */",67087d9d82a3a5339cc3dd4f
"public void setLength (float length) {
		joint.setLength(length);
	}",/** Set/get the natural length. Manipulating the length can lead to non-physical behavior when the frequency is zero. */,67087d9d82a3a5339cc3dd50
"public static QueryBuilder translateQueryBuilderFields(QueryBuilder queryBuilder, @Nullable Consumer<String> visitor) {
        Objects.requireNonNull(queryBuilder, ""unsupported \""null\"" query builder for field name translation"");
        final Consumer<String> fieldNameVisitor = visitor != null ? visitor : ignored -> {};
        if (queryBuilder instanceof final BoolQueryBuilder query) {
            final BoolQueryBuilder newQuery = QueryBuilders.boolQuery()
                .minimumShouldMatch(query.minimumShouldMatch())
                .adjustPureNegative(query.adjustPureNegative())
                .boost(query.boost())
                .queryName(query.queryName());
            query.must().stream().map(q -> translateQueryBuilderFields(q, fieldNameVisitor)).forEach(newQuery::must);
            query.should().stream().map(q -> translateQueryBuilderFields(q, fieldNameVisitor)).forEach(newQuery::should);
            query.mustNot().stream().map(q -> translateQueryBuilderFields(q, fieldNameVisitor)).forEach(newQuery::mustNot);
            query.filter().stream().map(q -> translateQueryBuilderFields(q, fieldNameVisitor)).forEach(newQuery::filter);
            return newQuery;
        } else if (queryBuilder instanceof final MatchAllQueryBuilder query) {
            // just be safe and consistent to always return a new copy instance of the translated query builders
            return QueryBuilders.matchAllQuery().boost(query.boost()).queryName(query.queryName());
        } else if (queryBuilder instanceof final IdsQueryBuilder query) {
            // just be safe and consistent to always return a new copy instance of the translated query builders
            return QueryBuilders.idsQuery().addIds(query.ids().toArray(new String[0])).boost(query.boost()).queryName(query.queryName());
        } else if (queryBuilder instanceof final TermQueryBuilder query) {
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            return QueryBuilders.termQuery(translatedFieldName, query.value())
                .caseInsensitive(query.caseInsensitive())
                .boost(query.boost())
                .queryName(query.queryName());
        } else if (queryBuilder instanceof final ExistsQueryBuilder query) {
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            return QueryBuilders.existsQuery(translatedFieldName).boost(query.boost()).queryName(query.queryName());
        } else if (queryBuilder instanceof final TermsQueryBuilder query) {
            if (query.termsLookup() != null) {
                throw new IllegalArgumentException(""terms query with terms lookup is not supported for API Key query"");
            }
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            return QueryBuilders.termsQuery(translatedFieldName, query.getValues()).boost(query.boost()).queryName(query.queryName());
        } else if (queryBuilder instanceof final PrefixQueryBuilder query) {
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            return QueryBuilders.prefixQuery(translatedFieldName, query.value())
                .caseInsensitive(query.caseInsensitive())
                .rewrite(query.rewrite())
                .boost(query.boost())
                .queryName(query.queryName());
        } else if (queryBuilder instanceof final WildcardQueryBuilder query) {
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            return QueryBuilders.wildcardQuery(translatedFieldName, query.value())
                .caseInsensitive(query.caseInsensitive())
                .rewrite(query.rewrite())
                .boost(query.boost())
                .queryName(query.queryName());
        } else if (queryBuilder instanceof final MatchQueryBuilder query) {
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            final MatchQueryBuilder matchQueryBuilder = QueryBuilders.matchQuery(translatedFieldName, query.value());
            if (query.operator() != null) {
                matchQueryBuilder.operator(query.operator());
            }
            if (query.analyzer() != null) {
                matchQueryBuilder.analyzer(query.analyzer());
            }
            if (query.fuzziness() != null) {
                matchQueryBuilder.fuzziness(query.fuzziness());
            }
            if (query.minimumShouldMatch() != null) {
                matchQueryBuilder.minimumShouldMatch(query.minimumShouldMatch());
            }
            if (query.fuzzyRewrite() != null) {
                matchQueryBuilder.fuzzyRewrite(query.fuzzyRewrite());
            }
            if (query.zeroTermsQuery() != null) {
                matchQueryBuilder.zeroTermsQuery(query.zeroTermsQuery());
            }
            matchQueryBuilder.prefixLength(query.prefixLength())
                .maxExpansions(query.maxExpansions())
                .fuzzyTranspositions(query.fuzzyTranspositions())
                .lenient(query.lenient())
                .autoGenerateSynonymsPhraseQuery(query.autoGenerateSynonymsPhraseQuery())
                .boost(query.boost())
                .queryName(query.queryName());
            return matchQueryBuilder;
        } else if (queryBuilder instanceof final RangeQueryBuilder query) {
            if (query.relation() != null) {
                throw new IllegalArgumentException(""range query with relation is not supported for API Key query"");
            }
            final String translatedFieldName = translate(query.fieldName());
            fieldNameVisitor.accept(translatedFieldName);
            final RangeQueryBuilder newQuery = QueryBuilders.rangeQuery(translatedFieldName);
            if (query.format() != null) {
                newQuery.format(query.format());
            }
            if (query.timeZone() != null) {
                newQuery.timeZone(query.timeZone());
            }
            if (query.from() != null) {
                newQuery.from(query.from()).includeLower(query.includeLower());
            }
            if (query.to() != null) {
                newQuery.to(query.to()).includeUpper(query.includeUpper());
            }
            return newQuery.boost(query.boost()).queryName(query.queryName());
        } else if (queryBuilder instanceof final SimpleQueryStringBuilder query) {
            SimpleQueryStringBuilder simpleQueryStringBuilder = QueryBuilders.simpleQueryStringQuery(query.value());
            Map<String, Float> queryFields = new HashMap<>(query.fields());
            // be explicit that no field means all fields
            if (queryFields.isEmpty()) {
                queryFields.put(""*"", AbstractQueryBuilder.DEFAULT_BOOST);
            }
            // override ""lenient"" if querying all the fields, because, due to different field mappings,
            // the query parsing will almost certainly fail otherwise
            if (QueryParserHelper.hasAllFieldsWildcard(queryFields.keySet())) {
                simpleQueryStringBuilder.lenient(true);
            } else {
                simpleQueryStringBuilder.lenient(query.lenient());
            }
            // translate query-level field name patterns to index-level concrete field names
            for (Map.Entry<String, Float> requestedFieldNameOrPattern : queryFields.entrySet()) {
                for (String translatedField : translatePattern(requestedFieldNameOrPattern.getKey())) {
                    simpleQueryStringBuilder.fields()
                        .compute(
                            translatedField,
                            (k, v) -> (v == null) ? requestedFieldNameOrPattern.getValue() : v * requestedFieldNameOrPattern.getValue()
                        );
                    fieldNameVisitor.accept(translatedField);
                }
            }
            if (simpleQueryStringBuilder.fields().isEmpty()) {
                // A SimpleQueryStringBuilder with empty fields() will eventually produce a SimpleQueryString
                // Lucene query that accesses all the fields, including disallowed ones.
                // Instead, the behavior we're after here is that a query that accesses only disallowed fields
                // mustn't match any docs.
                return new MatchNoneQueryBuilder().boost(simpleQueryStringBuilder.boost()).queryName(simpleQueryStringBuilder.queryName());
            }
            return simpleQueryStringBuilder.analyzer(query.analyzer())
                .defaultOperator(query.defaultOperator())
                .minimumShouldMatch(query.minimumShouldMatch())
                .flags(query.flags())
                .type(query.type())
                .quoteFieldSuffix(query.quoteFieldSuffix())
                .analyzeWildcard(query.analyzeWildcard())
                .autoGenerateSynonymsPhraseQuery(query.autoGenerateSynonymsPhraseQuery())
                .fuzzyTranspositions(query.fuzzyTranspositions())
                .fuzzyMaxExpansions(query.fuzzyMaxExpansions())
                .fuzzyPrefixLength(query.fuzzyPrefixLength())
                .boost(query.boost())
                .queryName(query.queryName());
        } else {
            throw new IllegalArgumentException(""Query type ["" + queryBuilder.getName() + ""] is not supported for API Key query"");
        }
    }","/**
     * Deep copies the passed-in {@param queryBuilder} translating all the field names, from query level to index level,
     * see {@link  #translate}. In general, the returned builder should create the same query as if the query were
     * created by the passed in {@param queryBuilder}, only with the field names translated.
     * Field name patterns (including ""*""), are also replaced with the explicit index level field names whose
     * associated query level field names match the pattern.
     * The optional {@param visitor} can be used to collect all the translated field names.
     */",67087d9d82a3a5339cc3dd51
"public void testIndexDeletionWhenNodeRejoins() throws Exception {
        final String indexName = ""test-index-del-on-node-rejoin-idx"";
        final int numNodes = 2;

        final List<String> nodes;
        logger.info(""--> starting a cluster with "" + numNodes + "" nodes"");
        nodes = internalCluster().startNodes(
            numNodes,
            Settings.builder().put(IndexGraveyard.SETTING_MAX_TOMBSTONES.getKey(), randomIntBetween(10, 100)).build()
        );
        logger.info(""--> create an index"");
        createIndex(indexName);

        logger.info(""--> waiting for green status"");
        ensureGreen();
        final String indexUUID = resolveIndex(indexName).getUUID();

        logger.info(""--> restart a random date node, deleting the index in between stopping and restarting"");
        internalCluster().restartRandomDataNode(new RestartCallback() {
            @Override
            public Settings onNodeStopped(final String nodeName) throws Exception {
                nodes.remove(nodeName);
                logger.info(""--> stopped node[{}], remaining nodes {}"", nodeName, nodes);
                assert nodes.size() > 0;
                final String otherNode = nodes.get(0);
                logger.info(""--> delete index and verify it is deleted"");
                final Client client = client(otherNode);
                client.admin().indices().prepareDelete(indexName).get();
                assertFalse(indexExists(indexName, client));
                logger.info(""--> index deleted"");
                return super.onNodeStopped(nodeName);
            }
        });

        logger.info(""--> wait until all nodes are back online"");
        clusterAdmin().health(
            new ClusterHealthRequest(new String[] {}).waitForEvents(Priority.LANGUID).waitForNodes(Integer.toString(numNodes))
        ).actionGet();

        logger.info(""--> waiting for green status"");
        ensureGreen();

        logger.info(""--> verify that the deleted index is removed from the cluster and not reimported as dangling by the restarted node"");
        assertFalse(indexExists(indexName));
        assertBusy(() -> {
            final NodeEnvironment nodeEnv = internalCluster().getInstance(NodeEnvironment.class);
            try {
                assertFalse(""index folder "" + indexUUID + "" should be deleted"", nodeEnv.availableIndexFolders().contains(indexUUID));
            } catch (IOException e) {
                logger.error(""Unable to retrieve available index folders from the node"", e);
                fail(""Unable to retrieve available index folders from the node"");
            }
        });
    }","/**
     * This test ensures that when an index deletion takes place while a node is offline, when that
     * node rejoins the cluster, it deletes the index locally instead of importing it as a dangling index.
     */",67087d9d82a3a5339cc3dd52
"public static String encodeFragment(String fragment, String encoding) {
		return encode(fragment, encoding, HierarchicalUriComponents.Type.FRAGMENT);
	}","/**
	 * Encode the given URI fragment with the given encoding.
	 * @param fragment the fragment to be encoded
	 * @param encoding the character encoding to encode to
	 * @return the encoded fragment
	 */",67087d9d82a3a5339cc3dd53
"private int purge(final int maxTombstones) {
            int count = tombstones().size() - maxTombstones;
            if (count <= 0) {
                return 0;
            }
            tombstones = tombstones.subList(count, tombstones.size());
            return count;
        }","/**
         * Purge tombstone entries.  Returns the number of entries that were purged.
         *
         * Tombstones are purged if the number of tombstones in the list
         * is greater than the input parameter of maximum allowed tombstones.
         * Tombstones are purged until the list is equal to the maximum allowed.
         */",67087d9d82a3a5339cc3dd54
"@Test(expected = RuntimeException.class)
  public void testPullDependencies_root_hadoop_dependencies_dir_bad_state() throws IOException
  {
    Assert.assertTrue(rootHadoopDependenciesDir.delete());
    Assert.assertTrue(rootHadoopDependenciesDir.createNewFile());
    pullDependencies.run();
  }","/**
   * A file exists on the root hadoop dependencies directory path, but it's not a directory, throw exception.
   */",67087d9d82a3a5339cc3dd55
"public CookieMapAssert hasValue(String name, String expected) {
		return hasCookieSatisfying(name, cookie ->
				Assertions.assertThat(cookie.getValue()).isEqualTo(expected));
	}","/**
	 * Verify that the actual cookies contain a cookie with the given {@code name}
	 * whose {@linkplain Cookie#getValue() value} is equal to the given one.
	 * @param name the name of the cookie
	 * @param expected the expected value of the cookie
	 */",67087d9d82a3a5339cc3dd56
"public static String md5DigestAsHex(InputStream inputStream) throws IOException {
		return digestAsHexString(MD5_ALGORITHM_NAME, inputStream);
	}","/**
	 * Return a hexadecimal string representation of the MD5 digest of the given stream.
	 * <p>This method does <strong>not</strong> close the input stream.
	 * @param inputStream the InputStream to calculate the digest over
	 * @return a hexadecimal digest string
	 * @since 4.2
	 */",67087d9d82a3a5339cc3dd57
"public ResultMatcher sessionAttribute(String name, @Nullable Object value) {
		return result -> {
			HttpSession session = result.getRequest().getSession();
			Assert.state(session != null, ""No HttpSession"");
			assertEquals(""Session attribute '"" + name + ""'"", value, session.getAttribute(name));
		};
	}","/**
	 * Assert a session attribute value.
	 */",67087d9d82a3a5339cc3dd58
"public static Block fromElementBlock(int positionCount, Optional<boolean[]> valueIsNullOptional, int[] arrayOffset, Block values)
    {
        boolean[] valueIsNull = valueIsNullOptional.orElse(null);
        validateConstructorArguments(0, positionCount, valueIsNull, arrayOffset, values);
        // for performance reasons per element checks are only performed on the public construction
        for (int i = 0; i < positionCount; i++) {
            int offset = arrayOffset[i];
            int length = arrayOffset[i + 1] - offset;
            if (length < 0) {
                throw new IllegalArgumentException(format(""Offset is not monotonically ascending. offsets[%s]=%s, offsets[%s]=%s"", i, arrayOffset[i], i + 1, arrayOffset[i + 1]));
            }
            if (valueIsNull != null && valueIsNull[i] && length != 0) {
                throw new IllegalArgumentException(""A null array must have zero entries"");
            }
        }
        return new ArrayBlock(0, positionCount, valueIsNull, arrayOffset, values);
    }","/**
     * Create an array block directly from columnar nulls, values, and offsets into the values.
     * A null array must have no entries.
     */",67087d9d82a3a5339cc3dd59
"public static Header.Factory defaultFormatRelationshipFileHeader(boolean normalizeTypes) {
        return defaultFormatRelationshipFileHeader(DEFAULT_TIME_ZONE, normalizeTypes);
    }","/**
     * Like {@link #defaultFormatRelationshipFileHeader(Supplier, boolean)} with UTC as the default time zone.
     * @param normalizeTypes whether or not to normalize types.
     */",67087d9d82a3a5339cc3dd5a
"public boolean has(int[] entityTokenIds, int propertyKey) {
        // Abort right away if there are no descriptors at all
        if (isEmpty()) {
            return false;
        }

        // Check if there are any descriptors that matches any of the first (or only) entity token
        for (long entityTokenId : entityTokenIds) {
            PropertyMultiSet set = byEntityToken.get(toIntExact(entityTokenId));
            if (set != null && set.has(propertyKey)) {
                return true;
            }
        }
        return false;
    }","/**
     * Cheap way of finding out whether or not there are any descriptors matching the set of entity token ids and the property key id.
     *
     * @param entityTokenIds complete list of entity token ids for the entity to check.
     * @param propertyKey a property key id to check.
     * @return {@code true} if there are one or more descriptors matching the given tokens.
     */",67087d9d82a3a5339cc3dd5b
"public static String decodeComponent(final String s) {
        return decodeComponent(s, HttpConstants.DEFAULT_CHARSET);
    }","/**
     * Decodes a bit of a URL encoded by a browser.
     * <p>
     * This is equivalent to calling {@link #decodeComponent(String, Charset)}
     * with the UTF-8 charset (recommended to comply with RFC 3986, Section 2).
     * @param s The string to decode (can be empty).
     * @return The decoded string, or {@code s} if there's nothing to decode.
     * If the string to decode is {@code null}, returns an empty string.
     * @throws IllegalArgumentException if the string contains a malformed
     * escape sequence.
     */",67087d9d82a3a5339cc3dd5c
"public void setHasVertex0 (boolean hasVertex0) {
		jniSetHasVertex0(addr, hasVertex0);
	}","/*
		b2EdgeShape* edge = (b2EdgeShape*)addr;
		return edge->m_hasVertex0;
	*/",67087d9d82a3a5339cc3dd5d
"static InetAddress[] getGlobalAddresses() throws IOException {
        return filterAllAddresses(
            address -> address.isLoopbackAddress() == false
                && address.isSiteLocalAddress() == false
                && address.isLinkLocalAddress() == false,
            ""no up-and-running global-scope (public) addresses found""
        );
    }",/** Returns all global scope addresses for interfaces that are up. */,67087d9d82a3a5339cc3dd5e
"public SpringPersistenceUnitInfo[] readPersistenceUnitInfos(String[] persistenceXmlLocations) {
		ErrorHandler handler = new SimpleSaxErrorHandler(logger);
		List<SpringPersistenceUnitInfo> infos = new ArrayList<>(1);
		String resourceLocation = null;
		try {
			for (String location : persistenceXmlLocations) {
				Resource[] resources = this.resourcePatternResolver.getResources(location);
				for (Resource resource : resources) {
					resourceLocation = resource.toString();
					try (InputStream stream = resource.getInputStream()) {
						Document document = buildDocument(handler, stream);
						parseDocument(resource, document, infos);
					}
				}
			}
		}
		catch (IOException ex) {
			throw new IllegalArgumentException(""Cannot parse persistence unit from "" + resourceLocation, ex);
		}
		catch (SAXException ex) {
			throw new IllegalArgumentException(""Invalid XML in persistence unit from "" + resourceLocation, ex);
		}
		catch (ParserConfigurationException ex) {
			throw new IllegalArgumentException(""Internal error parsing persistence unit from "" + resourceLocation);
		}

		return infos.toArray(new SpringPersistenceUnitInfo[0]);
	}","/**
	 * Parse and build all persistence unit infos defined in the given XML files.
	 * @param persistenceXmlLocations the resource locations (can be patterns)
	 * @return the resulting PersistenceUnitInfo instances
	 */",67087d9d82a3a5339cc3dd5f
"public ResultMatcher isAccepted() {
		return matcher(HttpStatus.ACCEPTED);
	}","/**
	 * Assert the response status code is {@code HttpStatus.ACCEPTED} (202).
	 */",67087d9d82a3a5339cc3dd60
"static Object unwrapResourceIfNecessary(Object resource) {
		Assert.notNull(resource, ""Resource must not be null"");
		Object resourceRef = resource;
		// unwrap infrastructure proxy
		if (resourceRef instanceof InfrastructureProxy infrastructureProxy) {
			resourceRef = infrastructureProxy.getWrappedObject();
		}
		if (aopAvailable) {
			// now unwrap scoped proxy
			resourceRef = ScopedProxyUnwrapper.unwrapIfNecessary(resourceRef);
		}
		return resourceRef;
	}","/**
	 * Unwrap the given resource handle if necessary; otherwise return
	 * the given handle as-is.
	 * @see InfrastructureProxy#getWrappedObject()
	 */",67087d9d82a3a5339cc3dd61
"public static void register(BeanDefinitionRegistry registry, String... packageNames) {
		if (registry.containsBeanDefinition(BEAN)) {
			addBasePackages(registry.getBeanDefinition(BEAN), packageNames);
		}
		else {
			RootBeanDefinition beanDefinition = new RootBeanDefinition(BasePackages.class);
			beanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);
			addBasePackages(beanDefinition, packageNames);
			registry.registerBeanDefinition(BEAN, beanDefinition);
		}
	}","/**
	 * Programmatically registers the auto-configuration package names. Subsequent
	 * invocations will add the given package names to those that have already been
	 * registered. You can use this method to manually define the base packages that will
	 * be used for a given {@link BeanDefinitionRegistry}. Generally it's recommended that
	 * you don't call this method directly, but instead rely on the default convention
	 * where the package name is set from your {@code @EnableAutoConfiguration}
	 * configuration class or classes.
	 * @param registry the bean definition registry
	 * @param packageNames the package names to set
	 */",67087d9d82a3a5339cc3dd62
"public static void stableSort(int[] order, double[] values, int n) {
        for (int i = 0; i < n; i++) {
            order[i] = i;
        }
        stableQuickSort(order, values, 0, n, 64);
        stableInsertionSort(order, values, 0, n, 64);
    }","/**
     * Single-key stabilized quick sort on using an index array
     *
     * @param order   Indexes into values
     * @param values  The values to sort.
     * @param n       The number of values to sort
     */",67087d9d82a3a5339cc3dd63
"private static void followReferral(
        LDAPConnection ldapConnection,
        String urlString,
        SearchRequest searchRequest,
        ActionListener<SearchResult> listener,
        int depth,
        boolean ignoreErrors,
        SearchResult originatingResult
    ) throws LDAPException {

        final LDAPURL referralURL = new LDAPURL(urlString);
        final String host = referralURL.getHost();
        // the host must be present in order to follow a referral
        if (host == null) {
            // nothing to really do since a null host cannot really be handled, so we treat it as
            // an error
            throw new LDAPException(ResultCode.UNAVAILABLE, ""Null referral host in "" + urlString);
        }

        // the referral URL often contains information necessary about the LDAP request such as
        // the base DN, scope, and filter. If it does not, then we reuse the values from the
        // originating search request
        final String requestBaseDN;
        if (referralURL.baseDNProvided()) {
            requestBaseDN = referralURL.getBaseDN().toString();
        } else {
            requestBaseDN = searchRequest.getBaseDN();
        }

        final SearchScope requestScope;
        if (referralURL.scopeProvided()) {
            requestScope = referralURL.getScope();
        } else {
            requestScope = searchRequest.getScope();
        }

        final Filter requestFilter;
        if (referralURL.filterProvided()) {
            requestFilter = referralURL.getFilter();
        } else {
            requestFilter = searchRequest.getFilter();
        }

        // in order to follow the referral we need to open a new connection and we do so using the
        // referral connector on the ldap connection
        final LDAPConnection referralConn = privilegedConnect(
            () -> ldapConnection.getReferralConnector().getReferralConnection(referralURL, ldapConnection)
        );
        final LdapSearchResultListener ldapListener = new LdapSearchResultListener(
            referralConn,
            ignoreErrors,
            ActionListener.wrap(searchResult -> {
                IOUtils.close(referralConn);
                listener.onResponse(searchResult);
            }, e -> {
                IOUtils.closeWhileHandlingException(referralConn);
                if (ignoreErrors) {
                    if (LOGGER.isDebugEnabled()) {
                        LOGGER.debug(
                            () -> format(""Failed to retrieve results from referral URL [%s]."" + "" Treating as 'no results'"", referralURL),
                            e
                        );
                    }
                    listener.onResponse(emptyResult(originatingResult));
                } else {
                    listener.onFailure(e);
                }
            }),
            depth
        );
        boolean success = false;
        try {
            final SearchRequest referralSearchRequest = new SearchRequest(
                ldapListener,
                searchRequest.getControls(),
                requestBaseDN,
                requestScope,
                searchRequest.getDereferencePolicy(),
                searchRequest.getSizeLimit(),
                searchRequest.getTimeLimitSeconds(),
                searchRequest.typesOnly(),
                requestFilter,
                searchRequest.getAttributes()
            );
            ldapListener.setSearchRequest(searchRequest);
            referralConn.asyncSearch(referralSearchRequest);
            success = true;
        } finally {
            if (success == false) {
                IOUtils.closeWhileHandlingException(referralConn);
            }
        }
    }","/**
     * Performs the actual connection and following of a referral given a URL string.
     * This referral is being followed as it may contain a result that is relevant to our search
     */",67087d9d82a3a5339cc3dd64
"public void testTextFieldWithKeywordSubfield() throws IOException {
        String text = randomAlphaOfLength(10) + "" "" + randomAlphaOfLength(10);
        boolean ignoreAbove = randomBoolean();
        String fieldName = ""text_field"";
        String subFieldName = ""text_field.keyword_subfield"";
        String query = ""SELECT "" + fieldName + "","" + subFieldName + "" FROM test"";

        Map<String, Map<String, Object>> subFieldsProps = null;
        if (ignoreAbove) {
            subFieldsProps = Maps.newMapWithExpectedSize(1);
            Map<String, Object> fieldProp = Maps.newMapWithExpectedSize(1);
            fieldProp.put(""ignore_above"", 10);
            subFieldsProps.put(subFieldName, fieldProp);
        }

        createIndexWithFieldTypeAndSubFields(""text"", null, getIndexProps(), subFieldsProps, ""keyword"");
        index(""{\"""" + fieldName + ""\"":\"""" + text + ""\""}"");

        Map<String, Object> expected = new HashMap<>();
        expected.put(
            ""columns"",
            asList(
                columnInfo(""plain"", fieldName, ""text"", JDBCType.VARCHAR, Integer.MAX_VALUE),
                columnInfo(""plain"", subFieldName, ""keyword"", JDBCType.VARCHAR, Integer.MAX_VALUE)
            )
        );

        expected.put(
            ""rows"",
            singletonList(asList(getExpectedValueFromSource(text), getExpectedValueFromSource(ignoreAbove ? null : text)))
        );
        assertResponse(expected, runSql(query));
    }","/*
     *    ""text_field"": {
     *       ""type"": ""text"",
     *       ""fields"": {
     *         ""keyword_subfield"": {
     *           ""type"": ""keyword"",
     *           ""ignore_above"": 10
     *         }
     *       }
     *     }
     */",67087d9d82a3a5339cc3dd65
"@Override
	public MimeMessage createMimeMessage() {
		return new SmartMimeMessage(getSession(), getDefaultEncoding(), getDefaultFileTypeMap());
	}","/**
	 * This implementation creates a SmartMimeMessage, holding the specified
	 * default encoding and default FileTypeMap. This special defaults-carrying
	 * message will be autodetected by {@link MimeMessageHelper}, which will use
	 * the carried encoding and FileTypeMap unless explicitly overridden.
	 * @see #setDefaultEncoding
	 * @see #setDefaultFileTypeMap
	 */",67087d9d82a3a5339cc3dd66
"public IndicesStatsRequest clear() {
        flags.clear();
        return this;
    }","/**
     * Clears all stats.
     */",67087d9d82a3a5339cc3dd67
"@SuppressWarnings(""unchecked"")
	@Nullable
	default <T> T getAttribute(String name) {
		return (T) getAttributes().get(name);
	}","/**
	 * Return the request attribute value if present.
	 * @param name the attribute name
	 * @param <T> the attribute type
	 * @return the attribute value
	 */",67087d9d82a3a5339cc3dd68
"private void adjustTree(Node n, Node nn)
  {
    // special case for root
    if (n == root) {
      if (nn != null) {
        root = buildRoot(false);
        root.addChild(n);
        root.addChild(nn);
      }
      root.enclose();
      return;
    }

    boolean updateParent = n.enclose();

    if (nn != null) {
      nn.enclose();
      updateParent = true;

      if (splitStrategy.needToSplit(n.getParent())) {
        Node[] groups = splitStrategy.split(n.getParent());
        adjustTree(groups[0], groups[1]);
      }
    }

    if (n.getParent() != null && updateParent) {
      adjustTree(n.getParent(), null);
    }
  }","/**
   * This description is from the original paper.
   *
   * AT1. [Initialize]. Set N=L. If L was split previously, set NN to be the resulting second node.
   *
   * AT2. [Check if done]. If N is the root, stop.
   *
   * AT3. [Adjust covering rectangle in parent entry]. Let P be the parent node of N, and let Ev(N)I be N's entry in P.
   * Adjust Ev(N)I so that it tightly encloses all entry rectangles in N.
   *
   * AT4. [Propagate node split upward]. If N has a partner NN resulting from an earlier split, create a new entry
   * Ev(NN) with Ev(NN)p pointing to NN and Ev(NN)I enclosing all rectangles in NN. Add Ev(NN) to p is there is room.
   * Otherwise, invoke {@link SplitStrategy} split to product p and pp containing Ev(NN) and all p's old entries.
   *
   * @param n  - first node to adjust
   * @param nn - optional second node to adjust
   */",67087d9d82a3a5339cc3dd69
"@WorkerThread
  public synchronized void updateMessageRingtone(@NonNull Recipient recipient, @Nullable Uri uri) {
    if (!supported() || recipient.getNotificationChannel() == null) {
      return;
    }
    Log.i(TAG, ""Updating recipient message ringtone with URI: "" + uri);

    String  newChannelId = generateChannelIdFor(recipient);
    boolean success      = updateExistingChannel(ServiceUtil.getNotificationManager(context),
                                                 recipient.getNotificationChannel(),
                                                 generateChannelIdFor(recipient),
                                                 channel -> channel.setSound(uri == null ? Settings.System.DEFAULT_NOTIFICATION_URI : uri, getRingtoneAudioAttributes()));

    SignalDatabase.recipients().setNotificationChannel(recipient.getId(), success ? newChannelId : null);
    ensureCustomChannelConsistency();
  }","/**
   * Updates the message ringtone for a specific recipient. If that recipient has no channel, this
   * does nothing.
   *
   * This has to update the database, and therefore should be run on a background thread.
   */",67087d9d82a3a5339cc3dd6a
"public boolean isSingleClient() {
        return getActiveClients(clientState.get()) == 1;
    }","/**
     * Check if we still have one active client
     *
     * @return true if have one open client, false otherwise.
     */",67087d9d82a3a5339cc3dd6b
"public static ValueMatcher makeAlwaysFalseWithNullUnknownNumericMatcher(BaseNullableColumnValueSelector selector)
  {
    return new ValueMatcher()
    {
      @Override
      public boolean matches(boolean includeUnknown)
      {
        return includeUnknown && selector.isNull();
      }

      @Override
      public void inspectRuntimeShape(RuntimeShapeInspector inspector)
      {
        inspector.visit(""selector"", selector);
      }
    };
  }","/**
   * Create a matcher that should always return false, except when {@code includeUnknown} is set, in which case only
   * null values will be matched. This is typically used when the filter should never match any actual values, but
   * still needs to be able to report 'unknown' matches.
   */",67087d9d82a3a5339cc3dd6c
"public static void copy(String in, Writer out) throws IOException {
        Objects.requireNonNull(in, ""No input String specified"");
        Objects.requireNonNull(out, ""No Writer specified"");
        try (Writer out2 = out) {
            out2.write(in);
        }
    }","/**
     * Copy the contents of the given String to the given output Writer.
     * Closes the write when done.
     *
     * @param in  the String to copy from
     * @param out the Writer to copy to
     * @throws IOException in case of I/O errors
     */",67087d9d82a3a5339cc3dd6d
"private void markForRemoval(Node<K, V> node) {
		for (; ; ) {
			final CacheEntry<V> current = node.get();
			if (!current.isActive()) {
				return;
			}
			final CacheEntry<V> pendingRemoval = new CacheEntry<>(current.value, CacheEntryState.PENDING_REMOVAL);
			if (node.compareAndSet(current, pendingRemoval)) {
				return;
			}
		}
	}","/*
	 * Transition the node from the {@code active} state to the {@code pending removal} state,
	 * if the transition is valid.
	 */",67087d9d82a3a5339cc3dd6e
"public static ResultSet executeCsvQuery(Connection csv, String csvTableName) throws SQLException {
        ResultSet expected = csv.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE, ResultSet.CONCUR_READ_ONLY)
            .executeQuery(""SELECT * FROM "" + csvTableName);
        // trigger data loading for type inference
        expected.beforeFirst();
        return expected;
    }","/**
     * Executes a query on provided CSV connection.
     * <p>
     * The supplied table name is only used for the test identification.
     */",67087d9d82a3a5339cc3dd6f
"@Override
	public AutowireCandidateResolver cloneIfNecessary() {
		try {
			return (AutowireCandidateResolver) clone();
		}
		catch (CloneNotSupportedException ex) {
			throw new IllegalStateException(ex);
		}
	}","/**
	 * This implementation clones all instance fields through standard
	 * {@link Cloneable} support, allowing for subsequent reconfiguration
	 * of the cloned instance through a fresh {@link #setBeanFactory} call.
	 * @see #clone()
	 */",67087d9d82a3a5339cc3dd70
"public RuntimeException createError(RuntimeException exception) {
        return location.createError(exception);
    }","/**
     * Create an error with location information pointing to this node.
     */",67087d9d82a3a5339cc3dd71
"public String getId() {
        return documentId(jobId, forecastId);
    }","/**
     * Return the document ID used for indexing. As there is 1 and only 1 document
     * per forecast request, the id has no dynamic parts.
     *
     * @return id
     */",67087d9d82a3a5339cc3dd72
"public static Pair<List<Filter>, List<JoinableClause>> convertJoinsToFilters(
      final List<JoinableClause> clauses,
      final Set<String> requiredColumns,
      final int maxNumFilterValues
  )
  {
    final List<Filter> filterList = new ArrayList<>();
    final List<JoinableClause> clausesToUse = new ArrayList<>();

    // Join clauses may depend on other, earlier join clauses.
    // We track that using a Multiset, because we'll need to remove required columns one by one as we convert clauses,
    // and multiple clauses may refer to the same column.
    final Multiset<String> columnsRequiredByJoinClauses = HashMultiset.create();

    for (JoinableClause clause : clauses) {
      for (String column : clause.getCondition().getRequiredColumns()) {
        columnsRequiredByJoinClauses.add(column, 1);
      }
    }

    Set<String> rightPrefixes = clauses.stream().map(JoinableClause::getPrefix).collect(Collectors.toSet());
    boolean isRightyJoinSeen = false;
    for (JoinableClause clause : clauses) {
      // Incase we find a RIGHT/OUTER join, we shouldn't convert join conditions to left column filters for any join
      // afterwards because the values of left colmun might change to NULL after the RIGHT/OUTER join. We should only
      // consider cases where the values of the filter columns do not change after the join.
      isRightyJoinSeen = isRightyJoinSeen || clause.getJoinType().isRighty();
      if (isRightyJoinSeen) {
        clausesToUse.add(clause);
        continue;
      }
      // Remove this clause from columnsRequiredByJoinClauses. It's ok if it relies on itself.
      for (String column : clause.getCondition().getRequiredColumns()) {
        columnsRequiredByJoinClauses.remove(column, 1);
      }

      final JoinClauseToFilterConversion joinClauseToFilterConversion =
          convertJoinToFilter(
              clause,
              Sets.union(requiredColumns, columnsRequiredByJoinClauses.elementSet()),
              maxNumFilterValues,
              rightPrefixes
          );

      // add the converted filter to the filter list
      if (joinClauseToFilterConversion.getConvertedFilter() != null) {
        filterList.add(joinClauseToFilterConversion.getConvertedFilter());
      }
      // if the converted filter is partial, keep the join clause too
      if (!joinClauseToFilterConversion.isJoinClauseFullyConverted()) {
        clausesToUse.add(clause);
        // add back the required columns by this join since it wasn't converted fully
        for (String column : clause.getCondition().getRequiredColumns()) {
          columnsRequiredByJoinClauses.add(column, 1);
        }
      }
    }

    return Pair.of(filterList, clausesToUse);
  }","/**
   * Converts any join clauses to filters that can be converted, and returns the rest as-is.
   * <p>
   * See {@link #convertJoinToFilter} for details on the logic.
   */",67087d9d82a3a5339cc3dd73
"public void rotateAround (Vector3 point, Vector3 axis, float angle) {
		tmpVec.set(point);
		tmpVec.sub(position);
		translate(tmpVec);
		rotate(axis, angle);
		tmpVec.rotate(axis, angle);
		translate(-tmpVec.x, -tmpVec.y, -tmpVec.z);
	}","/** Rotates the direction and up vector of this camera by the given angle around the given axis, with the axis attached to
	 * given point. The direction and up vector will not be orthogonalized.
	 * 
	 * @param point the point to attach the axis to
	 * @param axis the axis to rotate around
	 * @param angle the angle, in degrees */",67087d9d82a3a5339cc3dd74
"public void destroyFixture (Fixture fixture) {
		this.world.destroyFixture(this, fixture);
		fixture.setUserData(null);
		this.world.fixtures.remove(fixture.addr);
		this.fixtures.removeValue(fixture, true);
		this.world.freeFixtures.free(fixture);
	}","/** Destroy a fixture. This removes the fixture from the broad-phase and destroys all contacts associated with this fixture.
	 * This will automatically adjust the mass of the body if the body is dynamic and the fixture has positive density. All
	 * fixtures attached to a body are implicitly destroyed when the body is destroyed.
	 * @param fixture the fixture to be removed.
	 * @warning This function is locked during callbacks. */",67087d9d82a3a5339cc3dd75
"public static void writeLongLE(long val, byte[] arr, int offset) {
        LITTLE_ENDIAN_LONG.set(arr, offset, val);
    }","/**
     * Converts a long to a byte array in little endian format.
     *
     * @param val The long to convert to a byte array
     * @param arr The byte array to write the long value in little endian layout
     * @param offset The offset where in the array to write to
     */",67087d9d82a3a5339cc3dd76
"public SELF withConfiguration(Configurations configurations) {
		Assert.notNull(configurations, ""Configurations must not be null"");
		return newInstance(this.runnerConfiguration.withConfiguration(configurations));
	}","/**
	 * Register the specified configuration classes with the {@link ApplicationContext}.
	 * @param configurations the configurations to add
	 * @return a new instance with the updated configuration
	 */",67087d9d82a3a5339cc3dd77
"public static ArrayList<MockBucket> generateHistogram(int interval, int size, double gapProbability, double runProbability) {
        ArrayList<MockBucket> values = new ArrayList<>(size);

        boolean lastWasGap = false;
        boolean emptyHisto = true;

        for (int i = 0; i < size; i++) {
            MockBucket bucket = new MockBucket();
            if (randomDouble() < gapProbability) {
                // start a gap
                bucket.count = 0;
                bucket.docValues = new double[0];

                lastWasGap = true;

            } else if (lastWasGap && randomDouble() < runProbability) {
                // add to the existing gap
                bucket.count = 0;
                bucket.docValues = new double[0];

                lastWasGap = true;
            } else {
                bucket.count = randomIntBetween(1, 50);
                bucket.docValues = new double[bucket.count];
                for (int j = 0; j < bucket.count; j++) {
                    bucket.docValues[j] = randomDouble() * randomIntBetween(-20, 20);
                }
                lastWasGap = false;
                emptyHisto = false;
            }

            bucket.key = i * interval;
            values.add(bucket);
        }

        if (emptyHisto) {
            int idx = randomIntBetween(0, values.size() - 1);
            MockBucket bucket = values.get(idx);
            bucket.count = randomIntBetween(1, 50);
            bucket.docValues = new double[bucket.count];
            for (int j = 0; j < bucket.count; j++) {
                bucket.docValues[j] = randomDouble() * randomIntBetween(-20, 20);
            }
            values.set(idx, bucket);
        }

        return values;
    }","/**
     * Generates a mock histogram to use for testing.  Each MockBucket holds a doc count, key and document values
     * which can later be used to compute metrics and compare against the real aggregation results.  Gappiness can be
     * controlled via parameters
     *
     * @param interval          Interval between bucket keys
     * @param size              Size of mock histogram to generate (in buckets)
     * @param gapProbability    Probability of generating an empty bucket. 0.0-1.0 inclusive
     * @param runProbability    Probability of extending a gap once one has been created.  0.0-1.0 inclusive
     */",67087d9d82a3a5339cc3dd78
"public Map<String, ?> getDefaultUriVariables() {
		if (this.defaultUriVariables != null) {
			return Collections.unmodifiableMap(this.defaultUriVariables);
		}
		else {
			return Collections.emptyMap();
		}
	}","/**
	 * Return the configured default URI variable values.
	 */",67087d9d82a3a5339cc3dd79
"public void setLocation(@Nullable URI location) {
		setOrRemove(LOCATION, (location != null ? location.toASCIIString() : null));
	}","/**
	 * Set the (new) location of a resource,
	 * as specified by the {@code Location} header.
	 */",67087d9d82a3a5339cc3dd7a
"public void deleteDatafeedConfig(String datafeedId, ActionListener<DeleteResponse> actionListener) {
        DeleteRequest request = new DeleteRequest(MlConfigIndex.indexName(), DatafeedConfig.documentId(datafeedId));
        request.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE);
        executeAsyncWithOrigin(
            client,
            ML_ORIGIN,
            TransportDeleteAction.TYPE,
            request,
            actionListener.delegateFailure((l, deleteResponse) -> {
                if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) {
                    l.onFailure(ExceptionsHelper.missingDatafeedException(datafeedId));
                    return;
                }
                assert deleteResponse.getResult() == DocWriteResponse.Result.DELETED;
                l.onResponse(deleteResponse);
            })
        );
    }","/**
     * Delete the datafeed config document
     *
     * @param datafeedId The datafeed id
     * @param actionListener Deleted datafeed listener
     */",67087d9d82a3a5339cc3dd7b
"protected boolean isBinderMethodApplicable(HandlerMethod initBinderMethod, WebDataBinder dataBinder) {
		InitBinder ann = initBinderMethod.getMethodAnnotation(InitBinder.class);
		Assert.state(ann != null, ""No InitBinder annotation"");
		String[] names = ann.value();
		return (ObjectUtils.isEmpty(names) || ObjectUtils.containsElement(names, dataBinder.getObjectName()));
	}","/**
	 * Determine whether the given {@code @InitBinder} method should be used
	 * to initialize the given {@link WebDataBinder} instance. By default we
	 * check the specified attribute names in the annotation value, if any.
	 */",67087d9d82a3a5339cc3dd7c
"@SuppressWarnings(""unchecked"")
    public static <E> List<E> appendToCopy(Collection<E> collection, E element) {
        final int size = collection.size() + 1;
        final E[] array = collection.toArray((E[]) new Object[size]);
        array[size - 1] = element;
        return Collections.unmodifiableList(Arrays.asList(array));
    }","/**
     * Creates a copy of the given collection with the given element appended.
     *
     * @param collection collection to copy
     * @param element    element to append
     */",67087d9d82a3a5339cc3dd7d
"@Deprecated
    public static <T> T releaseLater(T msg, int decrement) {
        ObjectUtil.checkPositive(decrement, ""decrement"");
        if (msg instanceof ReferenceCounted) {
            ThreadDeathWatcher.watch(Thread.currentThread(), new ReleasingTask((ReferenceCounted) msg, decrement));
        }
        return msg;
    }","/**
     * Schedules the specified object to be released when the caller thread terminates. Note that this operation is
     * intended to simplify reference counting of ephemeral objects during unit tests. Do not use it beyond the
     * intended use case.
     *
     * @deprecated this may introduce a lot of memory usage so it is generally preferable to manually release objects.
     */",67087d9d82a3a5339cc3dd7e
"@Override
        public long get(Object inputId, Group group) {
            assert readyForUse;
            return binarySearch(inputId, group.id(), lookup);
        }","/**
         * Returns the data index (i.e. node id) if found, or {@code -1} if not found.
         */",67087d9d82a3a5339cc3dd7f
"public RowSignature resultArraySignature(QueryType query)
  {
    throw new UOE(""Query type '%s' does not support returning results as arrays"", query.getType());
  }","/**
   * Returns a {@link RowSignature} for the arrays returned by {@link #resultsAsArrays}. The returned signature will
   * be the same length as each array returned by {@link #resultsAsArrays}.
   *
   * @param query same query passed to {@link #resultsAsArrays}
   * @return row signature
   * @throws UnsupportedOperationException if this query type does not support returning results as arrays
   */",67087d9d82a3a5339cc3dd80
"static public Annotation[] getDeclaredAnnotations (Class c) {
		java.lang.annotation.Annotation[] annotations = c.getDeclaredAnnotations();
		Annotation[] result = new Annotation[annotations.length];
		for (int i = 0; i < annotations.length; i++) {
			result[i] = new Annotation(annotations[i]);
		}
		return result;
	}","/** Returns an array of {@link Annotation} objects reflecting all annotations declared by the supplied class, or an empty array
	 * if there are none. Does not include inherited annotations. */",67087d9d82a3a5339cc3dd81
"public void prepareForImmediateShutdown() {
        Iterator<Holder> iter = runningDatafeedsOnThisNode.values().iterator();
        while (iter.hasNext()) {
            iter.next().setNodeIsShuttingDown();
            iter.remove();
        }
    }","/**
     * This is used before the JVM is killed.  It differs from {@link #stopAllDatafeedsOnThisNode} in that it
     * leaves the datafeed tasks in the ""started"" state, so that they get restarted on a different node.  It
     * differs from {@link #vacateAllDatafeedsOnThisNode} in that it does not proactively relocate the persistent
     * tasks.  With this method the assumption is that the JVM is going to be killed almost immediately, whereas
     * {@link #vacateAllDatafeedsOnThisNode} is used with more graceful shutdowns.
     */",67087d9d82a3a5339cc3dd82
"protected boolean receiveAndExecute(
			Object invoker, @Nullable Session session, @Nullable MessageConsumer consumer)
			throws JMSException {

		if (this.transactionManager != null) {
			// Execute receive within transaction.
			TransactionStatus status = this.transactionManager.getTransaction(this.transactionDefinition);
			boolean messageReceived;
			try {
				messageReceived = doReceiveAndExecute(invoker, session, consumer, status);
			}
			catch (JMSException | RuntimeException | Error ex) {
				rollbackOnException(this.transactionManager, status, ex);
				throw ex;
			}
			try {
				this.transactionManager.commit(status);
			}
			catch (TransactionException ex) {
				// Propagate transaction system exceptions as infrastructure problems.
				throw ex;
			}
			catch (RuntimeException ex) {
				// Typically a late persistence exception from a listener-used resource
				// -> handle it as listener exception, not as an infrastructure problem.
				// E.g. a database locking failure should not lead to listener shutdown.
				handleListenerException(ex);
			}
			return messageReceived;
		}

		else {
			// Execute receive outside of transaction.
			return doReceiveAndExecute(invoker, session, consumer, null);
		}
	}","/**
	 * Execute the listener for a message received from the given consumer,
	 * wrapping the entire operation in an external transaction if demanded.
	 * @param session the JMS Session to work on
	 * @param consumer the MessageConsumer to work on
	 * @return whether a message has been received
	 * @throws JMSException if thrown by JMS methods
	 * @see #doReceiveAndExecute
	 */",67087d9d82a3a5339cc3dd83
"void validateApiKeyCredentials(
        String docId,
        ApiKeyDoc apiKeyDoc,
        ApiKeyCredentials credentials,
        Clock clock,
        ActionListener<AuthenticationResult<User>> listener
    ) {
        if (""api_key"".equals(apiKeyDoc.docType) == false) {
            listener.onResponse(
                AuthenticationResult.unsuccessful(""document ["" + docId + ""] is ["" + apiKeyDoc.docType + ""] not an api key"", null)
            );
        } else if (apiKeyDoc.invalidated == null) {
            listener.onResponse(AuthenticationResult.unsuccessful(""api key document is missing invalidated field"", null));
        } else if (apiKeyDoc.invalidated) {
            if (apiKeyAuthCache != null) {
                apiKeyAuthCache.invalidate(docId);
            }
            listener.onResponse(AuthenticationResult.unsuccessful(""api key ["" + credentials.getId() + ""] has been invalidated"", null));
        } else {
            if (apiKeyDoc.hash == null) {
                throw new IllegalStateException(""api key hash is missing"");
            }

            if (apiKeyAuthCache != null) {
                final AtomicBoolean valueAlreadyInCache = new AtomicBoolean(true);
                final ListenableFuture<CachedApiKeyHashResult> listenableCacheEntry;
                try {
                    listenableCacheEntry = apiKeyAuthCache.computeIfAbsent(credentials.getId(), k -> {
                        valueAlreadyInCache.set(false);
                        return new ListenableFuture<>();
                    });
                } catch (ExecutionException e) {
                    listener.onFailure(e);
                    return;
                }

                if (valueAlreadyInCache.get()) {
                    listenableCacheEntry.addListener(ActionListener.wrap(result -> {
                        if (result.success) {
                            if (result.verify(credentials.getKey())) {
                                // move on
                                validateApiKeyTypeAndExpiration(apiKeyDoc, credentials, clock, listener);
                            } else {
                                listener.onResponse(
                                    AuthenticationResult.unsuccessful(""invalid credentials for API key ["" + credentials.getId() + ""]"", null)
                                );
                            }
                        } else if (result.verify(credentials.getKey())) { // same key, pass the same result
                            listener.onResponse(
                                AuthenticationResult.unsuccessful(""invalid credentials for API key ["" + credentials.getId() + ""]"", null)
                            );
                        } else {
                            apiKeyAuthCache.invalidate(credentials.getId(), listenableCacheEntry);
                            validateApiKeyCredentials(docId, apiKeyDoc, credentials, clock, listener);
                        }
                    }, listener::onFailure), threadPool.generic(), threadPool.getThreadContext());
                } else {
                    verifyKeyAgainstHash(apiKeyDoc.hash, credentials, ActionListener.wrap(verified -> {
                        listenableCacheEntry.onResponse(new CachedApiKeyHashResult(verified, credentials.getKey()));
                        if (verified) {
                            // move on
                            validateApiKeyTypeAndExpiration(apiKeyDoc, credentials, clock, listener);
                        } else {
                            listener.onResponse(
                                AuthenticationResult.unsuccessful(""invalid credentials for API key ["" + credentials.getId() + ""]"", null)
                            );
                        }
                    }, listener::onFailure));
                }
            } else {
                verifyKeyAgainstHash(apiKeyDoc.hash, credentials, ActionListener.wrap(verified -> {
                    if (verified) {
                        // move on
                        validateApiKeyTypeAndExpiration(apiKeyDoc, credentials, clock, listener);
                    } else {
                        listener.onResponse(
                            AuthenticationResult.unsuccessful(""invalid credentials for API key ["" + credentials.getId() + ""]"", null)
                        );
                    }
                }, listener::onFailure));
            }
        }
    }","/**
     * Validates the ApiKey using the source map
     * @param docId the identifier of the document that was retrieved from the security index
     * @param apiKeyDoc the partially deserialized API key document
     * @param credentials the credentials provided by the user
     * @param listener the listener to notify after verification
     */",67087d9d82a3a5339cc3dd84
"public AddressResolver<InetSocketAddress> asAddressResolver() {
        AddressResolver<InetSocketAddress> result = addressResolver;
        if (result == null) {
            synchronized (this) {
                result = addressResolver;
                if (result == null) {
                    addressResolver = result = new InetSocketAddressResolver(executor(), this);
                }
            }
        }
        return result;
    }","/**
     * Return a {@link AddressResolver} that will use this name resolver underneath.
     * It's cached internally, so the same instance is always returned.
     */",67087d9d82a3a5339cc3dd85
"@Override
    public void visitCall(ECall userCallNode, SemanticScope semanticScope) {
        String methodName = userCallNode.getMethodName();
        List<AExpression> userArgumentNodes = userCallNode.getArgumentNodes();
        int userArgumentsSize = userArgumentNodes.size();

        if (semanticScope.getCondition(userCallNode, Write.class)) {
            throw userCallNode.createError(
                new IllegalArgumentException(
                    ""invalid assignment: cannot assign a value to method call ["" + methodName + ""/"" + userArgumentsSize + ""]""
                )
            );
        }

        AExpression userPrefixNode = userCallNode.getPrefixNode();
        semanticScope.setCondition(userPrefixNode, Read.class);
        visit(userPrefixNode, semanticScope);
        ValueType prefixValueType = semanticScope.getDecoration(userPrefixNode, ValueType.class);
        StaticType prefixStaticType = semanticScope.getDecoration(userPrefixNode, StaticType.class);

        if (prefixValueType != null && prefixStaticType != null) {
            throw userCallNode.createError(
                new IllegalStateException(
                    Strings.format(
                        ""cannot have both value [%s] and type [%s]"",
                        prefixValueType.getValueCanonicalTypeName(),
                        prefixStaticType.getStaticCanonicalTypeName()
                    )
                )
            );
        }

        if (semanticScope.hasDecoration(userPrefixNode, PartialCanonicalTypeName.class)) {
            throw userCallNode.createError(
                new IllegalArgumentException(
                    ""cannot resolve symbol ""
                        + ""[""
                        + semanticScope.getDecoration(userPrefixNode, PartialCanonicalTypeName.class).partialCanonicalTypeName()
                        + ""]""
                )
            );
        }

        boolean dynamic = false;
        PainlessMethod method = null;

        if (prefixValueType != null) {
            Class<?> type = prefixValueType.valueType();
            PainlessLookup lookup = semanticScope.getScriptScope().getPainlessLookup();

            if (prefixValueType.valueType() == def.class) {
                dynamic = true;
            } else {
                method = lookup.lookupPainlessMethod(type, false, methodName, userArgumentsSize);

                if (method == null) {
                    PainlessClass pc = lookup.lookupPainlessClass(type);
                    dynamic = pc != null
                        && pc.annotations.containsKey(DynamicTypeAnnotation.class)
                        && lookup.lookupPainlessSubClassesMethod(type, methodName, userArgumentsSize) != null;

                    if (dynamic == false) {
                        throw userCallNode.createError(
                            new IllegalArgumentException(
                                Strings.format(
                                    ""member method [%s, %s/%d] not found"",
                                    prefixValueType.getValueCanonicalTypeName(),
                                    methodName,
                                    userArgumentsSize
                                )
                            )
                        );
                    }
                }
            }
        } else if (prefixStaticType != null) {
            method = semanticScope.getScriptScope()
                .getPainlessLookup()
                .lookupPainlessMethod(prefixStaticType.staticType(), true, methodName, userArgumentsSize);

            if (method == null) {
                throw userCallNode.createError(
                    new IllegalArgumentException(
                        Strings.format(
                            ""static method [%s, %s/%d] not found"",
                            prefixStaticType.getStaticCanonicalTypeName(),
                            methodName,
                            userArgumentsSize
                        )
                    )
                );
            }
        } else {
            throw userCallNode.createError(new IllegalStateException(""value required: instead found no value""));
        }

        Class<?> valueType;

        if (dynamic) {
            for (AExpression userArgumentNode : userArgumentNodes) {
                semanticScope.setCondition(userArgumentNode, Read.class);
                semanticScope.setCondition(userArgumentNode, Internal.class);
                checkedVisit(userArgumentNode, semanticScope);
                Class<?> argumentValueType = semanticScope.getDecoration(userArgumentNode, ValueType.class).valueType();

                if (argumentValueType == void.class) {
                    throw userCallNode.createError(
                        new IllegalArgumentException(""Argument(s) cannot be of [void] type when calling method ["" + methodName + ""]."")
                    );
                }
            }

            TargetType targetType = userCallNode.isNullSafe() ? null : semanticScope.getDecoration(userCallNode, TargetType.class);
            valueType = targetType == null || semanticScope.getCondition(userCallNode, Explicit.class)
                ? def.class
                : targetType.targetType();

            semanticScope.setCondition(userCallNode, DynamicInvocation.class);
        } else {
            Objects.requireNonNull(method);
            semanticScope.getScriptScope().markNonDeterministic(method.annotations().containsKey(NonDeterministicAnnotation.class));

            for (int argument = 0; argument < userArgumentsSize; ++argument) {
                AExpression userArgumentNode = userArgumentNodes.get(argument);

                semanticScope.setCondition(userArgumentNode, Read.class);
                semanticScope.putDecoration(userArgumentNode, new TargetType(method.typeParameters().get(argument)));
                semanticScope.setCondition(userArgumentNode, Internal.class);
                checkedVisit(userArgumentNode, semanticScope);
                decorateWithCast(userArgumentNode, semanticScope);
            }

            semanticScope.putDecoration(userCallNode, new StandardPainlessMethod(method));
            valueType = method.returnType();
        }

        if (userCallNode.isNullSafe() && valueType.isPrimitive()) {
            throw new IllegalArgumentException(""Result of null safe operator must be nullable"");
        }

        semanticScope.putDecoration(userCallNode, new ValueType(valueType));
    }","/**
     * Visits a call expression which is a method call with a qualifier (prefix).
     * Checks: type validation, method resolution
     */",67087d9d82a3a5339cc3dd86
"public String getResourceDescription() {
		return getLocation().getResource().getDescription();
	}","/**
	 * Get the description of the bean configuration source that triggered the error,
	 * as contained within this Problem's Location object.
	 * @see #getLocation()
	 */",67087d9d82a3a5339cc3dd87
