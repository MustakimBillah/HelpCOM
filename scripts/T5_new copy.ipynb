{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dceeb593-70e9-4bf7-b6dc-d527cb676c17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/anaconda3/lib/python3.11/site-packages (from rouge-score) (2.0.0)\n",
      "Requirement already satisfied: nltk in /usr/local/anaconda3/lib/python3.11/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/anaconda3/lib/python3.11/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (8.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/anaconda3/lib/python3.11/site-packages (from nltk->rouge-score) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /student/mjr175/.local/lib/python3.11/site-packages (from nltk->rouge-score) (4.66.2)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=189c965516eebf3968644e8f09694a4ae699ed5c64617ded324c0f9e2225be2e\n",
      "  Stored in directory: /student/mjr175/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6a5665-8db1-4b55-aecf-45e77a4de0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 11:59:00.113512: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-08 11:59:00.160413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-08 11:59:00.160466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-08 11:59:00.162293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-08 11:59:00.172515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/student/mjr175/commentGeneration/Train_4_Lang/Java1000Train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(len(df) * 0.8)  # 80% of the data for training\n",
    "val_size = len(df) - train_size  # Remaining 20% for validation\n",
    "train_dataset, val_dataset = random_split(df, [train_size, val_size])\n",
    "train_df = pd.DataFrame(train_dataset.dataset)\n",
    "val_df = pd.DataFrame(val_dataset.dataset)\n",
    "\n",
    "# Define T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e97876-1097-4b0b-b3bf-693480d748f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "071163b0-8e58-4a27-a5ab-a0e1f612a3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, Batch loss: 0.46594423055648804\n",
      "epoch 1, Batch loss: 0.44376102089881897\n",
      "epoch 1, Batch loss: 0.47994065284729004\n",
      "epoch 1, Batch loss: 0.6689395904541016\n",
      "epoch 1, Batch loss: 0.5314613580703735\n",
      "epoch 1, Batch loss: 0.36245205998420715\n",
      "epoch 1, Batch loss: 0.4528369605541229\n",
      "epoch 1, Batch loss: 0.5547585487365723\n",
      "epoch 1, Batch loss: 0.4454065263271332\n",
      "epoch 1, Batch loss: 0.3706100881099701\n",
      "epoch 1, Batch loss: 0.4585029184818268\n",
      "epoch 1, Batch loss: 0.3009800910949707\n",
      "epoch 1, Batch loss: 0.5574549436569214\n",
      "epoch 1, Batch loss: 0.8279182314872742\n",
      "epoch 1, Batch loss: 0.5838012099266052\n",
      "epoch 1, Batch loss: 0.3659141957759857\n",
      "epoch 1, Batch loss: 0.23990868031978607\n",
      "epoch 1, Batch loss: 0.40476977825164795\n",
      "epoch 1, Batch loss: 0.803613007068634\n",
      "epoch 1, Batch loss: 0.47445544600486755\n",
      "epoch 1, Batch loss: 0.3535246253013611\n",
      "epoch 1, Batch loss: 0.37251442670822144\n",
      "epoch 1, Batch loss: 0.3674231171607971\n",
      "epoch 1, Batch loss: 0.7227097153663635\n",
      "epoch 1, Batch loss: 0.44418150186538696\n",
      "epoch 1, Batch loss: 0.3280882239341736\n",
      "epoch 1, Batch loss: 0.6039232611656189\n",
      "epoch 1, Batch loss: 0.5538371205329895\n",
      "epoch 1, Batch loss: 0.5666691660881042\n",
      "epoch 1, Batch loss: 0.3453274667263031\n",
      "epoch 1, Batch loss: 0.4999091327190399\n",
      "epoch 1, Batch loss: 0.34474727511405945\n",
      "epoch 1, Batch loss: 0.39007052779197693\n",
      "epoch 1, Batch loss: 0.7559540867805481\n",
      "epoch 1, Batch loss: 0.3674218952655792\n",
      "epoch 1, Batch loss: 0.39736586809158325\n",
      "epoch 1, Batch loss: 0.3375087082386017\n",
      "epoch 1, Batch loss: 0.4914168119430542\n",
      "epoch 1, Batch loss: 0.30503496527671814\n",
      "epoch 1, Batch loss: 0.39294639229774475\n",
      "epoch 1, Batch loss: 0.4410720467567444\n",
      "epoch 1, Batch loss: 0.49109676480293274\n",
      "epoch 1, Batch loss: 0.5391210913658142\n",
      "epoch 1, Batch loss: 0.5236042737960815\n",
      "epoch 1, Batch loss: 0.6976470351219177\n",
      "epoch 1, Batch loss: 0.42086490988731384\n",
      "epoch 1, Batch loss: 0.37987104058265686\n",
      "epoch 1, Batch loss: 0.6395686864852905\n",
      "epoch 1, Batch loss: 0.4436803162097931\n",
      "epoch 1, Batch loss: 0.4076763093471527\n",
      "epoch 1, Batch loss: 0.42744407057762146\n",
      "epoch 1, Batch loss: 0.36877676844596863\n",
      "epoch 1, Batch loss: 0.46781155467033386\n",
      "epoch 1, Batch loss: 0.5407441258430481\n",
      "epoch 1, Batch loss: 0.3081167936325073\n",
      "epoch 1, Batch loss: 0.37227845191955566\n",
      "epoch 1, Batch loss: 0.7482852935791016\n",
      "epoch 1, Batch loss: 0.327175498008728\n",
      "epoch 1, Batch loss: 0.5470377206802368\n",
      "epoch 1, Batch loss: 0.842904806137085\n",
      "epoch 1, Batch loss: 0.38923174142837524\n",
      "epoch 1, Batch loss: 0.3479298949241638\n",
      "epoch 1, Batch loss: 0.33644741773605347\n",
      "epoch 1, Batch loss: 0.5098690390586853\n",
      "epoch 1, Batch loss: 0.5179944038391113\n",
      "epoch 1, Batch loss: 0.40438777208328247\n",
      "epoch 1, Batch loss: 0.48399269580841064\n",
      "epoch 1, Batch loss: 0.6536562442779541\n",
      "epoch 1, Batch loss: 0.47360220551490784\n",
      "epoch 1, Batch loss: 0.5746334195137024\n",
      "epoch 1, Batch loss: 0.31784653663635254\n",
      "epoch 1, Batch loss: 0.5250521302223206\n",
      "epoch 1, Batch loss: 0.44655829668045044\n",
      "epoch 1, Batch loss: 0.5733771920204163\n",
      "epoch 1, Batch loss: 0.3786424994468689\n",
      "epoch 1, Batch loss: 0.5020117163658142\n",
      "epoch 1, Batch loss: 0.3178456723690033\n",
      "epoch 1, Batch loss: 0.4529157280921936\n",
      "epoch 1, Batch loss: 0.38664788007736206\n",
      "epoch 1, Batch loss: 0.46860888600349426\n",
      "epoch 1, Batch loss: 0.4193703234195709\n",
      "epoch 1, Batch loss: 0.5898355841636658\n",
      "epoch 1, Batch loss: 0.3650680184364319\n",
      "epoch 1, Batch loss: 0.43708595633506775\n",
      "epoch 1, Batch loss: 0.4976968765258789\n",
      "epoch 1, Batch loss: 0.5528451204299927\n",
      "epoch 1, Batch loss: 0.4942426383495331\n",
      "epoch 1, Batch loss: 0.6879467964172363\n",
      "epoch 1, Batch loss: 0.48730137944221497\n",
      "epoch 1, Batch loss: 0.4421250820159912\n",
      "epoch 1, Batch loss: 0.4777383804321289\n",
      "epoch 1, Batch loss: 0.5175478458404541\n",
      "epoch 1, Batch loss: 0.25531870126724243\n",
      "epoch 1, Batch loss: 0.4843999445438385\n",
      "epoch 1, Batch loss: 0.5331214070320129\n",
      "epoch 1, Batch loss: 0.3140261769294739\n",
      "epoch 1, Batch loss: 0.4975140690803528\n",
      "epoch 1, Batch loss: 0.6494425535202026\n",
      "epoch 1, Batch loss: 0.47036170959472656\n",
      "epoch 1, Batch loss: 0.5371816158294678\n",
      "epoch 1, Batch loss: 0.6241018772125244\n",
      "epoch 1, Batch loss: 0.5339362621307373\n",
      "epoch 1, Batch loss: 0.32605165243148804\n",
      "epoch 1, Batch loss: 0.2243259698152542\n",
      "epoch 1, Batch loss: 0.38385072350502014\n",
      "epoch 1, Batch loss: 0.408830851316452\n",
      "epoch 1, Batch loss: 0.464769184589386\n",
      "epoch 1, Batch loss: 0.3465752601623535\n",
      "epoch 1, Batch loss: 0.3912486433982849\n",
      "epoch 1, Batch loss: 0.4170583188533783\n",
      "epoch 1, Batch loss: 0.4202680289745331\n",
      "epoch 1, Batch loss: 0.40363696217536926\n",
      "epoch 1, Batch loss: 0.24448928236961365\n",
      "epoch 1, Batch loss: 0.5695656538009644\n",
      "epoch 1, Batch loss: 0.7923970222473145\n",
      "epoch 1, Batch loss: 0.3749241530895233\n",
      "epoch 1, Batch loss: 0.7910665273666382\n",
      "epoch 1, Batch loss: 0.4371408522129059\n",
      "epoch 1, Batch loss: 0.37588098645210266\n",
      "epoch 1, Batch loss: 0.4178900122642517\n",
      "epoch 1, Batch loss: 0.43776461482048035\n",
      "epoch 1, Batch loss: 0.2845992147922516\n",
      "epoch 1, Batch loss: 0.3621325194835663\n",
      "epoch 1, Batch loss: 0.5533888339996338\n",
      "epoch 1, Batch loss: 0.38024529814720154\n",
      "epoch 2, Batch loss: 0.3405263125896454\n",
      "epoch 2, Batch loss: 0.5193086266517639\n",
      "epoch 2, Batch loss: 0.6079193949699402\n",
      "epoch 2, Batch loss: 0.8514615297317505\n",
      "epoch 2, Batch loss: 0.7173758745193481\n",
      "epoch 2, Batch loss: 0.5483148097991943\n",
      "epoch 2, Batch loss: 0.41955360770225525\n",
      "epoch 2, Batch loss: 0.25000855326652527\n",
      "epoch 2, Batch loss: 0.5122900605201721\n",
      "epoch 2, Batch loss: 0.46724557876586914\n",
      "epoch 2, Batch loss: 0.3185543715953827\n",
      "epoch 2, Batch loss: 0.3562711775302887\n",
      "epoch 2, Batch loss: 0.29963478446006775\n",
      "epoch 2, Batch loss: 0.28313589096069336\n",
      "epoch 2, Batch loss: 0.40546914935112\n",
      "epoch 2, Batch loss: 0.49106860160827637\n",
      "epoch 2, Batch loss: 0.39784103631973267\n",
      "epoch 2, Batch loss: 0.5750271081924438\n",
      "epoch 2, Batch loss: 0.5156819224357605\n",
      "epoch 2, Batch loss: 0.37738749384880066\n",
      "epoch 2, Batch loss: 0.7573020458221436\n",
      "epoch 2, Batch loss: 0.42236918210983276\n",
      "epoch 2, Batch loss: 0.5874476432800293\n",
      "epoch 2, Batch loss: 0.33994388580322266\n",
      "epoch 2, Batch loss: 0.4069732427597046\n",
      "epoch 2, Batch loss: 0.321169376373291\n",
      "epoch 2, Batch loss: 0.6438694596290588\n",
      "epoch 2, Batch loss: 0.5285308361053467\n",
      "epoch 2, Batch loss: 0.378181517124176\n",
      "epoch 2, Batch loss: 0.39476558566093445\n",
      "epoch 2, Batch loss: 0.32827502489089966\n",
      "epoch 2, Batch loss: 0.4546653926372528\n",
      "epoch 2, Batch loss: 0.36320197582244873\n",
      "epoch 2, Batch loss: 0.4459242820739746\n",
      "epoch 2, Batch loss: 0.7074303030967712\n",
      "epoch 2, Batch loss: 0.3887726962566376\n",
      "epoch 2, Batch loss: 0.4982433319091797\n",
      "epoch 2, Batch loss: 0.30580833554267883\n",
      "epoch 2, Batch loss: 0.30056849122047424\n",
      "epoch 2, Batch loss: 0.48010098934173584\n",
      "epoch 2, Batch loss: 0.4825226068496704\n",
      "epoch 2, Batch loss: 0.5822227001190186\n",
      "epoch 2, Batch loss: 0.42420694231987\n",
      "epoch 2, Batch loss: 0.65449059009552\n",
      "epoch 2, Batch loss: 0.3824601173400879\n",
      "epoch 2, Batch loss: 0.6476223468780518\n",
      "epoch 2, Batch loss: 0.3577650487422943\n",
      "epoch 2, Batch loss: 0.40986135601997375\n",
      "epoch 2, Batch loss: 0.529032289981842\n",
      "epoch 2, Batch loss: 0.5676918625831604\n",
      "epoch 2, Batch loss: 0.43943339586257935\n",
      "epoch 2, Batch loss: 0.45538419485092163\n",
      "epoch 2, Batch loss: 0.3745451271533966\n",
      "epoch 2, Batch loss: 0.3429831862449646\n",
      "epoch 2, Batch loss: 0.4738558828830719\n",
      "epoch 2, Batch loss: 0.874984860420227\n",
      "epoch 2, Batch loss: 0.3306967616081238\n",
      "epoch 2, Batch loss: 0.32354477047920227\n",
      "epoch 2, Batch loss: 0.39768674969673157\n",
      "epoch 2, Batch loss: 0.5731155872344971\n",
      "epoch 2, Batch loss: 0.2234363704919815\n",
      "epoch 2, Batch loss: 0.5073053240776062\n",
      "epoch 2, Batch loss: 0.23646463453769684\n",
      "epoch 2, Batch loss: 0.39331334829330444\n",
      "epoch 2, Batch loss: 0.3333371877670288\n",
      "epoch 2, Batch loss: 0.4675939381122589\n",
      "epoch 2, Batch loss: 0.38203752040863037\n",
      "epoch 2, Batch loss: 0.3871786296367645\n",
      "epoch 2, Batch loss: 0.4096519947052002\n",
      "epoch 2, Batch loss: 0.4840235114097595\n",
      "epoch 2, Batch loss: 0.3363514542579651\n",
      "epoch 2, Batch loss: 0.24821071326732635\n",
      "epoch 2, Batch loss: 0.8757467865943909\n",
      "epoch 2, Batch loss: 0.5607290863990784\n",
      "epoch 2, Batch loss: 0.4067915081977844\n",
      "epoch 2, Batch loss: 0.5460413694381714\n",
      "epoch 2, Batch loss: 0.39130789041519165\n",
      "epoch 2, Batch loss: 0.3130549192428589\n",
      "epoch 2, Batch loss: 0.37470337748527527\n",
      "epoch 2, Batch loss: 0.7412506341934204\n",
      "epoch 2, Batch loss: 0.5144651532173157\n",
      "epoch 2, Batch loss: 0.4045197367668152\n",
      "epoch 2, Batch loss: 0.6695373058319092\n",
      "epoch 2, Batch loss: 0.36601054668426514\n",
      "epoch 2, Batch loss: 0.5070294141769409\n",
      "epoch 2, Batch loss: 0.5798222422599792\n",
      "epoch 2, Batch loss: 0.5573649406433105\n",
      "epoch 2, Batch loss: 0.5594223737716675\n",
      "epoch 2, Batch loss: 0.6559123396873474\n",
      "epoch 2, Batch loss: 0.4378659129142761\n",
      "epoch 2, Batch loss: 0.3252495527267456\n",
      "epoch 2, Batch loss: 0.41027477383613586\n",
      "epoch 2, Batch loss: 0.30834245681762695\n",
      "epoch 2, Batch loss: 0.3411971926689148\n",
      "epoch 2, Batch loss: 0.2768229842185974\n",
      "epoch 2, Batch loss: 0.465557724237442\n",
      "epoch 2, Batch loss: 0.5002458691596985\n",
      "epoch 2, Batch loss: 0.603750467300415\n",
      "epoch 2, Batch loss: 0.6099053621292114\n",
      "epoch 2, Batch loss: 0.36976513266563416\n",
      "epoch 2, Batch loss: 0.550643801689148\n",
      "epoch 2, Batch loss: 0.5706886649131775\n",
      "epoch 2, Batch loss: 0.32990309596061707\n",
      "epoch 2, Batch loss: 0.32765311002731323\n",
      "epoch 2, Batch loss: 0.37028536200523376\n",
      "epoch 2, Batch loss: 0.3552229702472687\n",
      "epoch 2, Batch loss: 0.40745267271995544\n",
      "epoch 2, Batch loss: 0.3645135462284088\n",
      "epoch 2, Batch loss: 0.42934638261795044\n",
      "epoch 2, Batch loss: 0.4924171268939972\n",
      "epoch 2, Batch loss: 0.6694650053977966\n",
      "epoch 2, Batch loss: 0.33495447039604187\n",
      "epoch 2, Batch loss: 0.45897266268730164\n",
      "epoch 2, Batch loss: 0.3575398921966553\n",
      "epoch 2, Batch loss: 0.5676889419555664\n",
      "epoch 2, Batch loss: 0.46624645590782166\n",
      "epoch 2, Batch loss: 0.4443156123161316\n",
      "epoch 2, Batch loss: 0.24580204486846924\n",
      "epoch 2, Batch loss: 0.27564460039138794\n",
      "epoch 2, Batch loss: 0.5670082569122314\n",
      "epoch 2, Batch loss: 0.47533118724823\n",
      "epoch 2, Batch loss: 0.3191559314727783\n",
      "epoch 2, Batch loss: 0.3905004858970642\n",
      "epoch 2, Batch loss: 0.6783434152603149\n",
      "epoch 2, Batch loss: 0.3008098602294922\n",
      "epoch 3, Batch loss: 0.3549463450908661\n",
      "epoch 3, Batch loss: 0.6755404472351074\n",
      "epoch 3, Batch loss: 0.3344598710536957\n",
      "epoch 3, Batch loss: 0.4768882393836975\n",
      "epoch 3, Batch loss: 0.3804279863834381\n",
      "epoch 3, Batch loss: 0.48691490292549133\n",
      "epoch 3, Batch loss: 0.44112637639045715\n",
      "epoch 3, Batch loss: 0.331595242023468\n",
      "epoch 3, Batch loss: 0.25575780868530273\n",
      "epoch 3, Batch loss: 0.40689554810523987\n",
      "epoch 3, Batch loss: 0.5241756439208984\n",
      "epoch 3, Batch loss: 0.2642981708049774\n",
      "epoch 3, Batch loss: 0.42585161328315735\n",
      "epoch 3, Batch loss: 0.565520167350769\n",
      "epoch 3, Batch loss: 0.2746308147907257\n",
      "epoch 3, Batch loss: 0.307522714138031\n",
      "epoch 3, Batch loss: 0.5835661888122559\n",
      "epoch 3, Batch loss: 0.46536582708358765\n",
      "epoch 3, Batch loss: 0.4460992217063904\n",
      "epoch 3, Batch loss: 0.39075925946235657\n",
      "epoch 3, Batch loss: 0.35025444626808167\n",
      "epoch 3, Batch loss: 0.5269641876220703\n",
      "epoch 3, Batch loss: 0.3773483335971832\n",
      "epoch 3, Batch loss: 0.33732566237449646\n",
      "epoch 3, Batch loss: 0.5285061597824097\n",
      "epoch 3, Batch loss: 0.41033482551574707\n",
      "epoch 3, Batch loss: 0.6120328307151794\n",
      "epoch 3, Batch loss: 0.624840497970581\n",
      "epoch 3, Batch loss: 0.41642919182777405\n",
      "epoch 3, Batch loss: 0.6209173798561096\n",
      "epoch 3, Batch loss: 0.6527653336524963\n",
      "epoch 3, Batch loss: 0.30348536372184753\n",
      "epoch 3, Batch loss: 0.31576475501060486\n",
      "epoch 3, Batch loss: 0.7109924554824829\n",
      "epoch 3, Batch loss: 0.35378092527389526\n",
      "epoch 3, Batch loss: 0.569829523563385\n",
      "epoch 3, Batch loss: 0.7225964665412903\n",
      "epoch 3, Batch loss: 0.6712518334388733\n",
      "epoch 3, Batch loss: 0.44415393471717834\n",
      "epoch 3, Batch loss: 0.5546610355377197\n",
      "epoch 3, Batch loss: 0.2712731957435608\n",
      "epoch 3, Batch loss: 0.35433876514434814\n",
      "epoch 3, Batch loss: 0.3964605927467346\n",
      "epoch 3, Batch loss: 0.4381944239139557\n",
      "epoch 3, Batch loss: 0.5243791341781616\n",
      "epoch 3, Batch loss: 0.5550829172134399\n",
      "epoch 3, Batch loss: 0.7993931174278259\n",
      "epoch 3, Batch loss: 0.5292319655418396\n",
      "epoch 3, Batch loss: 0.633416473865509\n",
      "epoch 3, Batch loss: 0.4449405372142792\n",
      "epoch 3, Batch loss: 0.46023982763290405\n",
      "epoch 3, Batch loss: 0.27531638741493225\n",
      "epoch 3, Batch loss: 0.31713998317718506\n",
      "epoch 3, Batch loss: 0.4516177773475647\n",
      "epoch 3, Batch loss: 0.6332885026931763\n",
      "epoch 3, Batch loss: 0.44413822889328003\n",
      "epoch 3, Batch loss: 0.317561537027359\n",
      "epoch 3, Batch loss: 0.5219557881355286\n",
      "epoch 3, Batch loss: 0.46761202812194824\n",
      "epoch 3, Batch loss: 0.7399359941482544\n",
      "epoch 3, Batch loss: 0.29493746161460876\n",
      "epoch 3, Batch loss: 0.3469979465007782\n",
      "epoch 3, Batch loss: 0.4561627209186554\n",
      "epoch 3, Batch loss: 0.6428541541099548\n",
      "epoch 3, Batch loss: 0.40374451875686646\n",
      "epoch 3, Batch loss: 0.4054962396621704\n",
      "epoch 3, Batch loss: 0.6294013261795044\n",
      "epoch 3, Batch loss: 0.3074016273021698\n",
      "epoch 3, Batch loss: 0.3477497100830078\n",
      "epoch 3, Batch loss: 0.4389875829219818\n",
      "epoch 3, Batch loss: 0.3568577468395233\n",
      "epoch 3, Batch loss: 0.34511420130729675\n",
      "epoch 3, Batch loss: 0.4206380844116211\n",
      "epoch 3, Batch loss: 0.3624284565448761\n",
      "epoch 3, Batch loss: 0.33387821912765503\n",
      "epoch 3, Batch loss: 0.38028594851493835\n",
      "epoch 3, Batch loss: 0.5741062164306641\n",
      "epoch 3, Batch loss: 0.5231386423110962\n",
      "epoch 3, Batch loss: 0.3932255804538727\n",
      "epoch 3, Batch loss: 0.45425844192504883\n",
      "epoch 3, Batch loss: 0.46207669377326965\n",
      "epoch 3, Batch loss: 0.37822380661964417\n",
      "epoch 3, Batch loss: 0.4378114342689514\n",
      "epoch 3, Batch loss: 0.4907621443271637\n",
      "epoch 3, Batch loss: 0.22481834888458252\n",
      "epoch 3, Batch loss: 0.3668448030948639\n",
      "epoch 3, Batch loss: 0.4278784990310669\n",
      "epoch 3, Batch loss: 0.4879261553287506\n",
      "epoch 3, Batch loss: 0.46048200130462646\n",
      "epoch 3, Batch loss: 0.5954636335372925\n",
      "epoch 3, Batch loss: 0.37756919860839844\n",
      "epoch 3, Batch loss: 0.3718291223049164\n",
      "epoch 3, Batch loss: 0.23313133418560028\n",
      "epoch 3, Batch loss: 0.22407478094100952\n",
      "epoch 3, Batch loss: 0.2754974663257599\n",
      "epoch 3, Batch loss: 0.36605340242385864\n",
      "epoch 3, Batch loss: 0.4214450418949127\n",
      "epoch 3, Batch loss: 0.40038278698921204\n",
      "epoch 3, Batch loss: 0.562074601650238\n",
      "epoch 3, Batch loss: 0.6872616410255432\n",
      "epoch 3, Batch loss: 0.5059832334518433\n",
      "epoch 3, Batch loss: 0.29373985528945923\n",
      "epoch 3, Batch loss: 0.297666072845459\n",
      "epoch 3, Batch loss: 0.40589988231658936\n",
      "epoch 3, Batch loss: 0.23639744520187378\n",
      "epoch 3, Batch loss: 0.5185724496841431\n",
      "epoch 3, Batch loss: 0.27693822979927063\n",
      "epoch 3, Batch loss: 0.44716086983680725\n",
      "epoch 3, Batch loss: 0.47768813371658325\n",
      "epoch 3, Batch loss: 0.7640624046325684\n",
      "epoch 3, Batch loss: 0.30877378582954407\n",
      "epoch 3, Batch loss: 0.3259258568286896\n",
      "epoch 3, Batch loss: 0.28468960523605347\n",
      "epoch 3, Batch loss: 0.38817712664604187\n",
      "epoch 3, Batch loss: 0.45044752955436707\n",
      "epoch 3, Batch loss: 0.36952969431877136\n",
      "epoch 3, Batch loss: 0.412331759929657\n",
      "epoch 3, Batch loss: 0.4742330312728882\n",
      "epoch 3, Batch loss: 0.5538886785507202\n",
      "epoch 3, Batch loss: 0.5438134074211121\n",
      "epoch 3, Batch loss: 0.7329846024513245\n",
      "epoch 3, Batch loss: 0.4772290289402008\n",
      "epoch 3, Batch loss: 0.28808796405792236\n",
      "epoch 3, Batch loss: 0.35667234659194946\n",
      "epoch 3, Batch loss: 0.3291837275028229\n",
      "epoch 4, Batch loss: 0.4631398618221283\n",
      "epoch 4, Batch loss: 0.4952731132507324\n",
      "epoch 4, Batch loss: 0.5187029242515564\n",
      "epoch 4, Batch loss: 0.37161552906036377\n",
      "epoch 4, Batch loss: 0.4020783305168152\n",
      "epoch 4, Batch loss: 0.310259610414505\n",
      "epoch 4, Batch loss: 0.47875434160232544\n",
      "epoch 4, Batch loss: 0.767302930355072\n",
      "epoch 4, Batch loss: 0.2862142026424408\n",
      "epoch 4, Batch loss: 0.5238860249519348\n",
      "epoch 4, Batch loss: 0.7286744117736816\n",
      "epoch 4, Batch loss: 0.5084593892097473\n",
      "epoch 4, Batch loss: 0.5092899799346924\n",
      "epoch 4, Batch loss: 0.29924097657203674\n",
      "epoch 4, Batch loss: 0.4538705050945282\n",
      "epoch 4, Batch loss: 0.4268573522567749\n",
      "epoch 4, Batch loss: 0.3876815736293793\n",
      "epoch 4, Batch loss: 0.2689295709133148\n",
      "epoch 4, Batch loss: 0.3382667005062103\n",
      "epoch 4, Batch loss: 0.240220308303833\n",
      "epoch 4, Batch loss: 0.35954707860946655\n",
      "epoch 4, Batch loss: 0.40347546339035034\n",
      "epoch 4, Batch loss: 0.4021852910518646\n",
      "epoch 4, Batch loss: 0.37220630049705505\n",
      "epoch 4, Batch loss: 0.3451714813709259\n",
      "epoch 4, Batch loss: 0.3326449692249298\n",
      "epoch 4, Batch loss: 0.4685666859149933\n",
      "epoch 4, Batch loss: 0.4066465198993683\n",
      "epoch 4, Batch loss: 0.5050683617591858\n",
      "epoch 4, Batch loss: 0.519220232963562\n",
      "epoch 4, Batch loss: 0.3768772482872009\n",
      "epoch 4, Batch loss: 0.3379961848258972\n",
      "epoch 4, Batch loss: 0.3547172248363495\n",
      "epoch 4, Batch loss: 0.3915437161922455\n",
      "epoch 4, Batch loss: 0.38382190465927124\n",
      "epoch 4, Batch loss: 0.41203099489212036\n",
      "epoch 4, Batch loss: 0.2861533463001251\n",
      "epoch 4, Batch loss: 0.6026487350463867\n",
      "epoch 4, Batch loss: 0.4026479721069336\n",
      "epoch 4, Batch loss: 0.3753296434879303\n",
      "epoch 4, Batch loss: 0.3740553855895996\n",
      "epoch 4, Batch loss: 0.3603089153766632\n",
      "epoch 4, Batch loss: 0.785798192024231\n",
      "epoch 4, Batch loss: 0.558473527431488\n",
      "epoch 4, Batch loss: 0.44090500473976135\n",
      "epoch 4, Batch loss: 0.38348421454429626\n",
      "epoch 4, Batch loss: 0.2532433569431305\n",
      "epoch 4, Batch loss: 0.3661963641643524\n",
      "epoch 4, Batch loss: 0.2882470488548279\n",
      "epoch 4, Batch loss: 0.40586891770362854\n",
      "epoch 4, Batch loss: 0.5358352661132812\n",
      "epoch 4, Batch loss: 0.4190143644809723\n",
      "epoch 4, Batch loss: 0.38411852717399597\n",
      "epoch 4, Batch loss: 0.22560767829418182\n",
      "epoch 4, Batch loss: 0.5480162501335144\n",
      "epoch 4, Batch loss: 0.39566370844841003\n",
      "epoch 4, Batch loss: 0.29576218128204346\n",
      "epoch 4, Batch loss: 0.2968331575393677\n",
      "epoch 4, Batch loss: 0.39939090609550476\n",
      "epoch 4, Batch loss: 0.6234303712844849\n",
      "epoch 4, Batch loss: 0.4124632775783539\n",
      "epoch 4, Batch loss: 0.4190533757209778\n",
      "epoch 4, Batch loss: 0.48967474699020386\n",
      "epoch 4, Batch loss: 0.1974661499261856\n",
      "epoch 4, Batch loss: 0.3573290705680847\n",
      "epoch 4, Batch loss: 0.313991904258728\n",
      "epoch 4, Batch loss: 0.5552005767822266\n",
      "epoch 4, Batch loss: 0.4004206657409668\n",
      "epoch 4, Batch loss: 0.5613883137702942\n",
      "epoch 4, Batch loss: 0.5585382580757141\n",
      "epoch 4, Batch loss: 0.6286770105361938\n",
      "epoch 4, Batch loss: 0.3227115869522095\n",
      "epoch 4, Batch loss: 0.31902211904525757\n",
      "epoch 4, Batch loss: 0.26940861344337463\n",
      "epoch 4, Batch loss: 0.2835676074028015\n",
      "epoch 4, Batch loss: 0.7052406668663025\n",
      "epoch 4, Batch loss: 0.32310813665390015\n",
      "epoch 4, Batch loss: 0.25440824031829834\n",
      "epoch 4, Batch loss: 0.3670642077922821\n",
      "epoch 4, Batch loss: 0.5104939341545105\n",
      "epoch 4, Batch loss: 0.3983234763145447\n",
      "epoch 4, Batch loss: 0.33265769481658936\n",
      "epoch 4, Batch loss: 0.46752026677131653\n",
      "epoch 4, Batch loss: 0.3039752244949341\n",
      "epoch 4, Batch loss: 0.33581772446632385\n",
      "epoch 4, Batch loss: 0.29165223240852356\n",
      "epoch 4, Batch loss: 0.6895075440406799\n",
      "epoch 4, Batch loss: 0.2238292247056961\n",
      "epoch 4, Batch loss: 0.5876120328903198\n",
      "epoch 4, Batch loss: 0.6422780752182007\n",
      "epoch 4, Batch loss: 0.6363324522972107\n",
      "epoch 4, Batch loss: 0.34349700808525085\n",
      "epoch 4, Batch loss: 0.44505631923675537\n",
      "epoch 4, Batch loss: 0.3458744287490845\n",
      "epoch 4, Batch loss: 0.2717571556568146\n",
      "epoch 4, Batch loss: 0.2825818359851837\n",
      "epoch 4, Batch loss: 0.41975611448287964\n",
      "epoch 4, Batch loss: 0.3791210353374481\n",
      "epoch 4, Batch loss: 0.42106109857559204\n",
      "epoch 4, Batch loss: 0.27575671672821045\n",
      "epoch 4, Batch loss: 0.4855002164840698\n",
      "epoch 4, Batch loss: 0.35370057821273804\n",
      "epoch 4, Batch loss: 0.34341520071029663\n",
      "epoch 4, Batch loss: 0.7609941959381104\n",
      "epoch 4, Batch loss: 0.4207550585269928\n",
      "epoch 4, Batch loss: 0.5010963678359985\n",
      "epoch 4, Batch loss: 0.4263760447502136\n",
      "epoch 4, Batch loss: 0.4745665192604065\n",
      "epoch 4, Batch loss: 0.47968342900276184\n",
      "epoch 4, Batch loss: 0.4965713322162628\n",
      "epoch 4, Batch loss: 0.7180403470993042\n",
      "epoch 4, Batch loss: 0.8433484435081482\n",
      "epoch 4, Batch loss: 0.3833193778991699\n",
      "epoch 4, Batch loss: 0.2905227243900299\n",
      "epoch 4, Batch loss: 0.5973454713821411\n",
      "epoch 4, Batch loss: 0.3988218903541565\n",
      "epoch 4, Batch loss: 0.3011200726032257\n",
      "epoch 4, Batch loss: 0.4256827235221863\n",
      "epoch 4, Batch loss: 0.4859185814857483\n",
      "epoch 4, Batch loss: 0.9320456981658936\n",
      "epoch 4, Batch loss: 0.5879815816879272\n",
      "epoch 4, Batch loss: 0.557252824306488\n",
      "epoch 4, Batch loss: 0.6090568900108337\n",
      "epoch 4, Batch loss: 0.45139196515083313\n",
      "epoch 4, Batch loss: 0.26924067735671997\n",
      "epoch 5, Batch loss: 0.3443596661090851\n",
      "epoch 5, Batch loss: 0.4156053960323334\n",
      "epoch 5, Batch loss: 0.23504260182380676\n",
      "epoch 5, Batch loss: 0.4738847315311432\n",
      "epoch 5, Batch loss: 0.3316522538661957\n",
      "epoch 5, Batch loss: 0.2944408357143402\n",
      "epoch 5, Batch loss: 0.43970778584480286\n",
      "epoch 5, Batch loss: 0.2858118414878845\n",
      "epoch 5, Batch loss: 0.33468374609947205\n",
      "epoch 5, Batch loss: 0.551170289516449\n",
      "epoch 5, Batch loss: 0.40597161650657654\n",
      "epoch 5, Batch loss: 0.4590965211391449\n",
      "epoch 5, Batch loss: 0.5755171775817871\n",
      "epoch 5, Batch loss: 0.3054371476173401\n",
      "epoch 5, Batch loss: 0.447811096906662\n",
      "epoch 5, Batch loss: 0.6855784058570862\n",
      "epoch 5, Batch loss: 0.5262387990951538\n",
      "epoch 5, Batch loss: 0.3347025215625763\n",
      "epoch 5, Batch loss: 0.3809272348880768\n",
      "epoch 5, Batch loss: 0.26028552651405334\n",
      "epoch 5, Batch loss: 0.3223295509815216\n",
      "epoch 5, Batch loss: 0.3644772171974182\n",
      "epoch 5, Batch loss: 0.41098552942276\n",
      "epoch 5, Batch loss: 0.4899844229221344\n",
      "epoch 5, Batch loss: 0.65211421251297\n",
      "epoch 5, Batch loss: 0.24140091240406036\n",
      "epoch 5, Batch loss: 0.4506123960018158\n",
      "epoch 5, Batch loss: 0.2599243223667145\n",
      "epoch 5, Batch loss: 0.39316803216934204\n",
      "epoch 5, Batch loss: 0.4280646741390228\n",
      "epoch 5, Batch loss: 0.3017878234386444\n",
      "epoch 5, Batch loss: 0.3637739419937134\n",
      "epoch 5, Batch loss: 0.39920273423194885\n",
      "epoch 5, Batch loss: 0.5819224119186401\n",
      "epoch 5, Batch loss: 0.5124150514602661\n",
      "epoch 5, Batch loss: 0.3558763563632965\n",
      "epoch 5, Batch loss: 0.37366655468940735\n",
      "epoch 5, Batch loss: 0.5405388474464417\n",
      "epoch 5, Batch loss: 0.29014846682548523\n",
      "epoch 5, Batch loss: 0.3959384262561798\n",
      "epoch 5, Batch loss: 0.46554428339004517\n",
      "epoch 5, Batch loss: 0.4686030447483063\n",
      "epoch 5, Batch loss: 0.5069804191589355\n",
      "epoch 5, Batch loss: 0.6620408892631531\n",
      "epoch 5, Batch loss: 0.3084246814250946\n",
      "epoch 5, Batch loss: 0.700782299041748\n",
      "epoch 5, Batch loss: 0.35033950209617615\n",
      "epoch 5, Batch loss: 0.3534821569919586\n",
      "epoch 5, Batch loss: 0.4263717234134674\n",
      "epoch 5, Batch loss: 0.2657821774482727\n",
      "epoch 5, Batch loss: 0.33111539483070374\n",
      "epoch 5, Batch loss: 0.3432563245296478\n",
      "epoch 5, Batch loss: 0.7091104984283447\n",
      "epoch 5, Batch loss: 0.409807950258255\n",
      "epoch 5, Batch loss: 0.30452099442481995\n",
      "epoch 5, Batch loss: 0.4884366989135742\n",
      "epoch 5, Batch loss: 0.45191720128059387\n",
      "epoch 5, Batch loss: 0.4519009590148926\n",
      "epoch 5, Batch loss: 0.451713889837265\n",
      "epoch 5, Batch loss: 0.46756890416145325\n",
      "epoch 5, Batch loss: 0.48720675706863403\n",
      "epoch 5, Batch loss: 0.4285218417644501\n",
      "epoch 5, Batch loss: 0.4115334451198578\n",
      "epoch 5, Batch loss: 0.560731828212738\n",
      "epoch 5, Batch loss: 0.44402191042900085\n",
      "epoch 5, Batch loss: 0.3196107745170593\n",
      "epoch 5, Batch loss: 0.32502254843711853\n",
      "epoch 5, Batch loss: 0.5695814490318298\n",
      "epoch 5, Batch loss: 0.4051285684108734\n",
      "epoch 5, Batch loss: 0.47435882687568665\n",
      "epoch 5, Batch loss: 0.4624156951904297\n",
      "epoch 5, Batch loss: 0.42245447635650635\n",
      "epoch 5, Batch loss: 0.6198212504386902\n",
      "epoch 5, Batch loss: 0.5035170316696167\n",
      "epoch 5, Batch loss: 0.28887709975242615\n",
      "epoch 5, Batch loss: 0.531434953212738\n",
      "epoch 5, Batch loss: 0.4273025095462799\n",
      "epoch 5, Batch loss: 0.4016474485397339\n",
      "epoch 5, Batch loss: 0.3079919219017029\n",
      "epoch 5, Batch loss: 0.44133955240249634\n",
      "epoch 5, Batch loss: 0.6461119651794434\n",
      "epoch 5, Batch loss: 0.7154764533042908\n",
      "epoch 5, Batch loss: 0.47302573919296265\n",
      "epoch 5, Batch loss: 0.43168944120407104\n",
      "epoch 5, Batch loss: 0.5951507687568665\n",
      "epoch 5, Batch loss: 0.506310760974884\n",
      "epoch 5, Batch loss: 0.33157750964164734\n",
      "epoch 5, Batch loss: 0.41867902874946594\n",
      "epoch 5, Batch loss: 0.4222869873046875\n",
      "epoch 5, Batch loss: 0.25781336426734924\n",
      "epoch 5, Batch loss: 0.45225948095321655\n",
      "epoch 5, Batch loss: 0.3209371864795685\n",
      "epoch 5, Batch loss: 0.3690066635608673\n",
      "epoch 5, Batch loss: 0.3114558756351471\n",
      "epoch 5, Batch loss: 0.42237886786460876\n",
      "epoch 5, Batch loss: 0.32395637035369873\n",
      "epoch 5, Batch loss: 0.5774081349372864\n",
      "epoch 5, Batch loss: 0.3196706473827362\n",
      "epoch 5, Batch loss: 0.32773256301879883\n",
      "epoch 5, Batch loss: 0.31061625480651855\n",
      "epoch 5, Batch loss: 0.4404977858066559\n",
      "epoch 5, Batch loss: 0.3753051459789276\n",
      "epoch 5, Batch loss: 0.4817259907722473\n",
      "epoch 5, Batch loss: 0.27657967805862427\n",
      "epoch 5, Batch loss: 0.28382623195648193\n",
      "epoch 5, Batch loss: 0.6377073526382446\n",
      "epoch 5, Batch loss: 0.23161670565605164\n",
      "epoch 5, Batch loss: 0.45202386379241943\n",
      "epoch 5, Batch loss: 0.37834692001342773\n",
      "epoch 5, Batch loss: 0.398762583732605\n",
      "epoch 5, Batch loss: 0.6792325973510742\n",
      "epoch 5, Batch loss: 0.3916747570037842\n",
      "epoch 5, Batch loss: 0.2356691211462021\n",
      "epoch 5, Batch loss: 0.4045691192150116\n",
      "epoch 5, Batch loss: 0.2391878068447113\n",
      "epoch 5, Batch loss: 0.3253227174282074\n",
      "epoch 5, Batch loss: 0.4376191198825836\n",
      "epoch 5, Batch loss: 0.4340430200099945\n",
      "epoch 5, Batch loss: 0.6462130546569824\n",
      "epoch 5, Batch loss: 0.5494645237922668\n",
      "epoch 5, Batch loss: 0.2960236966609955\n",
      "epoch 5, Batch loss: 0.49568426609039307\n",
      "epoch 5, Batch loss: 0.4792858064174652\n",
      "epoch 5, Batch loss: 0.4642479717731476\n",
      "epoch 5, Batch loss: 0.3190748691558838\n",
      "epoch 6, Batch loss: 0.46313536167144775\n",
      "epoch 6, Batch loss: 0.377502977848053\n",
      "epoch 6, Batch loss: 0.3083345293998718\n",
      "epoch 6, Batch loss: 0.3010120689868927\n",
      "epoch 6, Batch loss: 0.35811564326286316\n",
      "epoch 6, Batch loss: 0.31204137206077576\n",
      "epoch 6, Batch loss: 0.32569098472595215\n",
      "epoch 6, Batch loss: 0.4684826135635376\n",
      "epoch 6, Batch loss: 0.7125275731086731\n",
      "epoch 6, Batch loss: 0.3768296539783478\n",
      "epoch 6, Batch loss: 0.6153359413146973\n",
      "epoch 6, Batch loss: 0.3585498631000519\n",
      "epoch 6, Batch loss: 0.445954293012619\n",
      "epoch 6, Batch loss: 0.3670188784599304\n",
      "epoch 6, Batch loss: 0.2875625193119049\n",
      "epoch 6, Batch loss: 0.29490965604782104\n",
      "epoch 6, Batch loss: 0.3180404007434845\n",
      "epoch 6, Batch loss: 0.49828124046325684\n",
      "epoch 6, Batch loss: 0.5802145004272461\n",
      "epoch 6, Batch loss: 0.36585181951522827\n",
      "epoch 6, Batch loss: 0.4257356822490692\n",
      "epoch 6, Batch loss: 0.4244704246520996\n",
      "epoch 6, Batch loss: 0.22768732905387878\n",
      "epoch 6, Batch loss: 0.6708310842514038\n",
      "epoch 6, Batch loss: 0.5585388541221619\n",
      "epoch 6, Batch loss: 0.406511127948761\n",
      "epoch 6, Batch loss: 0.29893139004707336\n",
      "epoch 6, Batch loss: 0.7351187467575073\n",
      "epoch 6, Batch loss: 0.3166782855987549\n",
      "epoch 6, Batch loss: 0.5305711030960083\n",
      "epoch 6, Batch loss: 0.4135226905345917\n",
      "epoch 6, Batch loss: 0.629143476486206\n",
      "epoch 6, Batch loss: 0.5787861943244934\n",
      "epoch 6, Batch loss: 0.5460371375083923\n",
      "epoch 6, Batch loss: 0.33500489592552185\n",
      "epoch 6, Batch loss: 0.3418889343738556\n",
      "epoch 6, Batch loss: 0.33565109968185425\n",
      "epoch 6, Batch loss: 0.3204789459705353\n",
      "epoch 6, Batch loss: 0.2832423746585846\n",
      "epoch 6, Batch loss: 0.29367226362228394\n",
      "epoch 6, Batch loss: 0.5848018527030945\n",
      "epoch 6, Batch loss: 0.34490102529525757\n",
      "epoch 6, Batch loss: 0.31859514117240906\n",
      "epoch 6, Batch loss: 0.26925158500671387\n",
      "epoch 6, Batch loss: 0.4481690227985382\n",
      "epoch 6, Batch loss: 0.5590770244598389\n",
      "epoch 6, Batch loss: 0.7886959314346313\n",
      "epoch 6, Batch loss: 0.25614675879478455\n",
      "epoch 6, Batch loss: 0.5344948768615723\n",
      "epoch 6, Batch loss: 0.25105658173561096\n",
      "epoch 6, Batch loss: 0.5486242175102234\n",
      "epoch 6, Batch loss: 0.2719375491142273\n",
      "epoch 6, Batch loss: 0.4930676519870758\n",
      "epoch 6, Batch loss: 0.30820634961128235\n",
      "epoch 6, Batch loss: 0.4085320234298706\n",
      "epoch 6, Batch loss: 0.4129282236099243\n",
      "epoch 6, Batch loss: 0.4211922287940979\n",
      "epoch 6, Batch loss: 0.4616489112377167\n",
      "epoch 6, Batch loss: 0.39794841408729553\n",
      "epoch 6, Batch loss: 0.4050218462944031\n",
      "epoch 6, Batch loss: 0.23960573971271515\n",
      "epoch 6, Batch loss: 0.3929024338722229\n",
      "epoch 6, Batch loss: 0.35105645656585693\n",
      "epoch 6, Batch loss: 0.23713654279708862\n",
      "epoch 6, Batch loss: 0.25038713216781616\n",
      "epoch 6, Batch loss: 0.37970104813575745\n",
      "epoch 6, Batch loss: 0.42286714911460876\n",
      "epoch 6, Batch loss: 0.41945508122444153\n",
      "epoch 6, Batch loss: 0.2781735360622406\n",
      "epoch 6, Batch loss: 0.37880849838256836\n",
      "epoch 6, Batch loss: 0.30012384057044983\n",
      "epoch 6, Batch loss: 0.31442922353744507\n",
      "epoch 6, Batch loss: 0.2713139057159424\n",
      "epoch 6, Batch loss: 0.5942273736000061\n",
      "epoch 6, Batch loss: 0.29358136653900146\n",
      "epoch 6, Batch loss: 0.2721661627292633\n",
      "epoch 6, Batch loss: 0.34147533774375916\n",
      "epoch 6, Batch loss: 0.361628919839859\n",
      "epoch 6, Batch loss: 0.41003113985061646\n",
      "epoch 6, Batch loss: 0.5121508836746216\n",
      "epoch 6, Batch loss: 0.6038193106651306\n",
      "epoch 6, Batch loss: 0.35401612520217896\n",
      "epoch 6, Batch loss: 0.3458361029624939\n",
      "epoch 6, Batch loss: 0.7598382234573364\n",
      "epoch 6, Batch loss: 0.6474477648735046\n",
      "epoch 6, Batch loss: 0.6485615372657776\n",
      "epoch 6, Batch loss: 0.2641089856624603\n",
      "epoch 6, Batch loss: 0.41252920031547546\n",
      "epoch 6, Batch loss: 0.24715642631053925\n",
      "epoch 6, Batch loss: 0.4179946482181549\n",
      "epoch 6, Batch loss: 0.37814265489578247\n",
      "epoch 6, Batch loss: 0.38566190004348755\n",
      "epoch 6, Batch loss: 0.39660224318504333\n",
      "epoch 6, Batch loss: 0.2717536985874176\n",
      "epoch 6, Batch loss: 0.761520504951477\n",
      "epoch 6, Batch loss: 0.33601540327072144\n",
      "epoch 6, Batch loss: 0.5722924470901489\n",
      "epoch 6, Batch loss: 0.72431880235672\n",
      "epoch 6, Batch loss: 0.4195995032787323\n",
      "epoch 6, Batch loss: 0.32778194546699524\n",
      "epoch 6, Batch loss: 0.3237294554710388\n",
      "epoch 6, Batch loss: 0.33061596751213074\n",
      "epoch 6, Batch loss: 0.3160959482192993\n",
      "epoch 6, Batch loss: 0.39251455664634705\n",
      "epoch 6, Batch loss: 0.30382734537124634\n",
      "epoch 6, Batch loss: 0.3533463180065155\n",
      "epoch 6, Batch loss: 0.36484694480895996\n",
      "epoch 6, Batch loss: 0.2939302623271942\n",
      "epoch 6, Batch loss: 0.4853646159172058\n",
      "epoch 6, Batch loss: 0.42249172925949097\n",
      "epoch 6, Batch loss: 0.44983723759651184\n",
      "epoch 6, Batch loss: 0.39933666586875916\n",
      "epoch 6, Batch loss: 0.44273996353149414\n",
      "epoch 6, Batch loss: 0.4717957377433777\n",
      "epoch 6, Batch loss: 0.5162484645843506\n",
      "epoch 6, Batch loss: 0.4924575090408325\n",
      "epoch 6, Batch loss: 0.37794071435928345\n",
      "epoch 6, Batch loss: 0.5808427333831787\n",
      "epoch 6, Batch loss: 0.42746925354003906\n",
      "epoch 6, Batch loss: 0.48151272535324097\n",
      "epoch 6, Batch loss: 0.30606186389923096\n",
      "epoch 6, Batch loss: 0.3532460629940033\n",
      "epoch 6, Batch loss: 0.26337042450904846\n",
      "epoch 6, Batch loss: 0.32262104749679565\n",
      "epoch 6, Batch loss: 0.3776949346065521\n",
      "epoch 7, Batch loss: 0.525783896446228\n",
      "epoch 7, Batch loss: 0.23455147445201874\n",
      "epoch 7, Batch loss: 0.3191065192222595\n",
      "epoch 7, Batch loss: 0.2980335056781769\n",
      "epoch 7, Batch loss: 0.43041279911994934\n",
      "epoch 7, Batch loss: 0.2743600308895111\n",
      "epoch 7, Batch loss: 0.3304485082626343\n",
      "epoch 7, Batch loss: 0.36073216795921326\n",
      "epoch 7, Batch loss: 0.3213011622428894\n",
      "epoch 7, Batch loss: 0.5782551169395447\n",
      "epoch 7, Batch loss: 0.3134672939777374\n",
      "epoch 7, Batch loss: 0.3364209830760956\n",
      "epoch 7, Batch loss: 0.2932310700416565\n",
      "epoch 7, Batch loss: 0.530064582824707\n",
      "epoch 7, Batch loss: 0.6611015200614929\n",
      "epoch 7, Batch loss: 0.33463287353515625\n",
      "epoch 7, Batch loss: 0.36830538511276245\n",
      "epoch 7, Batch loss: 0.48498615622520447\n",
      "epoch 7, Batch loss: 0.3548039495944977\n",
      "epoch 7, Batch loss: 0.6257860660552979\n",
      "epoch 7, Batch loss: 0.5896235108375549\n",
      "epoch 7, Batch loss: 0.4689987301826477\n",
      "epoch 7, Batch loss: 0.3944668769836426\n",
      "epoch 7, Batch loss: 0.4616360068321228\n",
      "epoch 7, Batch loss: 0.43697336316108704\n",
      "epoch 7, Batch loss: 0.6792411208152771\n",
      "epoch 7, Batch loss: 0.3296581208705902\n",
      "epoch 7, Batch loss: 0.5625249147415161\n",
      "epoch 7, Batch loss: 0.4154508709907532\n",
      "epoch 7, Batch loss: 0.45739367604255676\n",
      "epoch 7, Batch loss: 0.6252654790878296\n",
      "epoch 7, Batch loss: 0.1928325891494751\n",
      "epoch 7, Batch loss: 0.3326496481895447\n",
      "epoch 7, Batch loss: 0.38389766216278076\n",
      "epoch 7, Batch loss: 0.379191517829895\n",
      "epoch 7, Batch loss: 0.3473888039588928\n",
      "epoch 7, Batch loss: 0.3648526668548584\n",
      "epoch 7, Batch loss: 0.45636242628097534\n",
      "epoch 7, Batch loss: 0.23062975704669952\n",
      "epoch 7, Batch loss: 0.434970885515213\n",
      "epoch 7, Batch loss: 0.4503501355648041\n",
      "epoch 7, Batch loss: 0.36765429377555847\n",
      "epoch 7, Batch loss: 0.24910487234592438\n",
      "epoch 7, Batch loss: 0.5505377054214478\n",
      "epoch 7, Batch loss: 0.33840855956077576\n",
      "epoch 7, Batch loss: 0.33780616521835327\n",
      "epoch 7, Batch loss: 0.2288021296262741\n",
      "epoch 7, Batch loss: 0.5481316447257996\n",
      "epoch 7, Batch loss: 0.3966774642467499\n",
      "epoch 7, Batch loss: 0.31536343693733215\n",
      "epoch 7, Batch loss: 0.32141348719596863\n",
      "epoch 7, Batch loss: 0.4636804759502411\n",
      "epoch 7, Batch loss: 0.3785521686077118\n",
      "epoch 7, Batch loss: 0.32524892687797546\n",
      "epoch 7, Batch loss: 0.30565395951271057\n",
      "epoch 7, Batch loss: 0.43932563066482544\n",
      "epoch 7, Batch loss: 0.3196847438812256\n",
      "epoch 7, Batch loss: 0.23972484469413757\n",
      "epoch 7, Batch loss: 0.637843668460846\n",
      "epoch 7, Batch loss: 0.40406015515327454\n",
      "epoch 7, Batch loss: 0.3243511915206909\n",
      "epoch 7, Batch loss: 0.34196799993515015\n",
      "epoch 7, Batch loss: 0.40269923210144043\n",
      "epoch 7, Batch loss: 0.3145206868648529\n",
      "epoch 7, Batch loss: 0.4774020314216614\n",
      "epoch 7, Batch loss: 0.570551872253418\n",
      "epoch 7, Batch loss: 0.2817066013813019\n",
      "epoch 7, Batch loss: 0.3685021996498108\n",
      "epoch 7, Batch loss: 0.4062109887599945\n",
      "epoch 7, Batch loss: 0.42449504137039185\n",
      "epoch 7, Batch loss: 0.39116325974464417\n",
      "epoch 7, Batch loss: 0.3119082450866699\n",
      "epoch 7, Batch loss: 0.6591978669166565\n",
      "epoch 7, Batch loss: 0.39871886372566223\n",
      "epoch 7, Batch loss: 0.6500763297080994\n",
      "epoch 7, Batch loss: 0.6424565315246582\n",
      "epoch 7, Batch loss: 0.48038849234580994\n",
      "epoch 7, Batch loss: 0.2071717381477356\n",
      "epoch 7, Batch loss: 0.5099495053291321\n",
      "epoch 7, Batch loss: 0.4181293845176697\n",
      "epoch 7, Batch loss: 0.5205223560333252\n",
      "epoch 7, Batch loss: 0.26902472972869873\n",
      "epoch 7, Batch loss: 0.40271562337875366\n",
      "epoch 7, Batch loss: 0.31404808163642883\n",
      "epoch 7, Batch loss: 0.24266760051250458\n",
      "epoch 7, Batch loss: 0.42648079991340637\n",
      "epoch 7, Batch loss: 0.5314891934394836\n",
      "epoch 7, Batch loss: 0.1991029679775238\n",
      "epoch 7, Batch loss: 0.41479071974754333\n",
      "epoch 7, Batch loss: 0.32704785466194153\n",
      "epoch 7, Batch loss: 0.3894895911216736\n",
      "epoch 7, Batch loss: 0.5100092887878418\n",
      "epoch 7, Batch loss: 0.34650328755378723\n",
      "epoch 7, Batch loss: 0.607323408126831\n",
      "epoch 7, Batch loss: 0.32013610005378723\n",
      "epoch 7, Batch loss: 0.3942027986049652\n",
      "epoch 7, Batch loss: 0.2633674442768097\n",
      "epoch 7, Batch loss: 0.5681854486465454\n",
      "epoch 7, Batch loss: 0.3932805061340332\n",
      "epoch 7, Batch loss: 0.30904170870780945\n",
      "epoch 7, Batch loss: 0.2328266054391861\n",
      "epoch 7, Batch loss: 0.4179651737213135\n",
      "epoch 7, Batch loss: 0.36432668566703796\n",
      "epoch 7, Batch loss: 0.4757481515407562\n",
      "epoch 7, Batch loss: 0.19008317589759827\n",
      "epoch 7, Batch loss: 0.5415305495262146\n",
      "epoch 7, Batch loss: 0.5537302494049072\n",
      "epoch 7, Batch loss: 0.31545379757881165\n",
      "epoch 7, Batch loss: 0.3411162793636322\n",
      "epoch 7, Batch loss: 0.38678425550460815\n",
      "epoch 7, Batch loss: 0.2737186551094055\n",
      "epoch 7, Batch loss: 0.505464494228363\n",
      "epoch 7, Batch loss: 0.8628067970275879\n",
      "epoch 7, Batch loss: 0.3591119050979614\n",
      "epoch 7, Batch loss: 0.29951581358909607\n",
      "epoch 7, Batch loss: 0.39233747124671936\n",
      "epoch 7, Batch loss: 0.297853022813797\n",
      "epoch 7, Batch loss: 0.26247721910476685\n",
      "epoch 7, Batch loss: 0.616518497467041\n",
      "epoch 7, Batch loss: 0.3123328983783722\n",
      "epoch 7, Batch loss: 0.20213928818702698\n",
      "epoch 7, Batch loss: 0.3902091681957245\n",
      "epoch 7, Batch loss: 0.2573215961456299\n",
      "epoch 7, Batch loss: 0.4527309238910675\n",
      "epoch 7, Batch loss: 0.30720511078834534\n",
      "epoch 8, Batch loss: 0.40688425302505493\n",
      "epoch 8, Batch loss: 0.33671578764915466\n",
      "epoch 8, Batch loss: 0.22139015793800354\n",
      "epoch 8, Batch loss: 0.5267871618270874\n",
      "epoch 8, Batch loss: 0.5619220733642578\n",
      "epoch 8, Batch loss: 0.46958863735198975\n",
      "epoch 8, Batch loss: 0.46074286103248596\n",
      "epoch 8, Batch loss: 0.33548998832702637\n",
      "epoch 8, Batch loss: 0.4296848177909851\n",
      "epoch 8, Batch loss: 0.4218030869960785\n",
      "epoch 8, Batch loss: 0.4620872437953949\n",
      "epoch 8, Batch loss: 0.2648526728153229\n",
      "epoch 8, Batch loss: 0.6022821068763733\n",
      "epoch 8, Batch loss: 0.4698764383792877\n",
      "epoch 8, Batch loss: 0.29251083731651306\n",
      "epoch 8, Batch loss: 0.6968324184417725\n",
      "epoch 8, Batch loss: 0.4417496621608734\n",
      "epoch 8, Batch loss: 0.39163079857826233\n",
      "epoch 8, Batch loss: 0.2562251389026642\n",
      "epoch 8, Batch loss: 0.4965040385723114\n",
      "epoch 8, Batch loss: 0.458392858505249\n",
      "epoch 8, Batch loss: 0.3148864805698395\n",
      "epoch 8, Batch loss: 0.2918400168418884\n",
      "epoch 8, Batch loss: 0.45416074991226196\n",
      "epoch 8, Batch loss: 0.32875746488571167\n",
      "epoch 8, Batch loss: 0.32155999541282654\n",
      "epoch 8, Batch loss: 0.19880743324756622\n",
      "epoch 8, Batch loss: 0.4921885132789612\n",
      "epoch 8, Batch loss: 0.4326282739639282\n",
      "epoch 8, Batch loss: 0.3257320821285248\n",
      "epoch 8, Batch loss: 0.37868475914001465\n",
      "epoch 8, Batch loss: 0.2593782842159271\n",
      "epoch 8, Batch loss: 0.3613496720790863\n",
      "epoch 8, Batch loss: 0.4704402685165405\n",
      "epoch 8, Batch loss: 0.3628687262535095\n",
      "epoch 8, Batch loss: 0.28162652254104614\n",
      "epoch 8, Batch loss: 0.41339752078056335\n",
      "epoch 8, Batch loss: 0.28852301836013794\n",
      "epoch 8, Batch loss: 0.28677111864089966\n",
      "epoch 8, Batch loss: 0.1953873187303543\n",
      "epoch 8, Batch loss: 0.2323502153158188\n",
      "epoch 8, Batch loss: 0.26596465706825256\n",
      "epoch 8, Batch loss: 0.44025877118110657\n",
      "epoch 8, Batch loss: 0.3356632590293884\n",
      "epoch 8, Batch loss: 0.435403436422348\n",
      "epoch 8, Batch loss: 0.38072142004966736\n",
      "epoch 8, Batch loss: 0.2648068964481354\n",
      "epoch 8, Batch loss: 0.47463926672935486\n",
      "epoch 8, Batch loss: 0.33304932713508606\n",
      "epoch 8, Batch loss: 0.47342565655708313\n",
      "epoch 8, Batch loss: 0.4250357747077942\n",
      "epoch 8, Batch loss: 0.31340882182121277\n",
      "epoch 8, Batch loss: 0.6159183382987976\n",
      "epoch 8, Batch loss: 0.24701246619224548\n",
      "epoch 8, Batch loss: 0.18950730562210083\n",
      "epoch 8, Batch loss: 0.33022552728652954\n",
      "epoch 8, Batch loss: 0.21454522013664246\n",
      "epoch 8, Batch loss: 0.3596869707107544\n",
      "epoch 8, Batch loss: 0.6176871061325073\n",
      "epoch 8, Batch loss: 0.2894284725189209\n",
      "epoch 8, Batch loss: 0.30124711990356445\n",
      "epoch 8, Batch loss: 0.300150990486145\n",
      "epoch 8, Batch loss: 0.4123896658420563\n",
      "epoch 8, Batch loss: 0.42381083965301514\n",
      "epoch 8, Batch loss: 0.5281491279602051\n",
      "epoch 8, Batch loss: 0.38673317432403564\n",
      "epoch 8, Batch loss: 0.50758957862854\n",
      "epoch 8, Batch loss: 0.4110751748085022\n",
      "epoch 8, Batch loss: 0.34319910407066345\n",
      "epoch 8, Batch loss: 0.38910630345344543\n",
      "epoch 8, Batch loss: 0.3827209770679474\n",
      "epoch 8, Batch loss: 0.25431421399116516\n",
      "epoch 8, Batch loss: 0.3465750813484192\n",
      "epoch 8, Batch loss: 0.3940150737762451\n",
      "epoch 8, Batch loss: 0.7197248339653015\n",
      "epoch 8, Batch loss: 0.39569368958473206\n",
      "epoch 8, Batch loss: 0.585399329662323\n",
      "epoch 8, Batch loss: 0.37281304597854614\n",
      "epoch 8, Batch loss: 0.4597969949245453\n",
      "epoch 8, Batch loss: 0.35034051537513733\n",
      "epoch 8, Batch loss: 0.2412310689687729\n",
      "epoch 8, Batch loss: 0.3044899106025696\n",
      "epoch 8, Batch loss: 0.531276285648346\n",
      "epoch 8, Batch loss: 0.364005982875824\n",
      "epoch 8, Batch loss: 0.36292997002601624\n",
      "epoch 8, Batch loss: 0.45404523611068726\n",
      "epoch 8, Batch loss: 0.4026244878768921\n",
      "epoch 8, Batch loss: 0.6922888159751892\n",
      "epoch 8, Batch loss: 0.3323163688182831\n",
      "epoch 8, Batch loss: 0.36306455731391907\n",
      "epoch 8, Batch loss: 0.5817337036132812\n",
      "epoch 8, Batch loss: 0.5472216606140137\n",
      "epoch 8, Batch loss: 0.6582715511322021\n",
      "epoch 8, Batch loss: 0.44198140501976013\n",
      "epoch 8, Batch loss: 0.4808264374732971\n",
      "epoch 8, Batch loss: 0.25497114658355713\n",
      "epoch 8, Batch loss: 0.376430481672287\n",
      "epoch 8, Batch loss: 0.6022371649742126\n",
      "epoch 8, Batch loss: 0.2761556804180145\n",
      "epoch 8, Batch loss: 0.2166973501443863\n",
      "epoch 8, Batch loss: 0.4054519832134247\n",
      "epoch 8, Batch loss: 0.3245715796947479\n",
      "epoch 8, Batch loss: 0.39513635635375977\n",
      "epoch 8, Batch loss: 0.3542928993701935\n",
      "epoch 8, Batch loss: 0.2882094383239746\n",
      "epoch 8, Batch loss: 0.3772857189178467\n",
      "epoch 8, Batch loss: 0.28719645738601685\n",
      "epoch 8, Batch loss: 0.37159013748168945\n",
      "epoch 8, Batch loss: 0.505799412727356\n",
      "epoch 8, Batch loss: 0.3582521378993988\n",
      "epoch 8, Batch loss: 0.23693722486495972\n",
      "epoch 8, Batch loss: 0.4363284111022949\n",
      "epoch 8, Batch loss: 0.3952012062072754\n",
      "epoch 8, Batch loss: 0.39715686440467834\n",
      "epoch 8, Batch loss: 0.3873760402202606\n",
      "epoch 8, Batch loss: 0.3130233883857727\n",
      "epoch 8, Batch loss: 0.4294775724411011\n",
      "epoch 8, Batch loss: 0.2922615706920624\n",
      "epoch 8, Batch loss: 0.3310917317867279\n",
      "epoch 8, Batch loss: 0.31961530447006226\n",
      "epoch 8, Batch loss: 0.43121230602264404\n",
      "epoch 8, Batch loss: 0.41242289543151855\n",
      "epoch 8, Batch loss: 0.5401180982589722\n",
      "epoch 8, Batch loss: 0.4360191226005554\n",
      "epoch 8, Batch loss: 0.44782087206840515\n",
      "epoch 9, Batch loss: 0.532260000705719\n",
      "epoch 9, Batch loss: 0.39885908365249634\n",
      "epoch 9, Batch loss: 0.287725567817688\n",
      "epoch 9, Batch loss: 0.3849996328353882\n",
      "epoch 9, Batch loss: 0.37348178029060364\n",
      "epoch 9, Batch loss: 0.290894478559494\n",
      "epoch 9, Batch loss: 0.3457903265953064\n",
      "epoch 9, Batch loss: 0.29251018166542053\n",
      "epoch 9, Batch loss: 0.6364348530769348\n",
      "epoch 9, Batch loss: 0.3932536840438843\n",
      "epoch 9, Batch loss: 0.19711413979530334\n",
      "epoch 9, Batch loss: 0.2849574089050293\n",
      "epoch 9, Batch loss: 0.36215606331825256\n",
      "epoch 9, Batch loss: 0.26706787943840027\n",
      "epoch 9, Batch loss: 0.39417141675949097\n",
      "epoch 9, Batch loss: 0.22126802802085876\n",
      "epoch 9, Batch loss: 0.44689539074897766\n",
      "epoch 9, Batch loss: 0.25230318307876587\n",
      "epoch 9, Batch loss: 0.28764113783836365\n",
      "epoch 9, Batch loss: 0.4039768874645233\n",
      "epoch 9, Batch loss: 0.2964637279510498\n",
      "epoch 9, Batch loss: 0.4425920844078064\n",
      "epoch 9, Batch loss: 0.2897762060165405\n",
      "epoch 9, Batch loss: 0.2489069253206253\n",
      "epoch 9, Batch loss: 0.3105108141899109\n",
      "epoch 9, Batch loss: 0.7469826340675354\n",
      "epoch 9, Batch loss: 0.3029244840145111\n",
      "epoch 9, Batch loss: 0.40027374029159546\n",
      "epoch 9, Batch loss: 0.33805766701698303\n",
      "epoch 9, Batch loss: 0.47927021980285645\n",
      "epoch 9, Batch loss: 0.27783623337745667\n",
      "epoch 9, Batch loss: 0.31183382868766785\n",
      "epoch 9, Batch loss: 0.37093302607536316\n",
      "epoch 9, Batch loss: 0.34799376130104065\n",
      "epoch 9, Batch loss: 0.38853806257247925\n",
      "epoch 9, Batch loss: 0.30233460664749146\n",
      "epoch 9, Batch loss: 0.5068365335464478\n",
      "epoch 9, Batch loss: 0.49379315972328186\n",
      "epoch 9, Batch loss: 0.3870856761932373\n",
      "epoch 9, Batch loss: 0.3229074776172638\n",
      "epoch 9, Batch loss: 0.3141876757144928\n",
      "epoch 9, Batch loss: 0.30121898651123047\n",
      "epoch 9, Batch loss: 0.40683451294898987\n",
      "epoch 9, Batch loss: 0.4218418002128601\n",
      "epoch 9, Batch loss: 0.2996509075164795\n",
      "epoch 9, Batch loss: 0.23692628741264343\n",
      "epoch 9, Batch loss: 0.42394453287124634\n",
      "epoch 9, Batch loss: 0.7106683850288391\n",
      "epoch 9, Batch loss: 0.37032464146614075\n",
      "epoch 9, Batch loss: 0.5031609535217285\n",
      "epoch 9, Batch loss: 0.36655551195144653\n",
      "epoch 9, Batch loss: 0.3633935749530792\n",
      "epoch 9, Batch loss: 0.36077240109443665\n",
      "epoch 9, Batch loss: 0.27278369665145874\n",
      "epoch 9, Batch loss: 0.266137957572937\n",
      "epoch 9, Batch loss: 0.6210339069366455\n",
      "epoch 9, Batch loss: 0.3846946358680725\n",
      "epoch 9, Batch loss: 0.30624914169311523\n",
      "epoch 9, Batch loss: 0.31432831287384033\n",
      "epoch 9, Batch loss: 0.4461233615875244\n",
      "epoch 9, Batch loss: 0.4266483783721924\n",
      "epoch 9, Batch loss: 0.3413448929786682\n",
      "epoch 9, Batch loss: 0.6972714066505432\n",
      "epoch 9, Batch loss: 0.6474789977073669\n",
      "epoch 9, Batch loss: 0.2737271189689636\n",
      "epoch 9, Batch loss: 0.24313458800315857\n",
      "epoch 9, Batch loss: 0.46167993545532227\n",
      "epoch 9, Batch loss: 0.3593626916408539\n",
      "epoch 9, Batch loss: 0.45199933648109436\n",
      "epoch 9, Batch loss: 0.2108524590730667\n",
      "epoch 9, Batch loss: 0.37314820289611816\n",
      "epoch 9, Batch loss: 0.2672273516654968\n",
      "epoch 9, Batch loss: 0.39702868461608887\n",
      "epoch 9, Batch loss: 0.4643080234527588\n",
      "epoch 9, Batch loss: 0.4557654857635498\n",
      "epoch 9, Batch loss: 0.3531673848628998\n",
      "epoch 9, Batch loss: 0.45829281210899353\n",
      "epoch 9, Batch loss: 0.30269312858581543\n",
      "epoch 9, Batch loss: 0.2689286172389984\n",
      "epoch 9, Batch loss: 0.2642423212528229\n",
      "epoch 9, Batch loss: 0.22695408761501312\n",
      "epoch 9, Batch loss: 0.4088301956653595\n",
      "epoch 9, Batch loss: 0.657285749912262\n",
      "epoch 9, Batch loss: 0.2585323452949524\n",
      "epoch 9, Batch loss: 0.4201483428478241\n",
      "epoch 9, Batch loss: 0.6286276578903198\n",
      "epoch 9, Batch loss: 0.49448883533477783\n",
      "epoch 9, Batch loss: 0.3733702301979065\n",
      "epoch 9, Batch loss: 0.5933189392089844\n",
      "epoch 9, Batch loss: 0.39937230944633484\n",
      "epoch 9, Batch loss: 0.3377591669559479\n",
      "epoch 9, Batch loss: 0.3282835781574249\n",
      "epoch 9, Batch loss: 0.30265286564826965\n",
      "epoch 9, Batch loss: 0.4913352131843567\n",
      "epoch 9, Batch loss: 0.24655336141586304\n",
      "epoch 9, Batch loss: 0.37231793999671936\n",
      "epoch 9, Batch loss: 0.33302825689315796\n",
      "epoch 9, Batch loss: 0.519635796546936\n",
      "epoch 9, Batch loss: 0.2991698980331421\n",
      "epoch 9, Batch loss: 0.3720822036266327\n",
      "epoch 9, Batch loss: 0.22977808117866516\n",
      "epoch 9, Batch loss: 0.3396556079387665\n",
      "epoch 9, Batch loss: 0.3537798225879669\n",
      "epoch 9, Batch loss: 0.29797041416168213\n",
      "epoch 9, Batch loss: 0.4281367361545563\n",
      "epoch 9, Batch loss: 0.4581422209739685\n",
      "epoch 9, Batch loss: 0.6366350650787354\n",
      "epoch 9, Batch loss: 0.5748709440231323\n",
      "epoch 9, Batch loss: 0.3750520646572113\n",
      "epoch 9, Batch loss: 0.3603202700614929\n",
      "epoch 9, Batch loss: 0.38919544219970703\n",
      "epoch 9, Batch loss: 0.5393116474151611\n",
      "epoch 9, Batch loss: 0.3710459768772125\n",
      "epoch 9, Batch loss: 0.4033219814300537\n",
      "epoch 9, Batch loss: 0.4798741638660431\n",
      "epoch 9, Batch loss: 0.5432189702987671\n",
      "epoch 9, Batch loss: 0.32532626390457153\n",
      "epoch 9, Batch loss: 0.4217444658279419\n",
      "epoch 9, Batch loss: 0.47959619760513306\n",
      "epoch 9, Batch loss: 0.2942623496055603\n",
      "epoch 9, Batch loss: 0.2580457925796509\n",
      "epoch 9, Batch loss: 0.35346415638923645\n",
      "epoch 9, Batch loss: 0.22656358778476715\n",
      "epoch 9, Batch loss: 0.3493153154850006\n",
      "epoch 9, Batch loss: 0.27608805894851685\n",
      "epoch 10, Batch loss: 0.390369176864624\n",
      "epoch 10, Batch loss: 0.22613078355789185\n",
      "epoch 10, Batch loss: 0.2599659264087677\n",
      "epoch 10, Batch loss: 0.4923386573791504\n",
      "epoch 10, Batch loss: 0.43581146001815796\n",
      "epoch 10, Batch loss: 0.33942919969558716\n",
      "epoch 10, Batch loss: 0.3562343120574951\n",
      "epoch 10, Batch loss: 0.3539435863494873\n",
      "epoch 10, Batch loss: 0.4284447133541107\n",
      "epoch 10, Batch loss: 0.4035904109477997\n",
      "epoch 10, Batch loss: 0.3447886109352112\n",
      "epoch 10, Batch loss: 0.5482853651046753\n",
      "epoch 10, Batch loss: 0.5438607335090637\n",
      "epoch 10, Batch loss: 0.3771623373031616\n",
      "epoch 10, Batch loss: 0.30705928802490234\n",
      "epoch 10, Batch loss: 0.23769940435886383\n",
      "epoch 10, Batch loss: 0.2092602401971817\n",
      "epoch 10, Batch loss: 0.44996917247772217\n",
      "epoch 10, Batch loss: 0.253787100315094\n",
      "epoch 10, Batch loss: 0.4284220039844513\n",
      "epoch 10, Batch loss: 0.3234563171863556\n",
      "epoch 10, Batch loss: 0.4111001491546631\n",
      "epoch 10, Batch loss: 0.5336967706680298\n",
      "epoch 10, Batch loss: 0.22446639835834503\n",
      "epoch 10, Batch loss: 0.37620067596435547\n",
      "epoch 10, Batch loss: 0.31543707847595215\n",
      "epoch 10, Batch loss: 0.3676672577857971\n",
      "epoch 10, Batch loss: 0.32884931564331055\n",
      "epoch 10, Batch loss: 0.34955036640167236\n",
      "epoch 10, Batch loss: 0.5093831419944763\n",
      "epoch 10, Batch loss: 0.7681519985198975\n",
      "epoch 10, Batch loss: 0.5815966725349426\n",
      "epoch 10, Batch loss: 0.32564422488212585\n",
      "epoch 10, Batch loss: 0.41333335638046265\n",
      "epoch 10, Batch loss: 0.5489363074302673\n",
      "epoch 10, Batch loss: 0.3575659394264221\n",
      "epoch 10, Batch loss: 0.281732976436615\n",
      "epoch 10, Batch loss: 0.27311432361602783\n",
      "epoch 10, Batch loss: 0.3372524380683899\n",
      "epoch 10, Batch loss: 0.4322099983692169\n",
      "epoch 10, Batch loss: 0.41041895747184753\n",
      "epoch 10, Batch loss: 0.4002249240875244\n",
      "epoch 10, Batch loss: 0.334377646446228\n",
      "epoch 10, Batch loss: 0.3909388482570648\n",
      "epoch 10, Batch loss: 0.3759444057941437\n",
      "epoch 10, Batch loss: 0.2456207424402237\n",
      "epoch 10, Batch loss: 0.24867229163646698\n",
      "epoch 10, Batch loss: 0.2827698886394501\n",
      "epoch 10, Batch loss: 0.30166199803352356\n",
      "epoch 10, Batch loss: 0.4164988696575165\n",
      "epoch 10, Batch loss: 0.3957931697368622\n",
      "epoch 10, Batch loss: 0.4300961494445801\n",
      "epoch 10, Batch loss: 0.5010311603546143\n",
      "epoch 10, Batch loss: 0.5707378387451172\n",
      "epoch 10, Batch loss: 0.394915908575058\n",
      "epoch 10, Batch loss: 0.3583245873451233\n",
      "epoch 10, Batch loss: 0.5243980884552002\n",
      "epoch 10, Batch loss: 0.24621933698654175\n",
      "epoch 10, Batch loss: 0.2248523086309433\n",
      "epoch 10, Batch loss: 0.28934168815612793\n",
      "epoch 10, Batch loss: 0.3431359827518463\n",
      "epoch 10, Batch loss: 0.37345650792121887\n",
      "epoch 10, Batch loss: 0.4468514621257782\n",
      "epoch 10, Batch loss: 0.3125374913215637\n",
      "epoch 10, Batch loss: 0.4306575655937195\n",
      "epoch 10, Batch loss: 0.27754756808280945\n",
      "epoch 10, Batch loss: 0.3142971098423004\n",
      "epoch 10, Batch loss: 0.41422879695892334\n",
      "epoch 10, Batch loss: 0.44132527709007263\n",
      "epoch 10, Batch loss: 0.2811616361141205\n",
      "epoch 10, Batch loss: 0.4041379988193512\n",
      "epoch 10, Batch loss: 0.3532273769378662\n",
      "epoch 10, Batch loss: 0.4763488173484802\n",
      "epoch 10, Batch loss: 0.43243587017059326\n",
      "epoch 10, Batch loss: 0.3919530510902405\n",
      "epoch 10, Batch loss: 0.5714073181152344\n",
      "epoch 10, Batch loss: 0.3301622271537781\n",
      "epoch 10, Batch loss: 0.2720341682434082\n",
      "epoch 10, Batch loss: 0.45577919483184814\n",
      "epoch 10, Batch loss: 0.3361733555793762\n",
      "epoch 10, Batch loss: 0.32193633913993835\n",
      "epoch 10, Batch loss: 0.2239244282245636\n",
      "epoch 10, Batch loss: 0.30610546469688416\n",
      "epoch 10, Batch loss: 0.5787436962127686\n",
      "epoch 10, Batch loss: 0.46973875164985657\n",
      "epoch 10, Batch loss: 0.46982696652412415\n",
      "epoch 10, Batch loss: 0.26561805605888367\n",
      "epoch 10, Batch loss: 0.4618097245693207\n",
      "epoch 10, Batch loss: 0.24603626132011414\n",
      "epoch 10, Batch loss: 0.26296988129615784\n",
      "epoch 10, Batch loss: 0.32664936780929565\n",
      "epoch 10, Batch loss: 0.4264611005783081\n",
      "epoch 10, Batch loss: 0.34358906745910645\n",
      "epoch 10, Batch loss: 0.22231674194335938\n",
      "epoch 10, Batch loss: 0.324770987033844\n",
      "epoch 10, Batch loss: 0.2810259163379669\n",
      "epoch 10, Batch loss: 0.489189088344574\n",
      "epoch 10, Batch loss: 0.35068079829216003\n",
      "epoch 10, Batch loss: 0.3399440348148346\n",
      "epoch 10, Batch loss: 0.2336863875389099\n",
      "epoch 10, Batch loss: 0.5968005657196045\n",
      "epoch 10, Batch loss: 0.4954611361026764\n",
      "epoch 10, Batch loss: 0.3680339455604553\n",
      "epoch 10, Batch loss: 0.3074410557746887\n",
      "epoch 10, Batch loss: 0.20152796804904938\n",
      "epoch 10, Batch loss: 0.2976645231246948\n",
      "epoch 10, Batch loss: 0.4618384838104248\n",
      "epoch 10, Batch loss: 0.23588231205940247\n",
      "epoch 10, Batch loss: 0.3149622976779938\n",
      "epoch 10, Batch loss: 0.2646103501319885\n",
      "epoch 10, Batch loss: 0.28741544485092163\n",
      "epoch 10, Batch loss: 0.35130321979522705\n",
      "epoch 10, Batch loss: 0.3660625219345093\n",
      "epoch 10, Batch loss: 0.357543408870697\n",
      "epoch 10, Batch loss: 0.3966989815235138\n",
      "epoch 10, Batch loss: 0.37231966853141785\n",
      "epoch 10, Batch loss: 0.4235815703868866\n",
      "epoch 10, Batch loss: 0.580249011516571\n",
      "epoch 10, Batch loss: 0.3930606544017792\n",
      "epoch 10, Batch loss: 0.2935231626033783\n",
      "epoch 10, Batch loss: 0.33860206604003906\n",
      "epoch 10, Batch loss: 0.23792114853858948\n",
      "epoch 10, Batch loss: 0.352115273475647\n",
      "epoch 10, Batch loss: 0.5028831958770752\n",
      "epoch 10, Batch loss: 0.2733995318412781\n",
      "epoch 11, Batch loss: 0.6387801766395569\n",
      "epoch 11, Batch loss: 0.37088897824287415\n",
      "epoch 11, Batch loss: 0.5759211182594299\n",
      "epoch 11, Batch loss: 0.3415694236755371\n",
      "epoch 11, Batch loss: 0.3610145151615143\n",
      "epoch 11, Batch loss: 0.32020843029022217\n",
      "epoch 11, Batch loss: 0.23952753841876984\n",
      "epoch 11, Batch loss: 0.33795803785324097\n",
      "epoch 11, Batch loss: 0.24442826211452484\n",
      "epoch 11, Batch loss: 0.2785901129245758\n",
      "epoch 11, Batch loss: 0.2910047769546509\n",
      "epoch 11, Batch loss: 0.27173981070518494\n",
      "epoch 11, Batch loss: 0.4961407780647278\n",
      "epoch 11, Batch loss: 0.2811771035194397\n",
      "epoch 11, Batch loss: 0.3694601058959961\n",
      "epoch 11, Batch loss: 0.43557479977607727\n",
      "epoch 11, Batch loss: 0.29583632946014404\n",
      "epoch 11, Batch loss: 0.2645728588104248\n",
      "epoch 11, Batch loss: 0.2976473271846771\n",
      "epoch 11, Batch loss: 0.3875083923339844\n",
      "epoch 11, Batch loss: 0.17754173278808594\n",
      "epoch 11, Batch loss: 0.24610507488250732\n",
      "epoch 11, Batch loss: 0.2773987352848053\n",
      "epoch 11, Batch loss: 0.31059885025024414\n",
      "epoch 11, Batch loss: 0.4647780656814575\n",
      "epoch 11, Batch loss: 0.5465761423110962\n",
      "epoch 11, Batch loss: 0.46035245060920715\n",
      "epoch 11, Batch loss: 0.21681274473667145\n",
      "epoch 11, Batch loss: 0.4199976325035095\n",
      "epoch 11, Batch loss: 0.49704790115356445\n",
      "epoch 11, Batch loss: 0.27877020835876465\n",
      "epoch 11, Batch loss: 0.2992526888847351\n",
      "epoch 11, Batch loss: 0.5598486065864563\n",
      "epoch 11, Batch loss: 0.339058518409729\n",
      "epoch 11, Batch loss: 0.35869818925857544\n",
      "epoch 11, Batch loss: 0.6463383436203003\n",
      "epoch 11, Batch loss: 0.2977539896965027\n",
      "epoch 11, Batch loss: 0.48119738698005676\n",
      "epoch 11, Batch loss: 0.4696793556213379\n",
      "epoch 11, Batch loss: 0.21918080747127533\n",
      "epoch 11, Batch loss: 0.5488384962081909\n",
      "epoch 11, Batch loss: 0.5123763084411621\n",
      "epoch 11, Batch loss: 0.4621241092681885\n",
      "epoch 11, Batch loss: 0.3457789421081543\n",
      "epoch 11, Batch loss: 0.21898990869522095\n",
      "epoch 11, Batch loss: 0.7619270086288452\n",
      "epoch 11, Batch loss: 0.46292710304260254\n",
      "epoch 11, Batch loss: 0.44915086030960083\n",
      "epoch 11, Batch loss: 0.3741086721420288\n",
      "epoch 11, Batch loss: 0.25649020075798035\n",
      "epoch 11, Batch loss: 0.3255944848060608\n",
      "epoch 11, Batch loss: 0.3698035180568695\n",
      "epoch 11, Batch loss: 0.2749578654766083\n",
      "epoch 11, Batch loss: 0.5368712544441223\n",
      "epoch 11, Batch loss: 0.27170783281326294\n",
      "epoch 11, Batch loss: 0.26262062788009644\n",
      "epoch 11, Batch loss: 0.2670604884624481\n",
      "epoch 11, Batch loss: 0.3430393636226654\n",
      "epoch 11, Batch loss: 0.19167810678482056\n",
      "epoch 11, Batch loss: 0.32791033387184143\n",
      "epoch 11, Batch loss: 0.2821231186389923\n",
      "epoch 11, Batch loss: 0.3378426134586334\n",
      "epoch 11, Batch loss: 0.3884952664375305\n",
      "epoch 11, Batch loss: 0.3250042796134949\n",
      "epoch 11, Batch loss: 0.3278409242630005\n",
      "epoch 11, Batch loss: 0.4930405914783478\n",
      "epoch 11, Batch loss: 0.3778607249259949\n",
      "epoch 11, Batch loss: 0.403847873210907\n",
      "epoch 11, Batch loss: 0.3383439779281616\n",
      "epoch 11, Batch loss: 0.3930411636829376\n",
      "epoch 11, Batch loss: 0.22003071010112762\n",
      "epoch 11, Batch loss: 0.28494736552238464\n",
      "epoch 11, Batch loss: 0.25232642889022827\n",
      "epoch 11, Batch loss: 0.39957723021507263\n",
      "epoch 11, Batch loss: 0.3802737593650818\n",
      "epoch 11, Batch loss: 0.22142300009727478\n",
      "epoch 11, Batch loss: 0.3175785541534424\n",
      "epoch 11, Batch loss: 0.30921047925949097\n",
      "epoch 11, Batch loss: 0.34550660848617554\n",
      "epoch 11, Batch loss: 0.20592118799686432\n",
      "epoch 11, Batch loss: 0.4655264914035797\n",
      "epoch 11, Batch loss: 0.32932567596435547\n",
      "epoch 11, Batch loss: 0.22243990004062653\n",
      "epoch 11, Batch loss: 0.4199874997138977\n",
      "epoch 11, Batch loss: 0.3451972007751465\n",
      "epoch 11, Batch loss: 0.3291228115558624\n",
      "epoch 11, Batch loss: 0.42673709988594055\n",
      "epoch 11, Batch loss: 0.4821043014526367\n",
      "epoch 11, Batch loss: 0.34966734051704407\n",
      "epoch 11, Batch loss: 0.22411055862903595\n",
      "epoch 11, Batch loss: 0.20841386914253235\n",
      "epoch 11, Batch loss: 0.4063361585140228\n",
      "epoch 11, Batch loss: 0.3002648651599884\n",
      "epoch 11, Batch loss: 0.20914757251739502\n",
      "epoch 11, Batch loss: 0.40102386474609375\n",
      "epoch 11, Batch loss: 0.40458938479423523\n",
      "epoch 11, Batch loss: 0.4251512885093689\n",
      "epoch 11, Batch loss: 0.3919357657432556\n",
      "epoch 11, Batch loss: 0.24379180371761322\n",
      "epoch 11, Batch loss: 0.29809239506721497\n",
      "epoch 11, Batch loss: 0.42165708541870117\n",
      "epoch 11, Batch loss: 0.37624651193618774\n",
      "epoch 11, Batch loss: 0.4524264931678772\n",
      "epoch 11, Batch loss: 0.7049510478973389\n",
      "epoch 11, Batch loss: 0.5145483613014221\n",
      "epoch 11, Batch loss: 0.7285088300704956\n",
      "epoch 11, Batch loss: 0.3093186020851135\n",
      "epoch 11, Batch loss: 0.4580704867839813\n",
      "epoch 11, Batch loss: 0.2912844121456146\n",
      "epoch 11, Batch loss: 0.2493799328804016\n",
      "epoch 11, Batch loss: 0.24749809503555298\n",
      "epoch 11, Batch loss: 0.30266574025154114\n",
      "epoch 11, Batch loss: 0.32559680938720703\n",
      "epoch 11, Batch loss: 0.22739094495773315\n",
      "epoch 11, Batch loss: 0.3660242259502411\n",
      "epoch 11, Batch loss: 0.38182392716407776\n",
      "epoch 11, Batch loss: 0.3362810015678406\n",
      "epoch 11, Batch loss: 0.5537049770355225\n",
      "epoch 11, Batch loss: 0.4542163014411926\n",
      "epoch 11, Batch loss: 0.3463073670864105\n",
      "epoch 11, Batch loss: 0.2906898856163025\n",
      "epoch 11, Batch loss: 0.49333399534225464\n",
      "epoch 11, Batch loss: 0.4322524070739746\n",
      "epoch 11, Batch loss: 0.35787710547447205\n",
      "epoch 11, Batch loss: 0.22796086966991425\n",
      "epoch 12, Batch loss: 0.312563955783844\n",
      "epoch 12, Batch loss: 0.352455198764801\n",
      "epoch 12, Batch loss: 0.4026142656803131\n",
      "epoch 12, Batch loss: 0.4939369857311249\n",
      "epoch 12, Batch loss: 0.3317309617996216\n",
      "epoch 12, Batch loss: 0.26085716485977173\n",
      "epoch 12, Batch loss: 0.24624992907047272\n",
      "epoch 12, Batch loss: 0.3106984496116638\n",
      "epoch 12, Batch loss: 0.3556857109069824\n",
      "epoch 12, Batch loss: 0.402592271566391\n",
      "epoch 12, Batch loss: 0.1971060186624527\n",
      "epoch 12, Batch loss: 0.40748918056488037\n",
      "epoch 12, Batch loss: 0.3580465018749237\n",
      "epoch 12, Batch loss: 0.32668882608413696\n",
      "epoch 12, Batch loss: 0.3187161684036255\n",
      "epoch 12, Batch loss: 0.30375465750694275\n",
      "epoch 12, Batch loss: 0.32352548837661743\n",
      "epoch 12, Batch loss: 0.37295931577682495\n",
      "epoch 12, Batch loss: 0.38754233717918396\n",
      "epoch 12, Batch loss: 0.318489670753479\n",
      "epoch 12, Batch loss: 0.3834378719329834\n",
      "epoch 12, Batch loss: 0.2901381254196167\n",
      "epoch 12, Batch loss: 0.25941962003707886\n",
      "epoch 12, Batch loss: 0.3572329580783844\n",
      "epoch 12, Batch loss: 0.2376680076122284\n",
      "epoch 12, Batch loss: 0.3584286868572235\n",
      "epoch 12, Batch loss: 0.4543553292751312\n",
      "epoch 12, Batch loss: 0.5639287233352661\n",
      "epoch 12, Batch loss: 0.20266443490982056\n",
      "epoch 12, Batch loss: 0.3053053617477417\n",
      "epoch 12, Batch loss: 0.5161840915679932\n",
      "epoch 12, Batch loss: 0.34947407245635986\n",
      "epoch 12, Batch loss: 0.27726900577545166\n",
      "epoch 12, Batch loss: 0.23911696672439575\n",
      "epoch 12, Batch loss: 0.14829139411449432\n",
      "epoch 12, Batch loss: 0.35974130034446716\n",
      "epoch 12, Batch loss: 0.31311875581741333\n",
      "epoch 12, Batch loss: 0.569412887096405\n",
      "epoch 12, Batch loss: 0.3140624165534973\n",
      "epoch 12, Batch loss: 0.3205384910106659\n",
      "epoch 12, Batch loss: 0.32813385128974915\n",
      "epoch 12, Batch loss: 0.26966944336891174\n",
      "epoch 12, Batch loss: 0.23935824632644653\n",
      "epoch 12, Batch loss: 0.50644850730896\n",
      "epoch 12, Batch loss: 0.43086856603622437\n",
      "epoch 12, Batch loss: 0.32789790630340576\n",
      "epoch 12, Batch loss: 0.24151089787483215\n",
      "epoch 12, Batch loss: 0.3905712962150574\n",
      "epoch 12, Batch loss: 0.43273013830184937\n",
      "epoch 12, Batch loss: 0.3130427598953247\n",
      "epoch 12, Batch loss: 0.3074435591697693\n",
      "epoch 12, Batch loss: 0.42288634181022644\n",
      "epoch 12, Batch loss: 0.4477689266204834\n",
      "epoch 12, Batch loss: 0.46678027510643005\n",
      "epoch 12, Batch loss: 0.3153960406780243\n",
      "epoch 12, Batch loss: 0.5017881989479065\n",
      "epoch 12, Batch loss: 0.21777954697608948\n",
      "epoch 12, Batch loss: 0.21234411001205444\n",
      "epoch 12, Batch loss: 0.3688645660877228\n",
      "epoch 12, Batch loss: 0.30274975299835205\n",
      "epoch 12, Batch loss: 0.2609666883945465\n",
      "epoch 12, Batch loss: 0.40206584334373474\n",
      "epoch 12, Batch loss: 0.25552862882614136\n",
      "epoch 12, Batch loss: 0.3003810942173004\n",
      "epoch 12, Batch loss: 0.3279291093349457\n",
      "epoch 12, Batch loss: 0.25275173783302307\n",
      "epoch 12, Batch loss: 0.558264970779419\n",
      "epoch 12, Batch loss: 0.4696345925331116\n",
      "epoch 12, Batch loss: 0.3906208276748657\n",
      "epoch 12, Batch loss: 0.2693954110145569\n",
      "epoch 12, Batch loss: 0.5704559087753296\n",
      "epoch 12, Batch loss: 0.43475568294525146\n",
      "epoch 12, Batch loss: 0.32588160037994385\n",
      "epoch 12, Batch loss: 0.31180235743522644\n",
      "epoch 12, Batch loss: 0.32665014266967773\n",
      "epoch 12, Batch loss: 0.14703741669654846\n",
      "epoch 12, Batch loss: 0.31534966826438904\n",
      "epoch 12, Batch loss: 0.36283451318740845\n",
      "epoch 12, Batch loss: 0.39144453406333923\n",
      "epoch 12, Batch loss: 0.34894540905952454\n",
      "epoch 12, Batch loss: 0.5479758381843567\n",
      "epoch 12, Batch loss: 0.5010108947753906\n",
      "epoch 12, Batch loss: 0.3249329626560211\n",
      "epoch 12, Batch loss: 0.4413646161556244\n",
      "epoch 12, Batch loss: 0.47629308700561523\n",
      "epoch 12, Batch loss: 0.3123428225517273\n",
      "epoch 12, Batch loss: 0.438242644071579\n",
      "epoch 12, Batch loss: 0.27089932560920715\n",
      "epoch 12, Batch loss: 0.3893321752548218\n",
      "epoch 12, Batch loss: 0.46409371495246887\n",
      "epoch 12, Batch loss: 0.34030264616012573\n",
      "epoch 12, Batch loss: 0.31217584013938904\n",
      "epoch 12, Batch loss: 0.336999773979187\n",
      "epoch 12, Batch loss: 0.3548843562602997\n",
      "epoch 12, Batch loss: 0.4316973388195038\n",
      "epoch 12, Batch loss: 0.2157995104789734\n",
      "epoch 12, Batch loss: 0.32958266139030457\n",
      "epoch 12, Batch loss: 0.38863247632980347\n",
      "epoch 12, Batch loss: 0.5160771608352661\n",
      "epoch 12, Batch loss: 0.29976218938827515\n",
      "epoch 12, Batch loss: 0.2800867557525635\n",
      "epoch 12, Batch loss: 0.541127622127533\n",
      "epoch 12, Batch loss: 0.29103970527648926\n",
      "epoch 12, Batch loss: 0.33131057024002075\n",
      "epoch 12, Batch loss: 0.2744497060775757\n",
      "epoch 12, Batch loss: 0.24568520486354828\n",
      "epoch 12, Batch loss: 0.2792308032512665\n",
      "epoch 12, Batch loss: 0.17114762961864471\n",
      "epoch 12, Batch loss: 0.3383149802684784\n",
      "epoch 12, Batch loss: 0.7034090161323547\n",
      "epoch 12, Batch loss: 0.6132978200912476\n",
      "epoch 12, Batch loss: 0.3038208782672882\n",
      "epoch 12, Batch loss: 0.4726194441318512\n",
      "epoch 12, Batch loss: 0.3298719823360443\n",
      "epoch 12, Batch loss: 0.5100278258323669\n",
      "epoch 12, Batch loss: 0.34528592228889465\n",
      "epoch 12, Batch loss: 0.2813294231891632\n",
      "epoch 12, Batch loss: 0.4212028980255127\n",
      "epoch 12, Batch loss: 0.23872870206832886\n",
      "epoch 12, Batch loss: 0.25817203521728516\n",
      "epoch 12, Batch loss: 0.4077697694301605\n",
      "epoch 12, Batch loss: 0.2648957669734955\n",
      "epoch 12, Batch loss: 0.2966063916683197\n",
      "epoch 12, Batch loss: 0.3780565857887268\n",
      "epoch 12, Batch loss: 0.40411216020584106\n",
      "epoch 13, Batch loss: 0.18599677085876465\n",
      "epoch 13, Batch loss: 0.347320556640625\n",
      "epoch 13, Batch loss: 0.46684566140174866\n",
      "epoch 13, Batch loss: 0.4598158299922943\n",
      "epoch 13, Batch loss: 0.33354270458221436\n",
      "epoch 13, Batch loss: 0.2986069619655609\n",
      "epoch 13, Batch loss: 0.3405049443244934\n",
      "epoch 13, Batch loss: 0.4359743893146515\n",
      "epoch 13, Batch loss: 0.3954659104347229\n",
      "epoch 13, Batch loss: 0.23559485375881195\n",
      "epoch 13, Batch loss: 0.28999266028404236\n",
      "epoch 13, Batch loss: 0.2653633654117584\n",
      "epoch 13, Batch loss: 0.2729136645793915\n",
      "epoch 13, Batch loss: 0.32083776593208313\n",
      "epoch 13, Batch loss: 0.32015034556388855\n",
      "epoch 13, Batch loss: 0.38202542066574097\n",
      "epoch 13, Batch loss: 0.2554813027381897\n",
      "epoch 13, Batch loss: 0.2576907277107239\n",
      "epoch 13, Batch loss: 0.2349209040403366\n",
      "epoch 13, Batch loss: 0.25160306692123413\n",
      "epoch 13, Batch loss: 0.3077361583709717\n",
      "epoch 13, Batch loss: 0.3792745769023895\n",
      "epoch 13, Batch loss: 0.4900868237018585\n",
      "epoch 13, Batch loss: 0.4143420159816742\n",
      "epoch 13, Batch loss: 0.30034518241882324\n",
      "epoch 13, Batch loss: 0.3425160348415375\n",
      "epoch 13, Batch loss: 0.4979345202445984\n",
      "epoch 13, Batch loss: 0.29817262291908264\n",
      "epoch 13, Batch loss: 0.23250441253185272\n",
      "epoch 13, Batch loss: 0.45287856459617615\n",
      "epoch 13, Batch loss: 0.3546527624130249\n",
      "epoch 13, Batch loss: 0.48036274313926697\n",
      "epoch 13, Batch loss: 0.4051870107650757\n",
      "epoch 13, Batch loss: 0.3782525062561035\n",
      "epoch 13, Batch loss: 0.359858900308609\n",
      "epoch 13, Batch loss: 0.3541385531425476\n",
      "epoch 13, Batch loss: 0.25441327691078186\n",
      "epoch 13, Batch loss: 0.583544135093689\n",
      "epoch 13, Batch loss: 0.3986673653125763\n",
      "epoch 13, Batch loss: 0.28248804807662964\n",
      "epoch 13, Batch loss: 0.26395800709724426\n",
      "epoch 13, Batch loss: 0.5897372364997864\n",
      "epoch 13, Batch loss: 0.29514601826667786\n",
      "epoch 13, Batch loss: 0.37573179602622986\n",
      "epoch 13, Batch loss: 0.17828083038330078\n",
      "epoch 13, Batch loss: 0.32741108536720276\n",
      "epoch 13, Batch loss: 0.44708406925201416\n",
      "epoch 13, Batch loss: 0.382513165473938\n",
      "epoch 13, Batch loss: 0.4702335000038147\n",
      "epoch 13, Batch loss: 0.4659639000892639\n",
      "epoch 13, Batch loss: 0.35482287406921387\n",
      "epoch 13, Batch loss: 0.4520077109336853\n",
      "epoch 13, Batch loss: 0.19739484786987305\n",
      "epoch 13, Batch loss: 0.4475756287574768\n",
      "epoch 13, Batch loss: 0.34882864356040955\n",
      "epoch 13, Batch loss: 0.6253990530967712\n",
      "epoch 13, Batch loss: 0.2534950375556946\n",
      "epoch 13, Batch loss: 0.3461616337299347\n",
      "epoch 13, Batch loss: 0.2744838297367096\n",
      "epoch 13, Batch loss: 0.45506805181503296\n",
      "epoch 13, Batch loss: 0.3973389267921448\n",
      "epoch 13, Batch loss: 0.5128042697906494\n",
      "epoch 13, Batch loss: 0.3499264419078827\n",
      "epoch 13, Batch loss: 0.42187145352363586\n",
      "epoch 13, Batch loss: 0.41066813468933105\n",
      "epoch 13, Batch loss: 0.40611669421195984\n",
      "epoch 13, Batch loss: 0.2778124511241913\n",
      "epoch 13, Batch loss: 0.1960807740688324\n",
      "epoch 13, Batch loss: 0.3156689703464508\n",
      "epoch 13, Batch loss: 0.4593496024608612\n",
      "epoch 13, Batch loss: 0.40858617424964905\n",
      "epoch 13, Batch loss: 0.3106172978878021\n",
      "epoch 13, Batch loss: 0.24255892634391785\n",
      "epoch 13, Batch loss: 0.454110711812973\n",
      "epoch 13, Batch loss: 0.323487251996994\n",
      "epoch 13, Batch loss: 0.31725379824638367\n",
      "epoch 13, Batch loss: 0.2667999267578125\n",
      "epoch 13, Batch loss: 0.23645438253879547\n",
      "epoch 13, Batch loss: 0.27420440316200256\n",
      "epoch 13, Batch loss: 0.3802734911441803\n",
      "epoch 13, Batch loss: 0.477028489112854\n",
      "epoch 13, Batch loss: 0.21375763416290283\n",
      "epoch 13, Batch loss: 0.23118944466114044\n",
      "epoch 13, Batch loss: 0.2192542403936386\n",
      "epoch 13, Batch loss: 0.40542393922805786\n",
      "epoch 13, Batch loss: 0.45897993445396423\n",
      "epoch 13, Batch loss: 0.38201940059661865\n",
      "epoch 13, Batch loss: 0.2611885368824005\n",
      "epoch 13, Batch loss: 0.4088606834411621\n",
      "epoch 13, Batch loss: 0.3690609037876129\n",
      "epoch 13, Batch loss: 0.23343537747859955\n",
      "epoch 13, Batch loss: 0.22172696888446808\n",
      "epoch 13, Batch loss: 0.39453914761543274\n",
      "epoch 13, Batch loss: 0.2827279567718506\n",
      "epoch 13, Batch loss: 0.33047157526016235\n",
      "epoch 13, Batch loss: 0.649199903011322\n",
      "epoch 13, Batch loss: 0.29117581248283386\n",
      "epoch 13, Batch loss: 0.3498404920101166\n",
      "epoch 13, Batch loss: 0.5225679874420166\n",
      "epoch 13, Batch loss: 0.29607030749320984\n",
      "epoch 13, Batch loss: 0.1899905651807785\n",
      "epoch 13, Batch loss: 0.38609015941619873\n",
      "epoch 13, Batch loss: 0.1703217774629593\n",
      "epoch 13, Batch loss: 0.21324488520622253\n",
      "epoch 13, Batch loss: 0.25218912959098816\n",
      "epoch 13, Batch loss: 0.29124751687049866\n",
      "epoch 13, Batch loss: 0.24713234603405\n",
      "epoch 13, Batch loss: 0.37644705176353455\n",
      "epoch 13, Batch loss: 0.48345834016799927\n",
      "epoch 13, Batch loss: 0.31719130277633667\n",
      "epoch 13, Batch loss: 0.25603291392326355\n",
      "epoch 13, Batch loss: 0.22519120573997498\n",
      "epoch 13, Batch loss: 0.43583032488822937\n",
      "epoch 13, Batch loss: 0.23757539689540863\n",
      "epoch 13, Batch loss: 0.4579957127571106\n",
      "epoch 13, Batch loss: 0.23298804461956024\n",
      "epoch 13, Batch loss: 0.34393492341041565\n",
      "epoch 13, Batch loss: 0.35112956166267395\n",
      "epoch 13, Batch loss: 0.23457688093185425\n",
      "epoch 13, Batch loss: 0.3485174775123596\n",
      "epoch 13, Batch loss: 0.3810223340988159\n",
      "epoch 13, Batch loss: 0.2660350203514099\n",
      "epoch 13, Batch loss: 0.32307103276252747\n",
      "epoch 13, Batch loss: 0.49037861824035645\n",
      "epoch 13, Batch loss: 0.4374946355819702\n",
      "epoch 14, Batch loss: 0.7288162112236023\n",
      "epoch 14, Batch loss: 0.5222741365432739\n",
      "epoch 14, Batch loss: 0.41971835494041443\n",
      "epoch 14, Batch loss: 0.26600170135498047\n",
      "epoch 14, Batch loss: 0.28855767846107483\n",
      "epoch 14, Batch loss: 0.42323750257492065\n",
      "epoch 14, Batch loss: 0.3686502277851105\n",
      "epoch 14, Batch loss: 0.41603943705558777\n",
      "epoch 14, Batch loss: 0.2879846692085266\n",
      "epoch 14, Batch loss: 0.25126025080680847\n",
      "epoch 14, Batch loss: 0.2780303955078125\n",
      "epoch 14, Batch loss: 0.2688303291797638\n",
      "epoch 14, Batch loss: 0.26750099658966064\n",
      "epoch 14, Batch loss: 0.2605467140674591\n",
      "epoch 14, Batch loss: 0.31725209951400757\n",
      "epoch 14, Batch loss: 0.22616949677467346\n",
      "epoch 14, Batch loss: 0.21298499405384064\n",
      "epoch 14, Batch loss: 0.34416064620018005\n",
      "epoch 14, Batch loss: 0.35068225860595703\n",
      "epoch 14, Batch loss: 0.4743802547454834\n",
      "epoch 14, Batch loss: 0.43525078892707825\n",
      "epoch 14, Batch loss: 0.340045690536499\n",
      "epoch 14, Batch loss: 0.4410970211029053\n",
      "epoch 14, Batch loss: 0.3370511531829834\n",
      "epoch 14, Batch loss: 0.27988681197166443\n",
      "epoch 14, Batch loss: 0.30817389488220215\n",
      "epoch 14, Batch loss: 0.2802571654319763\n",
      "epoch 14, Batch loss: 0.4236011207103729\n",
      "epoch 14, Batch loss: 0.18382713198661804\n",
      "epoch 14, Batch loss: 0.19237014651298523\n",
      "epoch 14, Batch loss: 0.5115855932235718\n",
      "epoch 14, Batch loss: 0.46869102120399475\n",
      "epoch 14, Batch loss: 0.22976483404636383\n",
      "epoch 14, Batch loss: 0.25409001111984253\n",
      "epoch 14, Batch loss: 0.474750280380249\n",
      "epoch 14, Batch loss: 0.47823962569236755\n",
      "epoch 14, Batch loss: 0.39923471212387085\n",
      "epoch 14, Batch loss: 0.48588985204696655\n",
      "epoch 14, Batch loss: 0.28260156512260437\n",
      "epoch 14, Batch loss: 0.2792298197746277\n",
      "epoch 14, Batch loss: 0.21409912407398224\n",
      "epoch 14, Batch loss: 0.27973154187202454\n",
      "epoch 14, Batch loss: 0.287035197019577\n",
      "epoch 14, Batch loss: 0.4558103680610657\n",
      "epoch 14, Batch loss: 0.2971831262111664\n",
      "epoch 14, Batch loss: 0.36531078815460205\n",
      "epoch 14, Batch loss: 0.2117326557636261\n",
      "epoch 14, Batch loss: 0.3805888891220093\n",
      "epoch 14, Batch loss: 0.146083801984787\n",
      "epoch 14, Batch loss: 0.34211382269859314\n",
      "epoch 14, Batch loss: 0.27891844511032104\n",
      "epoch 14, Batch loss: 0.3521519601345062\n",
      "epoch 14, Batch loss: 0.28533342480659485\n",
      "epoch 14, Batch loss: 0.37824419140815735\n",
      "epoch 14, Batch loss: 0.2755677103996277\n",
      "epoch 14, Batch loss: 0.18425370752811432\n",
      "epoch 14, Batch loss: 0.31372374296188354\n",
      "epoch 14, Batch loss: 0.33721569180488586\n",
      "epoch 14, Batch loss: 0.5131916999816895\n",
      "epoch 14, Batch loss: 0.2841300964355469\n",
      "epoch 14, Batch loss: 0.44690197706222534\n",
      "epoch 14, Batch loss: 0.31001511216163635\n",
      "epoch 14, Batch loss: 0.7094912528991699\n",
      "epoch 14, Batch loss: 0.3158852458000183\n",
      "epoch 14, Batch loss: 0.25558552145957947\n",
      "epoch 14, Batch loss: 0.3772999346256256\n",
      "epoch 14, Batch loss: 0.39557093381881714\n",
      "epoch 14, Batch loss: 0.29922008514404297\n",
      "epoch 14, Batch loss: 0.21890072524547577\n",
      "epoch 14, Batch loss: 0.3792437016963959\n",
      "epoch 14, Batch loss: 0.20405857264995575\n",
      "epoch 14, Batch loss: 0.23238444328308105\n",
      "epoch 14, Batch loss: 0.25335052609443665\n",
      "epoch 14, Batch loss: 0.2900198698043823\n",
      "epoch 14, Batch loss: 0.361714631319046\n",
      "epoch 14, Batch loss: 0.40147140622138977\n",
      "epoch 14, Batch loss: 0.2245871126651764\n",
      "epoch 14, Batch loss: 0.4194870591163635\n",
      "epoch 14, Batch loss: 0.2814444899559021\n",
      "epoch 14, Batch loss: 0.334001362323761\n",
      "epoch 14, Batch loss: 0.5594608187675476\n",
      "epoch 14, Batch loss: 0.5050031542778015\n",
      "epoch 14, Batch loss: 0.36353951692581177\n",
      "epoch 14, Batch loss: 0.3707316219806671\n",
      "epoch 14, Batch loss: 0.3473859429359436\n",
      "epoch 14, Batch loss: 0.25925660133361816\n",
      "epoch 14, Batch loss: 0.3239879012107849\n",
      "epoch 14, Batch loss: 0.37644264101982117\n",
      "epoch 14, Batch loss: 0.38988757133483887\n",
      "epoch 14, Batch loss: 0.27727988362312317\n",
      "epoch 14, Batch loss: 0.3103448152542114\n",
      "epoch 14, Batch loss: 0.2173386514186859\n",
      "epoch 14, Batch loss: 0.23787783086299896\n",
      "epoch 14, Batch loss: 0.2750542461872101\n",
      "epoch 14, Batch loss: 0.5202311873435974\n",
      "epoch 14, Batch loss: 0.2997087836265564\n",
      "epoch 14, Batch loss: 0.31547990441322327\n",
      "epoch 14, Batch loss: 0.2798457443714142\n",
      "epoch 14, Batch loss: 0.44384485483169556\n",
      "epoch 14, Batch loss: 0.4056420624256134\n",
      "epoch 14, Batch loss: 0.32074007391929626\n",
      "epoch 14, Batch loss: 0.24081046879291534\n",
      "epoch 14, Batch loss: 0.2850939929485321\n",
      "epoch 14, Batch loss: 0.4075125455856323\n",
      "epoch 14, Batch loss: 0.2803781032562256\n",
      "epoch 14, Batch loss: 0.25536635518074036\n",
      "epoch 14, Batch loss: 0.27174490690231323\n",
      "epoch 14, Batch loss: 0.4306250512599945\n",
      "epoch 14, Batch loss: 0.25653064250946045\n",
      "epoch 14, Batch loss: 0.30896830558776855\n",
      "epoch 14, Batch loss: 0.33520272374153137\n",
      "epoch 14, Batch loss: 0.28077834844589233\n",
      "epoch 14, Batch loss: 0.40657147765159607\n",
      "epoch 14, Batch loss: 0.2948997914791107\n",
      "epoch 14, Batch loss: 0.3529750108718872\n",
      "epoch 14, Batch loss: 0.43729814887046814\n",
      "epoch 14, Batch loss: 0.47416821122169495\n",
      "epoch 14, Batch loss: 0.2095167636871338\n",
      "epoch 14, Batch loss: 0.27188825607299805\n",
      "epoch 14, Batch loss: 0.2550489604473114\n",
      "epoch 14, Batch loss: 0.40997129678726196\n",
      "epoch 14, Batch loss: 0.4980107843875885\n",
      "epoch 14, Batch loss: 0.3537306487560272\n",
      "epoch 14, Batch loss: 0.35749804973602295\n",
      "epoch 14, Batch loss: 0.38626983761787415\n",
      "epoch 15, Batch loss: 0.3395717740058899\n",
      "epoch 15, Batch loss: 0.29410040378570557\n",
      "epoch 15, Batch loss: 0.3707420229911804\n",
      "epoch 15, Batch loss: 0.2702638804912567\n",
      "epoch 15, Batch loss: 0.39782580733299255\n",
      "epoch 15, Batch loss: 0.2532491385936737\n",
      "epoch 15, Batch loss: 0.32613134384155273\n",
      "epoch 15, Batch loss: 0.2699437141418457\n",
      "epoch 15, Batch loss: 0.23484334349632263\n",
      "epoch 15, Batch loss: 0.42722588777542114\n",
      "epoch 15, Batch loss: 0.22929935157299042\n",
      "epoch 15, Batch loss: 0.22279901802539825\n",
      "epoch 15, Batch loss: 0.24909242987632751\n",
      "epoch 15, Batch loss: 0.2550200819969177\n",
      "epoch 15, Batch loss: 0.26668715476989746\n",
      "epoch 15, Batch loss: 0.35022979974746704\n",
      "epoch 15, Batch loss: 0.28802022337913513\n",
      "epoch 15, Batch loss: 0.17755170166492462\n",
      "epoch 15, Batch loss: 0.23270533978939056\n",
      "epoch 15, Batch loss: 0.3933025896549225\n",
      "epoch 15, Batch loss: 0.3658481538295746\n",
      "epoch 15, Batch loss: 0.23940207064151764\n",
      "epoch 15, Batch loss: 0.3421412706375122\n",
      "epoch 15, Batch loss: 0.4319184720516205\n",
      "epoch 15, Batch loss: 0.3333680331707001\n",
      "epoch 15, Batch loss: 0.4005230963230133\n",
      "epoch 15, Batch loss: 0.21108075976371765\n",
      "epoch 15, Batch loss: 0.6424463987350464\n",
      "epoch 15, Batch loss: 0.35049134492874146\n",
      "epoch 15, Batch loss: 0.32400843501091003\n",
      "epoch 15, Batch loss: 0.41334912180900574\n",
      "epoch 15, Batch loss: 0.20429809391498566\n",
      "epoch 15, Batch loss: 0.32901689410209656\n",
      "epoch 15, Batch loss: 0.2469877153635025\n",
      "epoch 15, Batch loss: 0.2440808117389679\n",
      "epoch 15, Batch loss: 0.31423380970954895\n",
      "epoch 15, Batch loss: 0.276265025138855\n",
      "epoch 15, Batch loss: 0.5699992775917053\n",
      "epoch 15, Batch loss: 0.2881239950656891\n",
      "epoch 15, Batch loss: 0.5364820957183838\n",
      "epoch 15, Batch loss: 0.18594679236412048\n",
      "epoch 15, Batch loss: 0.253479927778244\n",
      "epoch 15, Batch loss: 0.7496136426925659\n",
      "epoch 15, Batch loss: 0.25156161189079285\n",
      "epoch 15, Batch loss: 0.5964105725288391\n",
      "epoch 15, Batch loss: 0.33823466300964355\n",
      "epoch 15, Batch loss: 0.3198280930519104\n",
      "epoch 15, Batch loss: 0.19870036840438843\n",
      "epoch 15, Batch loss: 0.378162682056427\n",
      "epoch 15, Batch loss: 0.15491929650306702\n",
      "epoch 15, Batch loss: 0.30104586482048035\n",
      "epoch 15, Batch loss: 0.280592143535614\n",
      "epoch 15, Batch loss: 0.3443721532821655\n",
      "epoch 15, Batch loss: 0.4148520529270172\n",
      "epoch 15, Batch loss: 0.26907843351364136\n",
      "epoch 15, Batch loss: 0.3194527328014374\n",
      "epoch 15, Batch loss: 0.6117634773254395\n",
      "epoch 15, Batch loss: 0.2558872401714325\n",
      "epoch 15, Batch loss: 0.4272145628929138\n",
      "epoch 15, Batch loss: 0.3020387291908264\n",
      "epoch 15, Batch loss: 0.27896201610565186\n",
      "epoch 15, Batch loss: 0.288595050573349\n",
      "epoch 15, Batch loss: 0.24025066196918488\n",
      "epoch 15, Batch loss: 0.3586142361164093\n",
      "epoch 15, Batch loss: 0.32072561979293823\n",
      "epoch 15, Batch loss: 0.6997416615486145\n",
      "epoch 15, Batch loss: 0.3614905774593353\n",
      "epoch 15, Batch loss: 0.3581765592098236\n",
      "epoch 15, Batch loss: 0.28378957509994507\n",
      "epoch 15, Batch loss: 0.36003318428993225\n",
      "epoch 15, Batch loss: 0.4185584783554077\n",
      "epoch 15, Batch loss: 0.1533762663602829\n",
      "epoch 15, Batch loss: 0.306702196598053\n",
      "epoch 15, Batch loss: 0.27360057830810547\n",
      "epoch 15, Batch loss: 0.4264659583568573\n",
      "epoch 15, Batch loss: 0.2008352130651474\n",
      "epoch 15, Batch loss: 0.3499053716659546\n",
      "epoch 15, Batch loss: 0.3869398236274719\n",
      "epoch 15, Batch loss: 0.32166966795921326\n",
      "epoch 15, Batch loss: 0.19758863747119904\n",
      "epoch 15, Batch loss: 0.2488636076450348\n",
      "epoch 15, Batch loss: 0.3229871988296509\n",
      "epoch 15, Batch loss: 0.36676743626594543\n",
      "epoch 15, Batch loss: 0.3191211223602295\n",
      "epoch 15, Batch loss: 0.2543588876724243\n",
      "epoch 15, Batch loss: 0.3057548999786377\n",
      "epoch 15, Batch loss: 0.22914619743824005\n",
      "epoch 15, Batch loss: 0.35211822390556335\n",
      "epoch 15, Batch loss: 0.49486708641052246\n",
      "epoch 15, Batch loss: 0.3741418421268463\n",
      "epoch 15, Batch loss: 0.2784859836101532\n",
      "epoch 15, Batch loss: 0.3465174734592438\n",
      "epoch 15, Batch loss: 0.3876764178276062\n",
      "epoch 15, Batch loss: 0.323839396238327\n",
      "epoch 15, Batch loss: 0.3916175961494446\n",
      "epoch 15, Batch loss: 0.2142101675271988\n",
      "epoch 15, Batch loss: 0.45857954025268555\n",
      "epoch 15, Batch loss: 0.23979994654655457\n",
      "epoch 15, Batch loss: 0.24787531793117523\n",
      "epoch 15, Batch loss: 0.2894088327884674\n",
      "epoch 15, Batch loss: 0.2386680394411087\n",
      "epoch 15, Batch loss: 0.4090290665626526\n",
      "epoch 15, Batch loss: 0.36656898260116577\n",
      "epoch 15, Batch loss: 0.30828428268432617\n",
      "epoch 15, Batch loss: 0.2566472887992859\n",
      "epoch 15, Batch loss: 0.3331518769264221\n",
      "epoch 15, Batch loss: 0.22393611073493958\n",
      "epoch 15, Batch loss: 0.2487882822751999\n",
      "epoch 15, Batch loss: 0.34396833181381226\n",
      "epoch 15, Batch loss: 0.45299044251441956\n",
      "epoch 15, Batch loss: 0.30282291769981384\n",
      "epoch 15, Batch loss: 0.3114088177680969\n",
      "epoch 15, Batch loss: 0.35906633734703064\n",
      "epoch 15, Batch loss: 0.3533187210559845\n",
      "epoch 15, Batch loss: 0.44145849347114563\n",
      "epoch 15, Batch loss: 0.3031747043132782\n",
      "epoch 15, Batch loss: 0.4635165333747864\n",
      "epoch 15, Batch loss: 0.2125437706708908\n",
      "epoch 15, Batch loss: 0.3404785990715027\n",
      "epoch 15, Batch loss: 0.4241904616355896\n",
      "epoch 15, Batch loss: 0.25150996446609497\n",
      "epoch 15, Batch loss: 0.49476057291030884\n",
      "epoch 15, Batch loss: 0.46274009346961975\n",
      "epoch 15, Batch loss: 0.37187454104423523\n",
      "epoch 15, Batch loss: 0.2381037175655365\n",
      "Epoch 15/15, Rouge Score: {'rouge1': 0.39295326801382535, 'rouge2': 0.19742346787738033, 'rougeL': 0.36685975277932903}, Batch loss: 0.2381037175655365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('codeNarrator_T5/tokenizer_config.json',\n",
       " 'codeNarrator_T5/special_tokens_map.json',\n",
       " 'codeNarrator_T5/spiece.model',\n",
       " 'codeNarrator_T5/added_tokens.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define dataset class\n",
    "class GPT2HumanDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gpt_comment = self.data.iloc[idx][\"gptComment\"]\n",
    "        human_comment = self.data.iloc[idx][\"groundTruth\"]\n",
    "\n",
    "        input_text = f\"generate human like comment from gptComment: {gpt_comment}\"\n",
    "        target_text = human_comment\n",
    "\n",
    "        input_ids = self.tokenizer.encode(input_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        labels = self.tokenizer.encode(target_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids.squeeze(),\n",
    "            \"attention_mask\": input_ids != tokenizer.pad_token_id,\n",
    "            \"labels\": labels.squeeze()\n",
    "        }\n",
    "\n",
    "def evaluate_rouge(model, val_loader):\n",
    "    model.eval()\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Generate predictions\n",
    "            generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=128, num_beams=4, early_stopping=True)\n",
    "            predicted_sentences = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "\n",
    "            # Compute ROUGE scores\n",
    "            for ref, hyp in zip(labels, predicted_sentences):\n",
    "                scores = scorer.score(hyp, tokenizer.decode(ref.cpu(), skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "                for rouge_type in rouge_scores.keys():\n",
    "                    rouge_scores[rouge_type] += scores[rouge_type].fmeasure\n",
    "                num_samples += 1\n",
    "\n",
    "    # Calculate average ROUGE scores\n",
    "    for rouge_type in rouge_scores.keys():\n",
    "        rouge_scores[rouge_type] /= num_samples\n",
    "\n",
    "    return rouge_scores\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "max_length = 128\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 15\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(GPT2HumanDataset(train_df, tokenizer, max_length), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(GPT2HumanDataset(val_df, tokenizer, max_length), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"epoch {epoch+1}, Batch loss: {loss.item()}\")\n",
    "    # Evaluate on validation set\n",
    "rouge_scores = evaluate_rouge(model, val_loader)\n",
    "print(f\"Epoch {epoch+1}/{num_epochs}, Rouge Score: {rouge_scores}, Batch loss: {loss.item()}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"codeNarrator_T5\")\n",
    "tokenizer.save_pretrained(\"codeNarrator_T5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49e9dfc2-9422-4245-ad2e-2157c78f4fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.06060606060606061}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_csv_file = \"/student/mjr175/commentGeneration/Test_From_Asap/outputJava250 (copy).csv\"\n",
    "output_csv_file = \"/student/mjr175/commentGeneration/Test_From_Asap/outputJava250_predicted.csv\"\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "fine_tuned_model = T5ForConditionalGeneration.from_pretrained(\"fine_tuned_t5\")\n",
    "fine_tuned_tokenizer = T5Tokenizer.from_pretrained(\"codeNarrator_T5\")\n",
    "\n",
    "def generateOutput(test_sentence):\n",
    "    inputs = fine_tuned_tokenizer.encode_plus(\n",
    "        test_sentence,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    fine_tuned_model.to(device)\n",
    "    output_ids = fine_tuned_model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=128,  # Adjust the max_length as needed\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return fine_tuned_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load test data from CSV file\n",
    "test_data = pd.read_csv(test_csv_file)\n",
    "\n",
    "# Generate outputs and save in another CSV file\n",
    "predicted_comments = []\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "for index, row in test_data.iterrows():\n",
    "    input_comment = row[\"gptComment\"]\n",
    "    output_comment = generateOutput(input_comment)\n",
    "    predicted_comments.append(output_comment)\n",
    "    reference_comment = row[\"groundTruth\"]\n",
    "    scores = scorer.score(reference_comment, output_comment)\n",
    "    for metric, score in scores.items():\n",
    "        rouge_scores[metric].append(score.fmeasure)\n",
    "# Add predicted comments to the test data and save to output CSV file\n",
    "average_rouge_scores = {metric: sum(scores) / len(scores) for metric, scores in rouge_scores.items()}\n",
    "\n",
    "test_data[\"Predicted_Comment\"] = predicted_comments\n",
    "print(average_rouge_scores) \n",
    "test_data.to_csv(output_csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f0324-7b8a-480f-9a9d-51417d7c963b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
